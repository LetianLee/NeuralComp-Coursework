{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2guthgOz-Ssm"
   },
   "source": [
    "# Coursework 2 for Cardiac MR Image Segmentation (2020-2021)\n",
    "\n",
    "After you have gone through the coursework description, this tutorial is designed to further helps you understand the problem and therefore enable you to propose a good solution for this coursework. You will learn:\n",
    "\n",
    "* how to load and save images with OpenCV\n",
    "* how to train a segmentation model with Pytorch\n",
    "* how to evaluate the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsnVbP35-Sso"
   },
   "source": [
    "## 1. Load, show, and save images with OpenCV\n",
    "\n",
    "OpenCV is an open-source computer vision library which helps us to manipulate image data. In this section, we will cover:\n",
    "* Loading an image from file with imread()\n",
    "* Displaying the image with matplotlib plt.imshow()\n",
    "* Saving an image with imwrite()\n",
    "\n",
    "For a more comprehensive study of OpenCV, we encourage you to check the official [OpenCV documentation](https://docs.opencv.org/master/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C7ZvSiY3qW_U"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def show_image_mask(img, mask, cmap='gray'): # visualisation\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=cmap)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "EN5WJ_XG-Sso"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2 #import OpenCV\n",
    "\n",
    "data_dir = './data/train'\n",
    "image = cv2.imread(os.path.join(data_dir,'image','cmr1.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask = cv2.imread(os.path.join(data_dir,'mask','cmr1_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "show_image_mask(image, mask, cmap='gray')\n",
    "plt.pause(1)\n",
    "cv2.imwrite(os.path.join('./','cmr1.png'), mask*85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UDvsGZnYfHS"
   },
   "source": [
    "Note: You will no doubt notice that the mask images appear to be completely black with no sign of any segmentations. This is because the max intensity of pixels in an 8-bit png image is 255 and your image viewer software only sees 255 as white. For those values close to zero, you will only see dark values. This is the case for our masks as the background, the right ventricle, the myocardium, and the left ventricle in each image are 0, 1, 2, and 3, respectively. All of which are close to zero. If we multiply the original mask by 85 and save the result to the directory where this code is, we can see the heart indeed shows up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hULAX3WH-Sss"
   },
   "source": [
    "## 2 Define a segmentation model with Pytorch\n",
    "\n",
    "In this section, we expect you to learn how to:\n",
    "* Define a Segmentation Model\n",
    "* Define a DataLoader that inputs images to the Model\n",
    "* Define training parameters and train the model\n",
    "* Test the trained model with a new input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrKFgoZvUbeg"
   },
   "source": [
    "### 2.1 Define a DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC9s43MqqW_U"
   },
   "source": [
    "Below we provide you with a dataloader to use in your assigment. You will only need to focus on the development of your model and loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "XYrD95T8qz8T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "        self.mask_files = []\n",
    "        for img_path in self.img_files:\n",
    "            basename = os.path.basename(img_path)\n",
    "            self.mask_files.append(os.path.join(root,'mask',basename[:-4]+'_mask.png'))\n",
    "            \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            mask_path = self.mask_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            label = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float(), torch.from_numpy(label).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82UAfnwSUgc_"
   },
   "source": [
    "### 2.2 Define a Segmenatation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEIkCqdfYnIn"
   },
   "source": [
    "You will need to define your CNN model for segmentation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-W6532hFXa_g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNSEG(nn.Module): # Define your model\n",
    "    def __init__(self):\n",
    "        super(CNNSEG, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "model = CNNSEG() # We can now create a model using your defined segmentation model\n",
    "# data_path = './data/train'\n",
    "# train_set = TrainDataset(data_path)\n",
    "# #input = torch.randn(1,1,96,96)\n",
    "# #out = model(input)\n",
    "# #print(out)\n",
    "# for x in train_set:\n",
    "#     print(x[0].size())\n",
    "#     input = x[0]\n",
    "#     a = model.forward(input)\n",
    "#     print(a)\n",
    "#     x[1] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ContBatchNorm3d(nn.modules.batchnorm._BatchNorm):\n",
    "    def _check_input_dim(self, input):\n",
    "\n",
    "        if input.dim() != 5:\n",
    "            pass\n",
    "#             raise ValueError('expected 5D input (got {}D input)'.format(input.dim()))\n",
    "        #super(ContBatchNorm3d, self)._check_input_dim(input)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self._check_input_dim(input)\n",
    "        return F.batch_norm(\n",
    "            input, self.running_mean, self.running_var, self.weight, self.bias,\n",
    "            True, self.momentum, self.eps)\n",
    "\n",
    "\n",
    "class LUConv(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, act):\n",
    "        super(LUConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, out_chan, kernel_size=3, padding=1)\n",
    "        self.bn1 = ContBatchNorm3d(out_chan)\n",
    "\n",
    "        if act == 'relu':\n",
    "            self.activation = nn.ReLU(out_chan)\n",
    "        elif act == 'prelu':\n",
    "            self.activation = nn.PReLU(out_chan)\n",
    "        elif act == 'elu':\n",
    "            self.activation = nn.ELU(inplace=True)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.bn1(self.conv1(x)))\n",
    "        return out\n",
    "\n",
    "\n",
    "def _make_nConv(in_channel, depth, act, double_chnnel=False):\n",
    "    if double_chnnel:\n",
    "        layer1 = LUConv(in_channel, 32 * (2 ** (depth+1)),act)\n",
    "        layer2 = LUConv(32 * (2 ** (depth+1)), 32 * (2 ** (depth+1)),act)\n",
    "    else:\n",
    "        layer1 = LUConv(in_channel, 32*(2**depth),act)\n",
    "        layer2 = LUConv(32*(2**depth), 32*(2**depth)*2,act)\n",
    "\n",
    "    return nn.Sequential(layer1,layer2)\n",
    "\n",
    "\n",
    "# class InputTransition(nn.Module):\n",
    "#     def __init__(self, outChans, elu):\n",
    "#         super(InputTransition, self).__init__()\n",
    "#         self.conv1 = nn.Conv3d(1, 16, kernel_size=5, padding=2)\n",
    "#         self.bn1 = ContBatchNorm3d(16)\n",
    "#         self.relu1 = ELUCons(elu, 16)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         # do we want a PRELU here as well?\n",
    "#         out = self.bn1(self.conv1(x))\n",
    "#         # split input in to 16 channels\n",
    "#         x16 = torch.cat((x, x, x, x, x, x, x, x,\n",
    "#                          x, x, x, x, x, x, x, x), 1)\n",
    "#         out = self.relu1(torch.add(out, x16))\n",
    "#         return out\n",
    "\n",
    "class DownTransition(nn.Module):\n",
    "    def __init__(self, in_channel,depth, act):\n",
    "        super(DownTransition, self).__init__()\n",
    "        self.ops = _make_nConv(in_channel, depth,act)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.current_depth = depth\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.current_depth == 3:\n",
    "            out = self.ops(x)\n",
    "            out_before_pool = out\n",
    "        else:\n",
    "            out_before_pool = self.ops(x)\n",
    "            out = self.maxpool(out_before_pool)\n",
    "        return out, out_before_pool\n",
    "\n",
    "class UpTransition(nn.Module):\n",
    "    def __init__(self, inChans, outChans, depth,act):\n",
    "        super(UpTransition, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.up_conv = nn.ConvTranspose2d(inChans, outChans, kernel_size=2, stride=2)\n",
    "        self.ops = _make_nConv(inChans+ outChans//2,depth, act, double_chnnel=True)\n",
    "\n",
    "    def forward(self, x, skip_x):\n",
    "        out_up_conv = self.up_conv(x)\n",
    "        concat = torch.cat((out_up_conv,skip_x),1)\n",
    "        out = self.ops(concat)\n",
    "        return out\n",
    "\n",
    "\n",
    "class OutputTransition(nn.Module):\n",
    "    def __init__(self, inChans, n_labels):\n",
    "\n",
    "        super(OutputTransition, self).__init__()\n",
    "        self.final_conv = nn.Conv2d(inChans, n_labels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.sigmoid(self.final_conv(x))\n",
    "        return out\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    # the number of convolutions in each layer corresponds\n",
    "    # to what is in the actual prototxt, not the intent\n",
    "    def __init__(self, n_class=4, act='relu'):\n",
    "        super(UNet3D, self).__init__()\n",
    "        \n",
    "\n",
    "        self.down_tr64 = DownTransition(1,0,act)\n",
    "        self.down_tr128 = DownTransition(64,1,act)\n",
    "        self.down_tr256 = DownTransition(128,2,act)\n",
    "        self.down_tr512 = DownTransition(256,3,act)\n",
    "\n",
    "        self.up_tr256 = UpTransition(512, 512,2,act)\n",
    "        self.up_tr128 = UpTransition(256,256, 1,act)\n",
    "        self.up_tr64 = UpTransition(128,128,0,act)\n",
    "        self.out_tr = OutputTransition(64, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out64, self.skip_out64 = self.down_tr64(x)\n",
    "        self.out128,self.skip_out128 = self.down_tr128(self.out64)\n",
    "        self.out256,self.skip_out256 = self.down_tr256(self.out128)\n",
    "        self.out512,self.skip_out512 = self.down_tr512(self.out256)\n",
    "\n",
    "        self.out_up_256 = self.up_tr256(self.out512,self.skip_out256)\n",
    "        self.out_up_128 = self.up_tr128(self.out_up_256, self.skip_out128)\n",
    "        self.out_up_64 = self.up_tr64(self.out_up_128, self.skip_out64)\n",
    "        self.out = self.out_tr(self.out_up_64)\n",
    "\n",
    "        return self.out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRdPFTa9a34J"
   },
   "source": [
    "### 2.3 Define a Loss function and optimizer\n",
    "\n",
    "You will need to define a loss function and an optimizer. torch.nn has a variety of readymade loss functions, although you may wish to create your own instead. torch.optim has a variety of optimizers, it is advised that you use one of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "QRjOZGXRbUFT"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "loss & optimizer\n",
    "\"\"\"\n",
    "\n",
    "import torch.optim as optim\n",
    "#from torch.optim import AdamW\n",
    "# Loss = nn.CrossEntropyLoss(weight=torch.Tensor([1,3,3,3]))\n",
    "\n",
    "def softmax_helper(x):\n",
    "    # copy from: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/utilities/nd_softmax.py\n",
    "    rpt = [1 for _ in range(len(x.size()))]\n",
    "    rpt[1] = x.size(1)\n",
    "    x_max = x.max(1, keepdim=True)[0].repeat(*rpt)\n",
    "    e_x = torch.exp(x - x_max)\n",
    "    return e_x / e_x.sum(1, keepdim=True).repeat(*rpt)\n",
    "\n",
    "def sum_tensor(inp, axes, keepdim=False):\n",
    "    # copy from: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/utilities/tensor_utilities.py\n",
    "    axes = np.unique(axes).astype(int)\n",
    "    if keepdim:\n",
    "        for ax in axes:\n",
    "            inp = inp.sum(int(ax), keepdim=True)\n",
    "    else:\n",
    "        for ax in sorted(axes, reverse=True):\n",
    "            inp = inp.sum(int(ax))\n",
    "    return inp\n",
    "\n",
    "def get_tp_fp_fn(net_output, gt, axes=None, mask=None, square=False):\n",
    "    \"\"\"\n",
    "    net_output must be (b, c, x, y(, z)))\n",
    "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
    "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
    "    :param net_output:\n",
    "    :param gt:\n",
    "    :param axes:\n",
    "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
    "    :param square: if True then fp, tp and fn will be squared before summation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = tuple(range(2, len(net_output.size())))\n",
    "\n",
    "    shp_x = net_output.shape\n",
    "    shp_y = gt.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if len(shp_x) != len(shp_y):\n",
    "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
    "\n",
    "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
    "            # if this is the case then gt is probably already a one hot encoding\n",
    "            y_onehot = gt\n",
    "        else:\n",
    "            gt = gt.long()\n",
    "            y_onehot = torch.zeros(shp_x)\n",
    "            if net_output.device.type == \"cuda\":\n",
    "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
    "            y_onehot.scatter_(1, gt, 1)\n",
    "\n",
    "    tp = net_output * y_onehot\n",
    "    fp = net_output * (1 - y_onehot)\n",
    "    fn = (1 - net_output) * y_onehot\n",
    "\n",
    "    if mask is not None:\n",
    "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
    "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
    "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
    "\n",
    "    if square:\n",
    "        tp = tp ** 2\n",
    "        fp = fp ** 2\n",
    "        fn = fn ** 2\n",
    "\n",
    "    tp = sum_tensor(tp, axes, keepdim=False)\n",
    "    fp = sum_tensor(fp, axes, keepdim=False)\n",
    "    fn = sum_tensor(fn, axes, keepdim=False)\n",
    "\n",
    "    return tp, fp, fn\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, apply_nonlin=None, batch_dice=False, do_bg=True, smooth=1.,\n",
    "                 square=False):\n",
    "        \"\"\"\n",
    "        paper: https://arxiv.org/pdf/1706.05721.pdf\n",
    "        \"\"\"\n",
    "        super(TverskyLoss, self).__init__()\n",
    "\n",
    "        self.square = square\n",
    "        self.do_bg = do_bg\n",
    "        self.batch_dice = batch_dice\n",
    "        self.apply_nonlin = apply_nonlin\n",
    "        self.smooth = smooth\n",
    "        self.alpha = 0.7\n",
    "        self.beta = 0.3\n",
    "\n",
    "    def forward(self, x, y, loss_mask=None):\n",
    "        shp_x = x.shape\n",
    "\n",
    "        if self.batch_dice:\n",
    "            axes = [0] + list(range(2, len(shp_x)))\n",
    "        else:\n",
    "            axes = list(range(2, len(shp_x)))\n",
    "\n",
    "        if self.apply_nonlin is not None:\n",
    "            x = self.apply_nonlin(x)\n",
    "\n",
    "        tp, fp, fn = get_tp_fp_fn(x, y, axes, loss_mask, self.square)\n",
    "\n",
    "\n",
    "        tversky = (tp + self.smooth) / (tp + self.alpha*fp + self.beta*fn + self.smooth)\n",
    "\n",
    "        if not self.do_bg:\n",
    "            if self.batch_dice:\n",
    "                tversky = tversky[1:]\n",
    "            else:\n",
    "                tversky = tversky[:, 1:]\n",
    "        tversky = tversky.mean()\n",
    "\n",
    "        return -tversky\n",
    "\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "#Loss = TverskyLoss()\n",
    "\n",
    "def optimize(model,method,learning_rate):\n",
    "    if method == \"SGD\":\n",
    "        return optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    elif method == \"Adam\":\n",
    "        return optim.AdamW(model.parameters(), lr=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
    "    elif method == \"AdaGrad\":\n",
    "        return optim.Adagrad(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grDz3fR1qW_V"
   },
   "source": [
    "### 2.4 Training\n",
    "\n",
    "As most of you will use CPUs to train the model, expect your models to take **30 minutes to train if not longer depending on network architecture**. To save time, you should not be using all training data until your model is well developed. If you are running your model on a GPU training should be significantly faster. During the training process, you may want to save the checkpoints as follows:\n",
    "\n",
    "```\n",
    "# Saving checkpoints for validation/testing\n",
    "torch.save(model.state_dict(), path)\n",
    "```\n",
    "The saved checkpoints can be used to load at a later date for validation and testing. Here we give some example code for training a model. Note that you need to specify the max iterations you want to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "iCb4bxVVchxf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "def learn(model,num_workers = 0, batch_size = 4,epochs = 10,learning_rate = 1, optimizer_name = \"SGD\"):\n",
    "\n",
    "    data_path = './data/train'\n",
    "    train_set = TrainDataset(data_path)\n",
    "    training_data_loader = DataLoader(dataset=train_set, num_workers=num_workers, batch_size=batch_size, \n",
    "                                      shuffle=True,drop_last = True)\n",
    "\n",
    "    data_path = './data/val'\n",
    "    val_set = TrainDataset(data_path)\n",
    "    val_data_loader = DataLoader(dataset=val_set, num_workers=num_workers, batch_size=batch_size, \n",
    "                                 shuffle=True,drop_last = True)\n",
    "\n",
    "    loss_list = list()\n",
    "    val_loss_list = list()\n",
    "    optimizer = optimize(model,\"SGD\",learning_rate)\n",
    "    for e in range(epochs):\n",
    "        # Fetch images and labels.  \n",
    "        for iteration, sample in enumerate(training_data_loader):\n",
    "        # for iteration, sample in enumerate(list(training_data_loader)[:5]):\n",
    "            print(\"epoch, iteration:\", e, iteration)\n",
    "            img, mask = sample\n",
    "            \n",
    "    #     show_image_mask(img[0,...].squeeze(), mask[0,...].squeeze()) #visualise all data in training set\n",
    "    #     plt.pause(1)\n",
    "\n",
    "            # Write your FORWARD below\n",
    "            # Note: Input image to your model and ouput the predicted mask and Your predicted mask should have 4 channels\n",
    "            model.train()  \n",
    "            optimizer.zero_grad()\n",
    "            img = img / 255 - 0.5\n",
    "            #img.transforms.ToTensor()\n",
    "            y_pred = model(img.reshape(batch_size,1,96,96))           \n",
    "            #y_pred = model(img.reshape(len(img),1,96,96))           \n",
    "            loss = Loss(y_pred , mask.long())               \n",
    "            loss_list.append(loss)\n",
    "            print(\"loss:\",loss)\n",
    "\n",
    "            # Then write your BACKWARD & OPTIMIZE below\n",
    "            # Note: Compute Loss and Optimize\n",
    "            loss.backward()           # calculate gradients\n",
    "            optimizer.step()          # update model's params\n",
    "\n",
    "        with torch.no_grad():          # fix the model's params\n",
    "            model.eval()               # set model to evaluation mode\n",
    "            loss_temp = list()\n",
    "            for val_iteration, val_sample in enumerate(val_data_loader):\n",
    "                val_img, val_mask = val_sample\n",
    "                val_img= val_img / 255 - 0.5\n",
    "                #val_img.transforms.ToTensor()\n",
    "                val_y_pred = model(val_img.reshape(batch_size,1,96,96))   \n",
    "                val_loss = Loss(val_y_pred , val_mask.long())      # validation loss\n",
    "                loss_temp.append(val_loss)\n",
    "\n",
    "            val_loss_list.append(np.mean(loss_temp))\n",
    "    \n",
    "    #plt.plot(loss_list, \"bo-\", label=u\"train loss\") \n",
    "    #plt.plot((np.arange(len(val_loss_list))+1)*25, val_loss_list, \"ro-\", label=u\"vel loss\") \n",
    "    #plt.legend(loc=\"upper right\")\n",
    "    #plt.show()\n",
    "    \n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "    return val_loss_list[-1],epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCZP-xof-Sst"
   },
   "source": [
    "### 2.5 Testing\n",
    "\n",
    "When validating the trained checkpoints (models), remember to change the model status as **Evaluation Mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lGmhTdkciDt0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LVS22lrjqW_V"
   },
   "outputs": [],
   "source": [
    "# In this block you are expected to write code to load saved model and deploy it to all data in test set to \n",
    "# produce segmentation masks in png images valued 0,1,2,3, which will be used for the submission to Kaggle.\n",
    "data_path = './data/test'\n",
    "num_workers = 0\n",
    "batch_size = 2\n",
    "\n",
    "test_set = TestDataset(data_path)\n",
    "test_data_loader = DataLoader(dataset=test_set, num_workers=num_workers,batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for iteration, sample in enumerate(test_data_loader):\n",
    "    img = sample\n",
    "#     print(img.shape)\n",
    "\n",
    "#     plt.imshow(img[0,...].squeeze(), cmap='gray') #visualise all images in test set\n",
    "#     plt.pause(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsycVbIuUov3"
   },
   "source": [
    "## 3 Evaluation\n",
    "\n",
    "As we will automatically evaluate your predicted test makes on Kaggle, in this section we expect you to learn:\n",
    "* what is the Dice score used on Kaggle to measure your models performance\n",
    "* how to submit your predicted masks to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NicQyj47jsD1"
   },
   "source": [
    "### 3.1 Dice Score\n",
    "\n",
    "To evaluate the quality of the predicted masks, the Dice score is adopted. Dice score on two masks A and B is defined as the intersection ratio between the overlap area and the average area of two masks. A higher Dice suggests a better registration.\n",
    "\n",
    "$Dice (A, B)= \\frac{2|A \\cap B|}{|A| + |B|} $\n",
    "\n",
    "However, in our coursework, we have three labels in each mask, we will compute the Dice score for each label and then average the three of them as the final score. Below we have given you `categorical_dice` for free so you can test your results before submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "RzOY4GROqW_V"
   },
   "outputs": [],
   "source": [
    "def categorical_dice(mask1, mask2, label_class=1):\n",
    "    \"\"\"\n",
    "    Dice score of a specified class between two volumes of label masks.\n",
    "    (classes are encoded but by label class number not one-hot )\n",
    "    Note: stacks of 2D slices are considered volumes.\n",
    "\n",
    "    Args:\n",
    "        mask1: N label masks, numpy array shaped (H, W, N)\n",
    "        mask2: N label masks, numpy array shaped (H, W, N)\n",
    "        label_class: the class over which to calculate dice scores\n",
    "\n",
    "    Returns:\n",
    "        volume_dice\n",
    "    \"\"\"\n",
    "    mask1_pos = (mask1 == label_class).astype(np.float32)\n",
    "    mask2_pos = (mask2 == label_class).astype(np.float32)\n",
    "    dice = 2 * np.sum(mask1_pos * mask2_pos) / (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_dice(mask1, mask2):\n",
    "    dice_list = list()\n",
    "    for i in range(1, 4):\n",
    "        dice = categorical_dice(mask1, mask2, label_class=i)\n",
    "        dice_list.append(dice)\n",
    "    return np.mean(dice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, num_workers = 0):\n",
    "    data_path = './data/val'\n",
    "    val_set = TrainDataset(data_path)\n",
    "    val_data_loader = DataLoader(dataset=val_set, num_workers=num_workers, shuffle=True)\n",
    "    with torch.no_grad():\n",
    "        model.eval() \n",
    "        batch_dice_list = list()\n",
    "        for iteration, sample in enumerate(val_data_loader):\n",
    "            img, mask = sample\n",
    "            img = img/255 - 0.5\n",
    "            #img = torchvision.transforms.ToTensor(img)\n",
    "            y_pred = model(img.reshape(1,1,96,96))\n",
    "            masks = torch.zeros(1,1,96,96)\n",
    "            for index in range(y_pred.shape[0]):\n",
    "                for i in range(y_pred.shape[2]):\n",
    "                    for j in range(y_pred.shape[3]):\n",
    "                        masks[index,:,i,j] = torch.argmax(y_pred[index,:,i,j])\n",
    "\n",
    "            plt.imshow(mask, cmap='gray')\n",
    "            plt.show()\n",
    "            plt.imshow(masks.squeeze(), cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "            batch_dice = see_dice(mask.numpy(), masks.squeeze().numpy())\n",
    "            print(\"batch_dice:\",batch_dice)\n",
    "            batch_dice_list.append(batch_dice)\n",
    "\n",
    "        val_dice = np.mean(batch_dice_list)\n",
    "        print(\"val_dice:\",val_dice)\n",
    "        return val_dice\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for Learning Rate:  0.01\n",
      "Test for Batch Size:  1\n",
      "epoch, iteration: 0 0\n",
      "loss: tensor(1.3764, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 1\n",
      "loss: tensor(1.3719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 2\n",
      "loss: tensor(1.3684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 3\n",
      "loss: tensor(1.3649, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 4\n",
      "loss: tensor(1.3589, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 5\n",
      "loss: tensor(1.3573, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 6\n",
      "loss: tensor(1.3533, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 7\n",
      "loss: tensor(1.3537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 8\n",
      "loss: tensor(1.3388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 9\n",
      "loss: tensor(1.3352, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 10\n",
      "loss: tensor(1.3385, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 11\n",
      "loss: tensor(1.3413, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 12\n",
      "loss: tensor(1.3359, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 13\n",
      "loss: tensor(1.3334, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 14\n",
      "loss: tensor(1.3183, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 15\n",
      "loss: tensor(1.3248, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 16\n",
      "loss: tensor(1.3265, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 17\n",
      "loss: tensor(1.3181, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 18\n",
      "loss: tensor(1.3114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 19\n",
      "loss: tensor(1.3035, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 20\n",
      "loss: tensor(1.3145, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 21\n",
      "loss: tensor(1.3088, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 22\n",
      "loss: tensor(1.3052, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 23\n",
      "loss: tensor(1.2839, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 24\n",
      "loss: tensor(1.2850, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 25\n",
      "loss: tensor(1.2835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 26\n",
      "loss: tensor(1.2935, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 27\n",
      "loss: tensor(1.2892, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 28\n",
      "loss: tensor(1.2734, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 29\n",
      "loss: tensor(1.2842, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 30\n",
      "loss: tensor(1.2978, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 31\n",
      "loss: tensor(1.2623, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 32\n",
      "loss: tensor(1.2732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 33\n",
      "loss: tensor(1.2645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 34\n",
      "loss: tensor(1.2673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 35\n",
      "loss: tensor(1.2568, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 36\n",
      "loss: tensor(1.2713, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 37\n",
      "loss: tensor(1.2620, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 38\n",
      "loss: tensor(1.2758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 39\n",
      "loss: tensor(1.2475, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 40\n",
      "loss: tensor(1.2417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 41\n",
      "loss: tensor(1.2442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 42\n",
      "loss: tensor(1.2571, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 43\n",
      "loss: tensor(1.2419, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 44\n",
      "loss: tensor(1.2450, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 45\n",
      "loss: tensor(1.2419, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 46\n",
      "loss: tensor(1.2306, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 47\n",
      "loss: tensor(1.2431, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 48\n",
      "loss: tensor(1.2260, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 49\n",
      "loss: tensor(1.2138, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 50\n",
      "loss: tensor(1.2409, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 51\n",
      "loss: tensor(1.2291, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 52\n",
      "loss: tensor(1.2244, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 53\n",
      "loss: tensor(1.2129, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 54\n",
      "loss: tensor(1.2049, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 55\n",
      "loss: tensor(1.2125, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 56\n",
      "loss: tensor(1.2168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 57\n",
      "loss: tensor(1.2022, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 58\n",
      "loss: tensor(1.2183, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 59\n",
      "loss: tensor(1.2289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 60\n",
      "loss: tensor(1.2180, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 61\n",
      "loss: tensor(1.2145, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 62\n",
      "loss: tensor(1.2157, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 63\n",
      "loss: tensor(1.1906, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 64\n",
      "loss: tensor(1.2411, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 65\n",
      "loss: tensor(1.1995, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 66\n",
      "loss: tensor(1.1905, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 67\n",
      "loss: tensor(1.2100, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 68\n",
      "loss: tensor(1.2032, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 69\n",
      "loss: tensor(1.1649, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 70\n",
      "loss: tensor(1.1948, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 71\n",
      "loss: tensor(1.1828, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 72\n",
      "loss: tensor(1.1965, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 73\n",
      "loss: tensor(1.1776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 74\n",
      "loss: tensor(1.2082, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 75\n",
      "loss: tensor(1.1896, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 76\n",
      "loss: tensor(1.1830, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 77\n",
      "loss: tensor(1.1599, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 78\n",
      "loss: tensor(1.1830, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 79\n",
      "loss: tensor(1.1696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 80\n",
      "loss: tensor(1.1882, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 81\n",
      "loss: tensor(1.1557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 82\n",
      "loss: tensor(1.1559, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 83\n",
      "loss: tensor(1.1708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 84\n",
      "loss: tensor(1.1622, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 85\n",
      "loss: tensor(1.1639, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 86\n",
      "loss: tensor(1.1759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 87\n",
      "loss: tensor(1.1474, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 88\n",
      "loss: tensor(1.1579, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 89\n",
      "loss: tensor(1.1437, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 90\n",
      "loss: tensor(1.1679, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 91\n",
      "loss: tensor(1.1382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 92\n",
      "loss: tensor(1.1694, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 93\n",
      "loss: tensor(1.1467, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 94\n",
      "loss: tensor(1.1451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 95\n",
      "loss: tensor(1.1488, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 96\n",
      "loss: tensor(1.1502, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 97\n",
      "loss: tensor(1.1476, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 98\n",
      "loss: tensor(1.1373, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 99\n",
      "loss: tensor(1.1433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 0\n",
      "loss: tensor(1.1442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 1\n",
      "loss: tensor(1.1328, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 2\n",
      "loss: tensor(1.1401, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 3\n",
      "loss: tensor(1.1755, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 4\n",
      "loss: tensor(1.1417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 5\n",
      "loss: tensor(1.1353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 6\n",
      "loss: tensor(1.1471, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 7\n",
      "loss: tensor(1.1340, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 8\n",
      "loss: tensor(1.1446, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 9\n",
      "loss: tensor(1.1117, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 10\n",
      "loss: tensor(1.1210, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 11\n",
      "loss: tensor(1.1339, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 1 12\n",
      "loss: tensor(1.1113, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 13\n",
      "loss: tensor(1.1177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 14\n",
      "loss: tensor(1.1250, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 15\n",
      "loss: tensor(1.1343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 16\n",
      "loss: tensor(1.1173, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 17\n",
      "loss: tensor(1.1175, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 18\n",
      "loss: tensor(1.1141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 19\n",
      "loss: tensor(1.1265, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 20\n",
      "loss: tensor(1.1364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 21\n",
      "loss: tensor(1.1046, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 22\n",
      "loss: tensor(1.1289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 23\n",
      "loss: tensor(1.1471, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 24\n",
      "loss: tensor(1.1033, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 25\n",
      "loss: tensor(1.1093, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 26\n",
      "loss: tensor(1.1266, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 27\n",
      "loss: tensor(1.0900, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 28\n",
      "loss: tensor(1.1124, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 29\n",
      "loss: tensor(1.1233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 30\n",
      "loss: tensor(1.1192, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 31\n",
      "loss: tensor(1.1758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 32\n",
      "loss: tensor(1.1142, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 33\n",
      "loss: tensor(1.1062, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 34\n",
      "loss: tensor(1.1104, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 35\n",
      "loss: tensor(1.1337, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 36\n",
      "loss: tensor(1.1088, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 37\n",
      "loss: tensor(1.1214, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 38\n",
      "loss: tensor(1.1098, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 39\n",
      "loss: tensor(1.0884, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 40\n",
      "loss: tensor(1.0979, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 41\n",
      "loss: tensor(1.0913, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 42\n",
      "loss: tensor(1.0873, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 43\n",
      "loss: tensor(1.1029, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 44\n",
      "loss: tensor(1.1216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 45\n",
      "loss: tensor(1.0999, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 46\n",
      "loss: tensor(1.1219, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 47\n",
      "loss: tensor(1.0830, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 48\n",
      "loss: tensor(1.0909, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 49\n",
      "loss: tensor(1.0616, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 50\n",
      "loss: tensor(1.1100, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 51\n",
      "loss: tensor(1.1018, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 52\n",
      "loss: tensor(1.0981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 53\n",
      "loss: tensor(1.0886, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 54\n",
      "loss: tensor(1.1078, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 55\n",
      "loss: tensor(1.1028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 56\n",
      "loss: tensor(1.0790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 57\n",
      "loss: tensor(1.0744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 58\n",
      "loss: tensor(1.0741, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 59\n",
      "loss: tensor(1.1182, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 60\n",
      "loss: tensor(1.0853, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 61\n",
      "loss: tensor(1.1003, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 62\n",
      "loss: tensor(1.0753, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 63\n",
      "loss: tensor(1.0746, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 64\n",
      "loss: tensor(1.0744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 65\n",
      "loss: tensor(1.0843, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 66\n",
      "loss: tensor(1.0812, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 67\n",
      "loss: tensor(1.0755, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 68\n",
      "loss: tensor(1.0953, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 69\n",
      "loss: tensor(1.0800, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 70\n",
      "loss: tensor(1.0861, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 71\n",
      "loss: tensor(1.0646, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 72\n",
      "loss: tensor(1.0772, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 73\n",
      "loss: tensor(1.1183, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 74\n",
      "loss: tensor(1.0743, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 75\n",
      "loss: tensor(1.0507, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 76\n",
      "loss: tensor(1.1308, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 77\n",
      "loss: tensor(1.0664, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 78\n",
      "loss: tensor(1.1063, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 79\n",
      "loss: tensor(1.0657, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 80\n",
      "loss: tensor(1.0574, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 81\n",
      "loss: tensor(1.0640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 82\n",
      "loss: tensor(1.1013, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 83\n",
      "loss: tensor(1.0669, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 84\n",
      "loss: tensor(1.0699, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 85\n",
      "loss: tensor(1.0447, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 86\n",
      "loss: tensor(1.0679, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 87\n",
      "loss: tensor(1.0534, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 88\n",
      "loss: tensor(1.0675, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 89\n",
      "loss: tensor(1.0565, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 90\n",
      "loss: tensor(1.0665, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 91\n",
      "loss: tensor(1.0647, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 92\n",
      "loss: tensor(1.0789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 93\n",
      "loss: tensor(1.0388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 94\n",
      "loss: tensor(1.0614, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 95\n",
      "loss: tensor(1.0605, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 96\n",
      "loss: tensor(1.0470, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 97\n",
      "loss: tensor(1.0336, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 98\n",
      "loss: tensor(1.0559, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 99\n",
      "loss: tensor(1.0572, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 0\n",
      "loss: tensor(1.0568, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 1\n",
      "loss: tensor(1.0478, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 2\n",
      "loss: tensor(1.0561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 3\n",
      "loss: tensor(1.0462, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 4\n",
      "loss: tensor(1.1160, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 5\n",
      "loss: tensor(1.0460, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 6\n",
      "loss: tensor(1.0520, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 7\n",
      "loss: tensor(1.0532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 8\n",
      "loss: tensor(1.0899, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 9\n",
      "loss: tensor(1.0585, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 10\n",
      "loss: tensor(1.0184, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 11\n",
      "loss: tensor(1.0818, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 12\n",
      "loss: tensor(1.0472, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 13\n",
      "loss: tensor(1.0687, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 14\n",
      "loss: tensor(1.0361, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 15\n",
      "loss: tensor(1.0353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 16\n",
      "loss: tensor(1.0676, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 17\n",
      "loss: tensor(1.0442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 18\n",
      "loss: tensor(1.0414, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 19\n",
      "loss: tensor(1.0500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 20\n",
      "loss: tensor(1.0319, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 21\n",
      "loss: tensor(1.0734, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 22\n",
      "loss: tensor(1.0269, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 23\n",
      "loss: tensor(1.0488, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 24\n",
      "loss: tensor(1.0414, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 2 25\n",
      "loss: tensor(1.0319, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 26\n",
      "loss: tensor(1.0264, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 27\n",
      "loss: tensor(1.0423, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 28\n",
      "loss: tensor(1.0577, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 29\n",
      "loss: tensor(1.0434, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 30\n",
      "loss: tensor(1.0435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 31\n",
      "loss: tensor(1.0256, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 32\n",
      "loss: tensor(1.0514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 33\n",
      "loss: tensor(1.0233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 34\n",
      "loss: tensor(1.0455, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 35\n",
      "loss: tensor(1.0314, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 36\n",
      "loss: tensor(1.0387, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 37\n",
      "loss: tensor(1.0667, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 38\n",
      "loss: tensor(1.0083, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 39\n",
      "loss: tensor(1.0482, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 40\n",
      "loss: tensor(1.0475, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 41\n",
      "loss: tensor(1.0664, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 42\n",
      "loss: tensor(1.0271, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 43\n",
      "loss: tensor(1.0083, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 44\n",
      "loss: tensor(1.0769, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 45\n",
      "loss: tensor(1.0435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 46\n",
      "loss: tensor(1.0316, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 47\n",
      "loss: tensor(1.0032, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 48\n",
      "loss: tensor(1.0013, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 49\n",
      "loss: tensor(1.0261, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 50\n",
      "loss: tensor(1.0195, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 51\n",
      "loss: tensor(1.0344, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 52\n",
      "loss: tensor(1.0501, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 53\n",
      "loss: tensor(1.1199, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 54\n",
      "loss: tensor(1.0684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 55\n",
      "loss: tensor(1.0143, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 56\n",
      "loss: tensor(1.0253, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 57\n",
      "loss: tensor(1.0170, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 58\n",
      "loss: tensor(0.9994, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 59\n",
      "loss: tensor(1.0400, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 60\n",
      "loss: tensor(0.9913, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 61\n",
      "loss: tensor(0.9919, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 62\n",
      "loss: tensor(1.0304, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 63\n",
      "loss: tensor(1.0406, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 64\n",
      "loss: tensor(1.0134, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 65\n",
      "loss: tensor(1.0229, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 66\n",
      "loss: tensor(1.0413, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 67\n",
      "loss: tensor(1.0216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 68\n",
      "loss: tensor(1.0875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 69\n",
      "loss: tensor(1.0179, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 70\n",
      "loss: tensor(1.0651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 71\n",
      "loss: tensor(1.0168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 72\n",
      "loss: tensor(1.0076, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 73\n",
      "loss: tensor(1.0169, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 74\n",
      "loss: tensor(0.9917, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 75\n",
      "loss: tensor(1.0216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 76\n",
      "loss: tensor(1.0015, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 77\n",
      "loss: tensor(1.0177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 78\n",
      "loss: tensor(1.0103, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 79\n",
      "loss: tensor(1.0570, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 80\n",
      "loss: tensor(0.9900, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 81\n",
      "loss: tensor(1.0230, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 82\n",
      "loss: tensor(1.0351, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 83\n",
      "loss: tensor(1.0016, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 84\n",
      "loss: tensor(1.0119, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 85\n",
      "loss: tensor(1.0095, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 86\n",
      "loss: tensor(1.0170, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 87\n",
      "loss: tensor(1.0745, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 88\n",
      "loss: tensor(1.0204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 89\n",
      "loss: tensor(1.0019, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 90\n",
      "loss: tensor(1.0211, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 91\n",
      "loss: tensor(1.0069, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 92\n",
      "loss: tensor(1.0111, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 93\n",
      "loss: tensor(1.0101, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 94\n",
      "loss: tensor(0.9812, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 95\n",
      "loss: tensor(1.0116, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 96\n",
      "loss: tensor(1.0039, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 97\n",
      "loss: tensor(1.0063, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 98\n",
      "loss: tensor(0.9802, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 99\n",
      "loss: tensor(1.0502, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 0\n",
      "loss: tensor(1.0100, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 1\n",
      "loss: tensor(1.0298, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 2\n",
      "loss: tensor(1.0243, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 3\n",
      "loss: tensor(1.0138, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 4\n",
      "loss: tensor(1.0233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 5\n",
      "loss: tensor(1.0135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 6\n",
      "loss: tensor(1.1090, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 7\n",
      "loss: tensor(1.0007, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 8\n",
      "loss: tensor(1.0068, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 9\n",
      "loss: tensor(0.9927, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 10\n",
      "loss: tensor(0.9965, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 11\n",
      "loss: tensor(1.0141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 12\n",
      "loss: tensor(1.0241, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 13\n",
      "loss: tensor(0.9968, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 14\n",
      "loss: tensor(1.0518, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 15\n",
      "loss: tensor(1.0092, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 16\n",
      "loss: tensor(1.0280, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 17\n",
      "loss: tensor(0.9908, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 18\n",
      "loss: tensor(1.0513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 19\n",
      "loss: tensor(1.0446, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 20\n",
      "loss: tensor(1.0040, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 21\n",
      "loss: tensor(0.9811, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 22\n",
      "loss: tensor(0.9991, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 23\n",
      "loss: tensor(1.0755, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 24\n",
      "loss: tensor(0.9988, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 25\n",
      "loss: tensor(0.9889, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 26\n",
      "loss: tensor(0.9922, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 27\n",
      "loss: tensor(1.0073, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 28\n",
      "loss: tensor(1.0072, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 29\n",
      "loss: tensor(1.0263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 30\n",
      "loss: tensor(0.9638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 31\n",
      "loss: tensor(0.9958, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 32\n",
      "loss: tensor(1.0423, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 33\n",
      "loss: tensor(1.0008, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 34\n",
      "loss: tensor(0.9943, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 35\n",
      "loss: tensor(0.9862, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 36\n",
      "loss: tensor(0.9675, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 37\n",
      "loss: tensor(0.9945, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 3 38\n",
      "loss: tensor(0.9925, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 39\n",
      "loss: tensor(0.9979, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 40\n",
      "loss: tensor(1.0010, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 41\n",
      "loss: tensor(0.9902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 42\n",
      "loss: tensor(1.0322, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 43\n",
      "loss: tensor(1.0033, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 44\n",
      "loss: tensor(0.9950, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 45\n",
      "loss: tensor(1.0047, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 46\n",
      "loss: tensor(0.9952, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 47\n",
      "loss: tensor(0.9650, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 48\n",
      "loss: tensor(0.9979, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 49\n",
      "loss: tensor(1.0120, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 50\n",
      "loss: tensor(0.9983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 51\n",
      "loss: tensor(1.0134, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 52\n",
      "loss: tensor(0.9990, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 53\n",
      "loss: tensor(0.9588, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 54\n",
      "loss: tensor(1.0171, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 55\n",
      "loss: tensor(0.9797, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 56\n",
      "loss: tensor(0.9931, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 57\n",
      "loss: tensor(0.9735, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 58\n",
      "loss: tensor(1.0031, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 59\n",
      "loss: tensor(0.9838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 60\n",
      "loss: tensor(1.0001, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 61\n",
      "loss: tensor(1.0002, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 62\n",
      "loss: tensor(1.0355, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 63\n",
      "loss: tensor(1.0375, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 64\n",
      "loss: tensor(1.0288, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 65\n",
      "loss: tensor(1.0172, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 66\n",
      "loss: tensor(0.9960, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 67\n",
      "loss: tensor(0.9896, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 68\n",
      "loss: tensor(0.9505, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 69\n",
      "loss: tensor(0.9826, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 70\n",
      "loss: tensor(0.9870, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 71\n",
      "loss: tensor(0.9738, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 72\n",
      "loss: tensor(0.9679, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 73\n",
      "loss: tensor(0.9555, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 74\n",
      "loss: tensor(0.9578, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 75\n",
      "loss: tensor(0.9729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 76\n",
      "loss: tensor(0.9592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 77\n",
      "loss: tensor(0.9734, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 78\n",
      "loss: tensor(0.9748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 79\n",
      "loss: tensor(0.9726, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 80\n",
      "loss: tensor(0.9831, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 81\n",
      "loss: tensor(1.0106, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 82\n",
      "loss: tensor(0.9987, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 83\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 84\n",
      "loss: tensor(0.9856, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 85\n",
      "loss: tensor(0.9643, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 86\n",
      "loss: tensor(1.0467, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 87\n",
      "loss: tensor(1.0567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 88\n",
      "loss: tensor(0.9848, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 89\n",
      "loss: tensor(0.9560, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 90\n",
      "loss: tensor(0.9851, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 91\n",
      "loss: tensor(0.9876, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 92\n",
      "loss: tensor(1.0670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 93\n",
      "loss: tensor(0.9471, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 94\n",
      "loss: tensor(0.9847, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 95\n",
      "loss: tensor(0.9775, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 96\n",
      "loss: tensor(0.9393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 97\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 98\n",
      "loss: tensor(1.0272, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 99\n",
      "loss: tensor(0.9474, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 0\n",
      "loss: tensor(0.9676, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 1\n",
      "loss: tensor(0.9865, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 2\n",
      "loss: tensor(0.9788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 3\n",
      "loss: tensor(0.9828, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 4\n",
      "loss: tensor(0.9911, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 5\n",
      "loss: tensor(0.9803, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 6\n",
      "loss: tensor(0.9939, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 7\n",
      "loss: tensor(0.9702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 8\n",
      "loss: tensor(1.0634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 9\n",
      "loss: tensor(0.9908, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 10\n",
      "loss: tensor(0.9681, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 11\n",
      "loss: tensor(1.0639, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 12\n",
      "loss: tensor(0.9443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 13\n",
      "loss: tensor(1.0003, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 14\n",
      "loss: tensor(1.0257, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 15\n",
      "loss: tensor(0.9708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 16\n",
      "loss: tensor(0.9953, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 17\n",
      "loss: tensor(0.9855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 18\n",
      "loss: tensor(0.9850, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 19\n",
      "loss: tensor(1.0057, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 20\n",
      "loss: tensor(0.9946, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 21\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 22\n",
      "loss: tensor(0.9443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 23\n",
      "loss: tensor(0.9841, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 24\n",
      "loss: tensor(0.9618, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 25\n",
      "loss: tensor(0.9572, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 26\n",
      "loss: tensor(0.9855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 27\n",
      "loss: tensor(0.9790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 28\n",
      "loss: tensor(0.9496, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 29\n",
      "loss: tensor(1.0208, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 30\n",
      "loss: tensor(0.9763, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 31\n",
      "loss: tensor(0.9469, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 32\n",
      "loss: tensor(0.9452, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 33\n",
      "loss: tensor(0.9993, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 34\n",
      "loss: tensor(0.9764, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 35\n",
      "loss: tensor(0.9673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 36\n",
      "loss: tensor(0.9600, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 37\n",
      "loss: tensor(1.0018, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 38\n",
      "loss: tensor(0.9706, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 39\n",
      "loss: tensor(0.9742, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 40\n",
      "loss: tensor(0.9417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 41\n",
      "loss: tensor(0.9742, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 42\n",
      "loss: tensor(0.9796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 43\n",
      "loss: tensor(0.9534, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 44\n",
      "loss: tensor(0.9716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 45\n",
      "loss: tensor(0.9426, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 46\n",
      "loss: tensor(0.9779, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 47\n",
      "loss: tensor(0.9719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 48\n",
      "loss: tensor(0.9662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 49\n",
      "loss: tensor(0.9697, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 50\n",
      "loss: tensor(0.9762, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 4 51\n",
      "loss: tensor(0.9510, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 52\n",
      "loss: tensor(0.9719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 53\n",
      "loss: tensor(0.9642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 54\n",
      "loss: tensor(1.0211, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 55\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 56\n",
      "loss: tensor(0.9956, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 57\n",
      "loss: tensor(0.9348, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 58\n",
      "loss: tensor(0.9675, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 59\n",
      "loss: tensor(1.0218, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 60\n",
      "loss: tensor(1.0162, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 61\n",
      "loss: tensor(0.9312, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 62\n",
      "loss: tensor(0.9994, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 63\n",
      "loss: tensor(0.9607, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 64\n",
      "loss: tensor(1.0059, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 65\n",
      "loss: tensor(0.9821, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 66\n",
      "loss: tensor(0.9532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 67\n",
      "loss: tensor(0.9610, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 68\n",
      "loss: tensor(0.9663, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 69\n",
      "loss: tensor(0.9531, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 70\n",
      "loss: tensor(0.9524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 71\n",
      "loss: tensor(0.9282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 72\n",
      "loss: tensor(1.0065, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 73\n",
      "loss: tensor(0.9624, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 74\n",
      "loss: tensor(0.9518, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 75\n",
      "loss: tensor(1.0324, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 76\n",
      "loss: tensor(0.9701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 77\n",
      "loss: tensor(0.9433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 78\n",
      "loss: tensor(1.0231, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 79\n",
      "loss: tensor(1.0141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 80\n",
      "loss: tensor(0.9417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 81\n",
      "loss: tensor(0.9943, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 82\n",
      "loss: tensor(1.0884, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 83\n",
      "loss: tensor(0.9197, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 84\n",
      "loss: tensor(0.9652, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 85\n",
      "loss: tensor(0.9733, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 86\n",
      "loss: tensor(0.9437, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 87\n",
      "loss: tensor(1.0445, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 88\n",
      "loss: tensor(0.9835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 89\n",
      "loss: tensor(0.9790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 90\n",
      "loss: tensor(0.9700, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 91\n",
      "loss: tensor(0.9714, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 92\n",
      "loss: tensor(0.9729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 93\n",
      "loss: tensor(0.9595, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 94\n",
      "loss: tensor(0.9515, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 95\n",
      "loss: tensor(1.0047, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 96\n",
      "loss: tensor(0.9723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 97\n",
      "loss: tensor(0.9179, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 98\n",
      "loss: tensor(0.9213, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 99\n",
      "loss: tensor(0.9700, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 0\n",
      "loss: tensor(0.9482, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 1\n",
      "loss: tensor(0.9537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 2\n",
      "loss: tensor(0.9635, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 3\n",
      "loss: tensor(0.9929, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 4\n",
      "loss: tensor(0.9491, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 5\n",
      "loss: tensor(1.0422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 6\n",
      "loss: tensor(0.9688, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 7\n",
      "loss: tensor(0.9295, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 8\n",
      "loss: tensor(0.9662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 9\n",
      "loss: tensor(0.9681, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 10\n",
      "loss: tensor(0.9648, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 11\n",
      "loss: tensor(0.9363, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 12\n",
      "loss: tensor(0.9984, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 13\n",
      "loss: tensor(0.9469, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 14\n",
      "loss: tensor(0.9723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 15\n",
      "loss: tensor(0.9674, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 16\n",
      "loss: tensor(0.9120, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 17\n",
      "loss: tensor(0.9515, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 18\n",
      "loss: tensor(0.9592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 19\n",
      "loss: tensor(0.9248, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 20\n",
      "loss: tensor(0.9682, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 21\n",
      "loss: tensor(1.0539, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 22\n",
      "loss: tensor(0.9388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 23\n",
      "loss: tensor(0.9524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 24\n",
      "loss: tensor(0.9671, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 25\n",
      "loss: tensor(0.9489, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 26\n",
      "loss: tensor(0.9574, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 27\n",
      "loss: tensor(0.9529, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 28\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 29\n",
      "loss: tensor(0.9433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 30\n",
      "loss: tensor(0.9155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 31\n",
      "loss: tensor(1.0065, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 32\n",
      "loss: tensor(0.9532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 33\n",
      "loss: tensor(0.9697, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 34\n",
      "loss: tensor(0.9730, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 35\n",
      "loss: tensor(0.9379, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 36\n",
      "loss: tensor(0.9716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 37\n",
      "loss: tensor(0.9273, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 38\n",
      "loss: tensor(0.9500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 39\n",
      "loss: tensor(0.9393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 40\n",
      "loss: tensor(0.9863, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 41\n",
      "loss: tensor(0.9529, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 42\n",
      "loss: tensor(0.9654, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 43\n",
      "loss: tensor(0.9581, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 44\n",
      "loss: tensor(0.9621, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 45\n",
      "loss: tensor(0.9133, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 46\n",
      "loss: tensor(0.9135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 47\n",
      "loss: tensor(1.0178, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 48\n",
      "loss: tensor(0.9971, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 49\n",
      "loss: tensor(0.9533, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 50\n",
      "loss: tensor(1.0123, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 51\n",
      "loss: tensor(0.9796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 52\n",
      "loss: tensor(0.9533, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 53\n",
      "loss: tensor(0.9184, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 54\n",
      "loss: tensor(0.9383, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 55\n",
      "loss: tensor(1.0121, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 56\n",
      "loss: tensor(0.9720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 57\n",
      "loss: tensor(1.0501, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 58\n",
      "loss: tensor(0.9561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 59\n",
      "loss: tensor(0.9470, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 60\n",
      "loss: tensor(0.9385, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 61\n",
      "loss: tensor(0.9063, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 62\n",
      "loss: tensor(0.9236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 63\n",
      "loss: tensor(0.9545, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 5 64\n",
      "loss: tensor(0.9505, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 65\n",
      "loss: tensor(0.9246, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 66\n",
      "loss: tensor(0.9595, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 67\n",
      "loss: tensor(0.9687, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 68\n",
      "loss: tensor(0.9302, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 69\n",
      "loss: tensor(0.9376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 70\n",
      "loss: tensor(0.9549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 71\n",
      "loss: tensor(0.9597, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 72\n",
      "loss: tensor(0.9546, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 73\n",
      "loss: tensor(0.9880, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 74\n",
      "loss: tensor(1.0053, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 75\n",
      "loss: tensor(0.9637, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 76\n",
      "loss: tensor(0.9796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 77\n",
      "loss: tensor(0.9294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 78\n",
      "loss: tensor(0.9597, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 79\n",
      "loss: tensor(0.9249, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 80\n",
      "loss: tensor(0.9485, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 81\n",
      "loss: tensor(1.0040, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 82\n",
      "loss: tensor(1.0236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 83\n",
      "loss: tensor(0.9544, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 84\n",
      "loss: tensor(0.9328, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 85\n",
      "loss: tensor(0.9573, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 86\n",
      "loss: tensor(0.9223, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 87\n",
      "loss: tensor(0.9713, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 88\n",
      "loss: tensor(0.9815, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 89\n",
      "loss: tensor(1.0838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 90\n",
      "loss: tensor(0.9563, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 91\n",
      "loss: tensor(0.9838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 92\n",
      "loss: tensor(0.9491, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 93\n",
      "loss: tensor(0.9124, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 94\n",
      "loss: tensor(0.9677, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 95\n",
      "loss: tensor(0.9654, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 96\n",
      "loss: tensor(0.9950, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 97\n",
      "loss: tensor(1.0000, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 98\n",
      "loss: tensor(0.9520, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 99\n",
      "loss: tensor(0.9377, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 0\n",
      "loss: tensor(0.9929, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 1\n",
      "loss: tensor(0.9757, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 2\n",
      "loss: tensor(0.9448, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 3\n",
      "loss: tensor(0.9360, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 4\n",
      "loss: tensor(0.9604, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 5\n",
      "loss: tensor(0.9986, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 6\n",
      "loss: tensor(1.0785, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 7\n",
      "loss: tensor(0.9412, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 8\n",
      "loss: tensor(1.0194, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 9\n",
      "loss: tensor(0.9286, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 10\n",
      "loss: tensor(0.9640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 11\n",
      "loss: tensor(0.9504, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 12\n",
      "loss: tensor(0.9337, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 13\n",
      "loss: tensor(0.9016, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 14\n",
      "loss: tensor(0.9168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 15\n",
      "loss: tensor(0.9422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 16\n",
      "loss: tensor(0.9512, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 17\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 18\n",
      "loss: tensor(0.9707, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 19\n",
      "loss: tensor(0.9088, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 20\n",
      "loss: tensor(0.9528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 21\n",
      "loss: tensor(0.9550, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 22\n",
      "loss: tensor(0.9161, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 23\n",
      "loss: tensor(0.9548, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 24\n",
      "loss: tensor(0.9395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 25\n",
      "loss: tensor(0.9203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 26\n",
      "loss: tensor(1.0324, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 27\n",
      "loss: tensor(0.9556, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 28\n",
      "loss: tensor(0.9372, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 29\n",
      "loss: tensor(0.9365, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 30\n",
      "loss: tensor(0.9524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 31\n",
      "loss: tensor(0.9414, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 32\n",
      "loss: tensor(0.9289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 33\n",
      "loss: tensor(0.9036, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 34\n",
      "loss: tensor(1.0028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 35\n",
      "loss: tensor(0.9156, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 36\n",
      "loss: tensor(0.9021, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 37\n",
      "loss: tensor(0.9271, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 38\n",
      "loss: tensor(0.9283, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 39\n",
      "loss: tensor(0.9114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 40\n",
      "loss: tensor(0.9528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 41\n",
      "loss: tensor(0.9465, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 42\n",
      "loss: tensor(0.9513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 43\n",
      "loss: tensor(0.9512, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 44\n",
      "loss: tensor(0.9545, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 45\n",
      "loss: tensor(0.9429, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 46\n",
      "loss: tensor(0.9447, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 47\n",
      "loss: tensor(0.9506, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 48\n",
      "loss: tensor(0.9994, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 49\n",
      "loss: tensor(0.9974, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 50\n",
      "loss: tensor(0.9168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 51\n",
      "loss: tensor(0.9797, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 52\n",
      "loss: tensor(0.9232, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 53\n",
      "loss: tensor(0.9550, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 54\n",
      "loss: tensor(0.9753, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 55\n",
      "loss: tensor(0.9298, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 56\n",
      "loss: tensor(0.9640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 57\n",
      "loss: tensor(0.9444, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 58\n",
      "loss: tensor(0.9452, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 59\n",
      "loss: tensor(0.9903, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 60\n",
      "loss: tensor(1.0053, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 61\n",
      "loss: tensor(0.9414, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 62\n",
      "loss: tensor(0.9137, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 63\n",
      "loss: tensor(0.9435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 64\n",
      "loss: tensor(0.9053, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 65\n",
      "loss: tensor(0.9037, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 66\n",
      "loss: tensor(0.9330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 67\n",
      "loss: tensor(0.9561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 68\n",
      "loss: tensor(0.9826, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 69\n",
      "loss: tensor(0.9771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 70\n",
      "loss: tensor(0.9561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 71\n",
      "loss: tensor(0.9411, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 72\n",
      "loss: tensor(0.9529, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 73\n",
      "loss: tensor(0.9488, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 74\n",
      "loss: tensor(0.9919, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 75\n",
      "loss: tensor(0.9591, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 76\n",
      "loss: tensor(0.9173, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 6 77\n",
      "loss: tensor(0.9549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 78\n",
      "loss: tensor(0.9259, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 79\n",
      "loss: tensor(0.9330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 80\n",
      "loss: tensor(0.9245, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 81\n",
      "loss: tensor(1.0423, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 82\n",
      "loss: tensor(0.9580, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 83\n",
      "loss: tensor(0.9608, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 84\n",
      "loss: tensor(0.8902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 85\n",
      "loss: tensor(0.9378, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 86\n",
      "loss: tensor(0.9383, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 87\n",
      "loss: tensor(0.9411, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 88\n",
      "loss: tensor(0.9470, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 89\n",
      "loss: tensor(0.9481, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 90\n",
      "loss: tensor(0.9257, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 91\n",
      "loss: tensor(1.0003, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 92\n",
      "loss: tensor(0.9730, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 93\n",
      "loss: tensor(0.9457, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 94\n",
      "loss: tensor(0.9740, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 95\n",
      "loss: tensor(0.9614, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 96\n",
      "loss: tensor(0.8964, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 97\n",
      "loss: tensor(1.0416, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 98\n",
      "loss: tensor(0.9282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 99\n",
      "loss: tensor(0.9362, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 0\n",
      "loss: tensor(1.0138, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 1\n",
      "loss: tensor(0.9719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 2\n",
      "loss: tensor(0.9500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 3\n",
      "loss: tensor(0.9241, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 4\n",
      "loss: tensor(0.9975, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 5\n",
      "loss: tensor(0.9507, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 6\n",
      "loss: tensor(0.9855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 7\n",
      "loss: tensor(0.9473, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 8\n",
      "loss: tensor(0.9500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 9\n",
      "loss: tensor(0.9540, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 10\n",
      "loss: tensor(0.9399, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 11\n",
      "loss: tensor(0.9632, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 12\n",
      "loss: tensor(1.0790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 13\n",
      "loss: tensor(0.9399, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 14\n",
      "loss: tensor(0.9082, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 15\n",
      "loss: tensor(0.9570, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 16\n",
      "loss: tensor(0.9919, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 17\n",
      "loss: tensor(0.9361, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 18\n",
      "loss: tensor(0.9737, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 19\n",
      "loss: tensor(0.9111, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 20\n",
      "loss: tensor(0.9244, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 21\n",
      "loss: tensor(0.9395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 22\n",
      "loss: tensor(0.9732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 23\n",
      "loss: tensor(0.9372, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 24\n",
      "loss: tensor(0.9686, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 25\n",
      "loss: tensor(1.0393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 26\n",
      "loss: tensor(0.9428, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 27\n",
      "loss: tensor(0.9229, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 28\n",
      "loss: tensor(0.9376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 29\n",
      "loss: tensor(0.9159, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 30\n",
      "loss: tensor(0.9376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 31\n",
      "loss: tensor(0.9258, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 32\n",
      "loss: tensor(0.9175, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 33\n",
      "loss: tensor(0.9528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 34\n",
      "loss: tensor(0.9763, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 35\n",
      "loss: tensor(0.9348, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 36\n",
      "loss: tensor(0.9325, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 37\n",
      "loss: tensor(0.9794, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 38\n",
      "loss: tensor(0.9176, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 39\n",
      "loss: tensor(0.9075, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 40\n",
      "loss: tensor(0.9063, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 41\n",
      "loss: tensor(0.8929, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 42\n",
      "loss: tensor(0.9998, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 43\n",
      "loss: tensor(0.9679, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 44\n",
      "loss: tensor(0.9396, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 45\n",
      "loss: tensor(0.9265, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 46\n",
      "loss: tensor(0.9901, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 47\n",
      "loss: tensor(0.9238, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 48\n",
      "loss: tensor(0.9414, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 49\n",
      "loss: tensor(0.8954, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 50\n",
      "loss: tensor(0.9345, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 51\n",
      "loss: tensor(0.9474, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 52\n",
      "loss: tensor(0.9561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 53\n",
      "loss: tensor(0.9465, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 54\n",
      "loss: tensor(0.9308, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 55\n",
      "loss: tensor(0.9034, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 56\n",
      "loss: tensor(0.9532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 57\n",
      "loss: tensor(0.8937, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 58\n",
      "loss: tensor(0.9368, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 59\n",
      "loss: tensor(0.9457, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 60\n",
      "loss: tensor(0.9513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 61\n",
      "loss: tensor(0.9303, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 62\n",
      "loss: tensor(0.8824, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 63\n",
      "loss: tensor(0.9417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 64\n",
      "loss: tensor(0.9882, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 65\n",
      "loss: tensor(0.9319, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 66\n",
      "loss: tensor(0.8906, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 67\n",
      "loss: tensor(1.0233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 68\n",
      "loss: tensor(0.9412, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 69\n",
      "loss: tensor(0.9926, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 70\n",
      "loss: tensor(0.9858, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 71\n",
      "loss: tensor(0.9247, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 72\n",
      "loss: tensor(0.9112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 73\n",
      "loss: tensor(0.9327, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 74\n",
      "loss: tensor(0.8948, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 75\n",
      "loss: tensor(0.9154, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 76\n",
      "loss: tensor(0.9395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 77\n",
      "loss: tensor(0.9425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 78\n",
      "loss: tensor(0.9218, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 79\n",
      "loss: tensor(0.9226, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 80\n",
      "loss: tensor(0.9027, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 81\n",
      "loss: tensor(0.9415, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 82\n",
      "loss: tensor(0.9228, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 83\n",
      "loss: tensor(0.9040, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 84\n",
      "loss: tensor(0.9251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 85\n",
      "loss: tensor(0.8801, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 86\n",
      "loss: tensor(0.9115, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 87\n",
      "loss: tensor(0.9540, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 88\n",
      "loss: tensor(0.9397, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 89\n",
      "loss: tensor(1.0372, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 7 90\n",
      "loss: tensor(0.9597, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 91\n",
      "loss: tensor(0.8881, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 92\n",
      "loss: tensor(0.9095, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 93\n",
      "loss: tensor(0.9395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 94\n",
      "loss: tensor(0.9136, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 95\n",
      "loss: tensor(0.9250, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 96\n",
      "loss: tensor(0.9384, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 97\n",
      "loss: tensor(0.9369, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 98\n",
      "loss: tensor(0.9141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 99\n",
      "loss: tensor(0.9389, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 0\n",
      "loss: tensor(0.9384, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 1\n",
      "loss: tensor(0.8894, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 2\n",
      "loss: tensor(0.9413, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 3\n",
      "loss: tensor(0.9387, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 4\n",
      "loss: tensor(0.9007, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 5\n",
      "loss: tensor(0.9413, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 6\n",
      "loss: tensor(0.9454, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 7\n",
      "loss: tensor(0.9720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 8\n",
      "loss: tensor(0.9068, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 9\n",
      "loss: tensor(0.9267, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 10\n",
      "loss: tensor(0.9309, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 11\n",
      "loss: tensor(0.8773, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 12\n",
      "loss: tensor(0.9074, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 13\n",
      "loss: tensor(0.8979, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 14\n",
      "loss: tensor(0.9855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 15\n",
      "loss: tensor(0.9354, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 16\n",
      "loss: tensor(0.9393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 17\n",
      "loss: tensor(0.9118, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 18\n",
      "loss: tensor(0.9069, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 19\n",
      "loss: tensor(0.9198, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 20\n",
      "loss: tensor(0.8990, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 21\n",
      "loss: tensor(0.9466, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 22\n",
      "loss: tensor(0.9572, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 23\n",
      "loss: tensor(0.9323, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 24\n",
      "loss: tensor(0.9346, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 25\n",
      "loss: tensor(0.9882, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 26\n",
      "loss: tensor(0.9103, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 27\n",
      "loss: tensor(0.9338, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 28\n",
      "loss: tensor(0.9278, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 29\n",
      "loss: tensor(0.9356, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 30\n",
      "loss: tensor(0.9018, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 31\n",
      "loss: tensor(0.9175, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 32\n",
      "loss: tensor(0.9461, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 33\n",
      "loss: tensor(0.9314, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 34\n",
      "loss: tensor(0.9080, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 35\n",
      "loss: tensor(0.9513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 36\n",
      "loss: tensor(0.9163, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 37\n",
      "loss: tensor(0.9364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 38\n",
      "loss: tensor(0.9179, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 39\n",
      "loss: tensor(0.9132, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 40\n",
      "loss: tensor(0.9969, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 41\n",
      "loss: tensor(0.8823, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 42\n",
      "loss: tensor(0.9264, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 43\n",
      "loss: tensor(0.9372, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 44\n",
      "loss: tensor(0.9287, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 45\n",
      "loss: tensor(1.0796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 46\n",
      "loss: tensor(0.9396, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 47\n",
      "loss: tensor(0.9282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 48\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 49\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 50\n",
      "loss: tensor(0.9478, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 51\n",
      "loss: tensor(0.9357, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 52\n",
      "loss: tensor(0.9070, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 53\n",
      "loss: tensor(0.9227, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 54\n",
      "loss: tensor(0.9209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 55\n",
      "loss: tensor(0.9090, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 56\n",
      "loss: tensor(0.9320, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 57\n",
      "loss: tensor(0.8824, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 58\n",
      "loss: tensor(0.9310, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 59\n",
      "loss: tensor(0.9654, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 60\n",
      "loss: tensor(0.9877, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 61\n",
      "loss: tensor(1.0051, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 62\n",
      "loss: tensor(0.9396, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 63\n",
      "loss: tensor(0.9486, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 64\n",
      "loss: tensor(0.8731, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 65\n",
      "loss: tensor(0.8954, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 66\n",
      "loss: tensor(0.9578, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 67\n",
      "loss: tensor(0.9166, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 68\n",
      "loss: tensor(0.9220, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 69\n",
      "loss: tensor(0.9355, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 70\n",
      "loss: tensor(0.9170, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 71\n",
      "loss: tensor(0.9836, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 72\n",
      "loss: tensor(0.9274, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 73\n",
      "loss: tensor(0.9044, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 74\n",
      "loss: tensor(1.0322, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 75\n",
      "loss: tensor(0.9330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 76\n",
      "loss: tensor(0.9789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 77\n",
      "loss: tensor(0.9317, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 78\n",
      "loss: tensor(0.9294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 79\n",
      "loss: tensor(0.9425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 80\n",
      "loss: tensor(0.9665, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 81\n",
      "loss: tensor(0.8944, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 82\n",
      "loss: tensor(0.9105, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 83\n",
      "loss: tensor(0.9870, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 84\n",
      "loss: tensor(0.8871, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 85\n",
      "loss: tensor(0.9560, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 86\n",
      "loss: tensor(0.9229, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 87\n",
      "loss: tensor(1.0169, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 88\n",
      "loss: tensor(0.9205, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 89\n",
      "loss: tensor(0.9341, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 90\n",
      "loss: tensor(0.9497, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 91\n",
      "loss: tensor(0.9789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 92\n",
      "loss: tensor(0.8963, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 93\n",
      "loss: tensor(0.8853, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 94\n",
      "loss: tensor(0.9081, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 95\n",
      "loss: tensor(1.0303, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 96\n",
      "loss: tensor(0.9127, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 97\n",
      "loss: tensor(0.9177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 98\n",
      "loss: tensor(0.8803, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 99\n",
      "loss: tensor(0.9680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 0\n",
      "loss: tensor(0.9138, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 1\n",
      "loss: tensor(0.9233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 2\n",
      "loss: tensor(0.9294, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 9 3\n",
      "loss: tensor(0.9235, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 4\n",
      "loss: tensor(0.9404, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 5\n",
      "loss: tensor(0.9316, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 6\n",
      "loss: tensor(0.9039, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 7\n",
      "loss: tensor(0.9359, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 8\n",
      "loss: tensor(0.9332, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 9\n",
      "loss: tensor(0.9092, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 10\n",
      "loss: tensor(0.8789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 11\n",
      "loss: tensor(0.8794, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 12\n",
      "loss: tensor(1.0722, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 13\n",
      "loss: tensor(0.9128, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 14\n",
      "loss: tensor(0.9152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 15\n",
      "loss: tensor(0.9777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 16\n",
      "loss: tensor(0.9590, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 17\n",
      "loss: tensor(0.9355, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 18\n",
      "loss: tensor(0.8902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 19\n",
      "loss: tensor(0.9642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 20\n",
      "loss: tensor(0.9259, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 21\n",
      "loss: tensor(0.9001, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 22\n",
      "loss: tensor(0.8976, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 23\n",
      "loss: tensor(0.9284, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 24\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 25\n",
      "loss: tensor(0.9444, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 26\n",
      "loss: tensor(0.8795, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 27\n",
      "loss: tensor(0.9234, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 28\n",
      "loss: tensor(0.9264, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 29\n",
      "loss: tensor(0.9015, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 30\n",
      "loss: tensor(1.0001, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 31\n",
      "loss: tensor(0.9171, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 32\n",
      "loss: tensor(0.9027, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 33\n",
      "loss: tensor(0.9541, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 34\n",
      "loss: tensor(0.9326, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 35\n",
      "loss: tensor(0.8711, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 36\n",
      "loss: tensor(0.9777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 37\n",
      "loss: tensor(0.9250, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 38\n",
      "loss: tensor(0.9173, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 39\n",
      "loss: tensor(0.9302, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 40\n",
      "loss: tensor(0.9297, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 41\n",
      "loss: tensor(0.9161, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 42\n",
      "loss: tensor(0.9823, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 43\n",
      "loss: tensor(0.9290, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 44\n",
      "loss: tensor(0.9638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 45\n",
      "loss: tensor(0.9713, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 46\n",
      "loss: tensor(0.9353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 47\n",
      "loss: tensor(0.9404, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 48\n",
      "loss: tensor(0.9282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 49\n",
      "loss: tensor(0.9436, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 50\n",
      "loss: tensor(0.8765, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 51\n",
      "loss: tensor(0.9477, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 52\n",
      "loss: tensor(0.8889, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 53\n",
      "loss: tensor(0.9231, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 54\n",
      "loss: tensor(0.9114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 55\n",
      "loss: tensor(0.9153, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 56\n",
      "loss: tensor(0.9303, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 57\n",
      "loss: tensor(0.9081, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 58\n",
      "loss: tensor(0.9135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 59\n",
      "loss: tensor(0.8944, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 60\n",
      "loss: tensor(0.9363, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 61\n",
      "loss: tensor(0.9199, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 62\n",
      "loss: tensor(0.9187, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 63\n",
      "loss: tensor(0.9887, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 64\n",
      "loss: tensor(0.9265, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 65\n",
      "loss: tensor(0.9013, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 66\n",
      "loss: tensor(0.9806, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 67\n",
      "loss: tensor(0.9034, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 68\n",
      "loss: tensor(0.9233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 69\n",
      "loss: tensor(0.9154, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 70\n",
      "loss: tensor(1.0282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 71\n",
      "loss: tensor(0.8989, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 72\n",
      "loss: tensor(0.8931, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 73\n",
      "loss: tensor(1.0143, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 74\n",
      "loss: tensor(0.8977, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 75\n",
      "loss: tensor(0.9483, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 76\n",
      "loss: tensor(0.8902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 77\n",
      "loss: tensor(0.9088, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 78\n",
      "loss: tensor(0.8903, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 79\n",
      "loss: tensor(0.8884, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 80\n",
      "loss: tensor(0.9053, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 81\n",
      "loss: tensor(0.9042, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 82\n",
      "loss: tensor(0.9353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 83\n",
      "loss: tensor(0.9185, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 84\n",
      "loss: tensor(0.8784, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 85\n",
      "loss: tensor(0.9226, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 86\n",
      "loss: tensor(1.0298, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 87\n",
      "loss: tensor(0.9112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 88\n",
      "loss: tensor(0.9782, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 89\n",
      "loss: tensor(0.8992, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 90\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 91\n",
      "loss: tensor(0.9186, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 92\n",
      "loss: tensor(0.8780, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 93\n",
      "loss: tensor(0.9774, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 94\n",
      "loss: tensor(0.8638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 95\n",
      "loss: tensor(0.9557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 96\n",
      "loss: tensor(0.9343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 97\n",
      "loss: tensor(0.9304, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 98\n",
      "loss: tensor(0.9320, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 99\n",
      "loss: tensor(0.9236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 0\n",
      "loss: tensor(0.9099, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 1\n",
      "loss: tensor(0.8729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 2\n",
      "loss: tensor(0.9004, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 3\n",
      "loss: tensor(0.9203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 4\n",
      "loss: tensor(0.9065, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 5\n",
      "loss: tensor(0.9185, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 6\n",
      "loss: tensor(0.8836, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 7\n",
      "loss: tensor(0.9074, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 8\n",
      "loss: tensor(0.9028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 9\n",
      "loss: tensor(0.9212, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 10\n",
      "loss: tensor(0.8847, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 11\n",
      "loss: tensor(1.0290, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 12\n",
      "loss: tensor(0.8883, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 13\n",
      "loss: tensor(0.9605, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 14\n",
      "loss: tensor(0.8624, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9196, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 16\n",
      "loss: tensor(0.9464, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 17\n",
      "loss: tensor(0.9272, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 18\n",
      "loss: tensor(0.8970, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 19\n",
      "loss: tensor(0.9046, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 20\n",
      "loss: tensor(0.9855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 21\n",
      "loss: tensor(0.9085, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 22\n",
      "loss: tensor(0.9556, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 23\n",
      "loss: tensor(0.8956, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 24\n",
      "loss: tensor(0.9138, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 25\n",
      "loss: tensor(0.9152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 26\n",
      "loss: tensor(0.8719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 27\n",
      "loss: tensor(0.9112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 28\n",
      "loss: tensor(0.9322, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 29\n",
      "loss: tensor(0.9140, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 30\n",
      "loss: tensor(0.8737, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 31\n",
      "loss: tensor(0.9015, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 32\n",
      "loss: tensor(0.9008, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 33\n",
      "loss: tensor(0.9208, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 34\n",
      "loss: tensor(0.9988, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 35\n",
      "loss: tensor(0.9442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 36\n",
      "loss: tensor(1.0104, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 37\n",
      "loss: tensor(0.8880, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 38\n",
      "loss: tensor(0.9187, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 39\n",
      "loss: tensor(0.9216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 40\n",
      "loss: tensor(0.9127, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 41\n",
      "loss: tensor(0.9414, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 42\n",
      "loss: tensor(0.9108, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 43\n",
      "loss: tensor(1.0675, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 44\n",
      "loss: tensor(0.9190, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 45\n",
      "loss: tensor(0.9146, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 46\n",
      "loss: tensor(0.8933, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 47\n",
      "loss: tensor(0.9237, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 48\n",
      "loss: tensor(0.9315, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 49\n",
      "loss: tensor(0.9722, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 50\n",
      "loss: tensor(0.9268, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 51\n",
      "loss: tensor(0.9045, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 52\n",
      "loss: tensor(0.9209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 53\n",
      "loss: tensor(0.9281, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 54\n",
      "loss: tensor(0.8853, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 55\n",
      "loss: tensor(0.9233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 56\n",
      "loss: tensor(0.9295, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 57\n",
      "loss: tensor(0.9780, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 58\n",
      "loss: tensor(0.9517, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 59\n",
      "loss: tensor(0.9042, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 60\n",
      "loss: tensor(0.8875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 61\n",
      "loss: tensor(1.0251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 62\n",
      "loss: tensor(0.9202, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 63\n",
      "loss: tensor(0.9064, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 64\n",
      "loss: tensor(0.9130, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 65\n",
      "loss: tensor(0.9168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 66\n",
      "loss: tensor(0.9339, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 67\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 68\n",
      "loss: tensor(0.8912, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 69\n",
      "loss: tensor(0.8950, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 70\n",
      "loss: tensor(0.9209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 71\n",
      "loss: tensor(0.9661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 72\n",
      "loss: tensor(0.9190, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 73\n",
      "loss: tensor(0.8937, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 74\n",
      "loss: tensor(0.9171, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 75\n",
      "loss: tensor(0.8933, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 76\n",
      "loss: tensor(0.9282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 77\n",
      "loss: tensor(0.9494, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 78\n",
      "loss: tensor(0.9192, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 79\n",
      "loss: tensor(0.9753, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 80\n",
      "loss: tensor(0.9655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 81\n",
      "loss: tensor(0.9057, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 82\n",
      "loss: tensor(0.9472, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 83\n",
      "loss: tensor(0.9067, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 84\n",
      "loss: tensor(0.9101, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 85\n",
      "loss: tensor(0.8684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 86\n",
      "loss: tensor(0.9312, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 87\n",
      "loss: tensor(0.8812, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 88\n",
      "loss: tensor(0.9115, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 89\n",
      "loss: tensor(0.9366, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 90\n",
      "loss: tensor(0.8980, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 91\n",
      "loss: tensor(0.8655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 92\n",
      "loss: tensor(0.8820, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 93\n",
      "loss: tensor(0.9719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 94\n",
      "loss: tensor(0.9743, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 95\n",
      "loss: tensor(0.9197, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 96\n",
      "loss: tensor(0.8716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 97\n",
      "loss: tensor(0.9289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 98\n",
      "loss: tensor(0.8758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 99\n",
      "loss: tensor(0.9270, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 0\n",
      "loss: tensor(0.9705, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 1\n",
      "loss: tensor(0.9007, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 2\n",
      "loss: tensor(0.8907, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 3\n",
      "loss: tensor(0.9155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 4\n",
      "loss: tensor(0.9223, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 5\n",
      "loss: tensor(0.9281, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 6\n",
      "loss: tensor(0.9121, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 7\n",
      "loss: tensor(0.8961, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 8\n",
      "loss: tensor(0.8923, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 9\n",
      "loss: tensor(0.9251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 10\n",
      "loss: tensor(0.9287, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 11\n",
      "loss: tensor(0.9477, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 12\n",
      "loss: tensor(0.8796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 13\n",
      "loss: tensor(0.9149, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 14\n",
      "loss: tensor(0.9075, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 15\n",
      "loss: tensor(0.9002, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 16\n",
      "loss: tensor(0.8931, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 17\n",
      "loss: tensor(0.8881, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 18\n",
      "loss: tensor(0.9089, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 19\n",
      "loss: tensor(0.9048, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 20\n",
      "loss: tensor(0.8655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 21\n",
      "loss: tensor(0.9387, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 22\n",
      "loss: tensor(0.9725, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 23\n",
      "loss: tensor(0.8797, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 24\n",
      "loss: tensor(0.9060, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 25\n",
      "loss: tensor(0.8883, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 27\n",
      "loss: tensor(0.9114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 28\n",
      "loss: tensor(0.9142, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 29\n",
      "loss: tensor(0.9510, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 30\n",
      "loss: tensor(0.9306, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 31\n",
      "loss: tensor(0.8822, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 32\n",
      "loss: tensor(0.9110, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 33\n",
      "loss: tensor(0.9042, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 34\n",
      "loss: tensor(0.9108, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 35\n",
      "loss: tensor(0.9274, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 36\n",
      "loss: tensor(0.9717, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 37\n",
      "loss: tensor(0.9017, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 38\n",
      "loss: tensor(0.9175, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 39\n",
      "loss: tensor(0.9309, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 40\n",
      "loss: tensor(0.8657, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 41\n",
      "loss: tensor(0.9135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 42\n",
      "loss: tensor(0.9885, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 43\n",
      "loss: tensor(0.8827, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 44\n",
      "loss: tensor(0.9678, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 45\n",
      "loss: tensor(0.9044, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 46\n",
      "loss: tensor(0.9216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 47\n",
      "loss: tensor(1.0691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 48\n",
      "loss: tensor(0.9028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 49\n",
      "loss: tensor(0.8800, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 50\n",
      "loss: tensor(0.8786, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 51\n",
      "loss: tensor(0.9129, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 52\n",
      "loss: tensor(0.9177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 53\n",
      "loss: tensor(0.8999, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 54\n",
      "loss: tensor(0.8683, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 55\n",
      "loss: tensor(0.9577, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 56\n",
      "loss: tensor(0.9168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 57\n",
      "loss: tensor(0.9040, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 58\n",
      "loss: tensor(0.8864, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 59\n",
      "loss: tensor(1.0167, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 60\n",
      "loss: tensor(0.8825, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 61\n",
      "loss: tensor(0.9189, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 62\n",
      "loss: tensor(0.9150, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 63\n",
      "loss: tensor(0.9558, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 64\n",
      "loss: tensor(0.9085, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 65\n",
      "loss: tensor(0.9385, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 66\n",
      "loss: tensor(0.9117, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 67\n",
      "loss: tensor(0.9150, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 68\n",
      "loss: tensor(0.8884, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 69\n",
      "loss: tensor(0.8711, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 70\n",
      "loss: tensor(0.9488, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 71\n",
      "loss: tensor(0.9140, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 72\n",
      "loss: tensor(0.9073, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 73\n",
      "loss: tensor(0.8720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 74\n",
      "loss: tensor(0.9342, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 75\n",
      "loss: tensor(0.8637, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 76\n",
      "loss: tensor(1.0011, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 77\n",
      "loss: tensor(0.8607, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 78\n",
      "loss: tensor(0.8835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 79\n",
      "loss: tensor(0.9103, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 80\n",
      "loss: tensor(0.8971, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 81\n",
      "loss: tensor(0.8992, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 82\n",
      "loss: tensor(0.9715, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 83\n",
      "loss: tensor(0.9200, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 84\n",
      "loss: tensor(0.9101, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 85\n",
      "loss: tensor(1.0123, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 86\n",
      "loss: tensor(0.9067, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 87\n",
      "loss: tensor(0.9209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 88\n",
      "loss: tensor(0.9209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 89\n",
      "loss: tensor(0.8956, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 90\n",
      "loss: tensor(0.8992, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 91\n",
      "loss: tensor(0.9427, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 92\n",
      "loss: tensor(0.9132, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 93\n",
      "loss: tensor(0.8747, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 94\n",
      "loss: tensor(0.9313, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 95\n",
      "loss: tensor(0.8883, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 96\n",
      "loss: tensor(0.8550, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 97\n",
      "loss: tensor(0.8967, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 98\n",
      "loss: tensor(0.9085, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 99\n",
      "loss: tensor(0.9155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 0\n",
      "loss: tensor(0.9670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 1\n",
      "loss: tensor(0.9093, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 2\n",
      "loss: tensor(0.8964, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 3\n",
      "loss: tensor(0.9132, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 4\n",
      "loss: tensor(0.9875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 5\n",
      "loss: tensor(0.8513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 6\n",
      "loss: tensor(0.9039, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 7\n",
      "loss: tensor(0.9099, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 8\n",
      "loss: tensor(0.8977, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 9\n",
      "loss: tensor(0.8942, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 10\n",
      "loss: tensor(0.9037, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 11\n",
      "loss: tensor(1.0015, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 12\n",
      "loss: tensor(0.8651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 13\n",
      "loss: tensor(0.8980, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 14\n",
      "loss: tensor(0.9198, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 15\n",
      "loss: tensor(0.9704, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 16\n",
      "loss: tensor(0.9077, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 17\n",
      "loss: tensor(0.9073, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 18\n",
      "loss: tensor(1.0126, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 19\n",
      "loss: tensor(0.9047, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 20\n",
      "loss: tensor(0.9094, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 21\n",
      "loss: tensor(0.9251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 22\n",
      "loss: tensor(0.9534, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 23\n",
      "loss: tensor(0.8718, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 24\n",
      "loss: tensor(0.9012, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 25\n",
      "loss: tensor(0.9434, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 26\n",
      "loss: tensor(0.9226, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 27\n",
      "loss: tensor(0.9002, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 28\n",
      "loss: tensor(0.8742, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 29\n",
      "loss: tensor(0.9695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 30\n",
      "loss: tensor(0.9064, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 31\n",
      "loss: tensor(0.8731, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 32\n",
      "loss: tensor(0.9285, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 33\n",
      "loss: tensor(0.8756, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 34\n",
      "loss: tensor(0.8661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 35\n",
      "loss: tensor(0.8621, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 36\n",
      "loss: tensor(0.9160, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9378, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 38\n",
      "loss: tensor(0.8824, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 39\n",
      "loss: tensor(1.0590, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 40\n",
      "loss: tensor(0.8820, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 41\n",
      "loss: tensor(0.9092, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 42\n",
      "loss: tensor(0.9010, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 43\n",
      "loss: tensor(0.9609, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 44\n",
      "loss: tensor(0.8789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 45\n",
      "loss: tensor(0.9186, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 46\n",
      "loss: tensor(0.8960, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 47\n",
      "loss: tensor(0.9101, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 48\n",
      "loss: tensor(0.8953, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 49\n",
      "loss: tensor(0.9276, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 50\n",
      "loss: tensor(0.9049, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 51\n",
      "loss: tensor(0.8991, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 52\n",
      "loss: tensor(0.9261, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 53\n",
      "loss: tensor(0.9106, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 54\n",
      "loss: tensor(0.9068, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 55\n",
      "loss: tensor(0.9168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 56\n",
      "loss: tensor(0.8914, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 57\n",
      "loss: tensor(0.8813, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 58\n",
      "loss: tensor(0.9010, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 59\n",
      "loss: tensor(0.8716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 60\n",
      "loss: tensor(1.0121, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 61\n",
      "loss: tensor(0.9402, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 62\n",
      "loss: tensor(0.8732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 63\n",
      "loss: tensor(0.9267, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 64\n",
      "loss: tensor(0.8869, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 65\n",
      "loss: tensor(0.9115, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 66\n",
      "loss: tensor(0.8594, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 67\n",
      "loss: tensor(0.8851, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 68\n",
      "loss: tensor(0.8839, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 69\n",
      "loss: tensor(0.8980, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 70\n",
      "loss: tensor(0.9064, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 71\n",
      "loss: tensor(0.9033, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 72\n",
      "loss: tensor(0.9701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 73\n",
      "loss: tensor(0.9532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 74\n",
      "loss: tensor(0.8817, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 75\n",
      "loss: tensor(0.9645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 76\n",
      "loss: tensor(0.9123, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 77\n",
      "loss: tensor(0.8799, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 78\n",
      "loss: tensor(0.8897, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 79\n",
      "loss: tensor(0.9054, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 80\n",
      "loss: tensor(0.8960, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 81\n",
      "loss: tensor(0.8993, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 82\n",
      "loss: tensor(0.8831, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 83\n",
      "loss: tensor(0.9152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 84\n",
      "loss: tensor(0.9128, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 85\n",
      "loss: tensor(0.8686, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 86\n",
      "loss: tensor(0.9370, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 87\n",
      "loss: tensor(0.8887, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 88\n",
      "loss: tensor(0.8803, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 89\n",
      "loss: tensor(0.9343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 90\n",
      "loss: tensor(0.8989, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 91\n",
      "loss: tensor(0.8910, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 92\n",
      "loss: tensor(0.9129, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 93\n",
      "loss: tensor(0.8993, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 94\n",
      "loss: tensor(0.9047, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 95\n",
      "loss: tensor(0.8598, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 96\n",
      "loss: tensor(0.9073, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 97\n",
      "loss: tensor(0.8945, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 98\n",
      "loss: tensor(0.8552, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 99\n",
      "loss: tensor(0.8839, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 0\n",
      "loss: tensor(0.8643, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 1\n",
      "loss: tensor(0.8558, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 2\n",
      "loss: tensor(0.8768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 3\n",
      "loss: tensor(0.9027, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 4\n",
      "loss: tensor(0.8923, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 5\n",
      "loss: tensor(0.8895, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 6\n",
      "loss: tensor(0.8842, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 7\n",
      "loss: tensor(0.8701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 8\n",
      "loss: tensor(0.9143, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 9\n",
      "loss: tensor(0.8798, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 10\n",
      "loss: tensor(0.9669, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 11\n",
      "loss: tensor(0.9227, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 12\n",
      "loss: tensor(0.9353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 13\n",
      "loss: tensor(0.9299, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 14\n",
      "loss: tensor(0.8942, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 15\n",
      "loss: tensor(0.8994, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 16\n",
      "loss: tensor(0.8780, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 17\n",
      "loss: tensor(0.8995, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 18\n",
      "loss: tensor(0.8781, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 19\n",
      "loss: tensor(0.8977, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 20\n",
      "loss: tensor(0.9318, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 21\n",
      "loss: tensor(0.9033, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 22\n",
      "loss: tensor(0.9119, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 23\n",
      "loss: tensor(0.8939, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 24\n",
      "loss: tensor(0.9230, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 25\n",
      "loss: tensor(0.8734, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 26\n",
      "loss: tensor(0.8944, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 27\n",
      "loss: tensor(0.9042, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 28\n",
      "loss: tensor(0.8855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 29\n",
      "loss: tensor(0.9606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 30\n",
      "loss: tensor(0.9367, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 31\n",
      "loss: tensor(0.9149, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 32\n",
      "loss: tensor(0.9009, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 33\n",
      "loss: tensor(0.8867, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 34\n",
      "loss: tensor(0.9198, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 35\n",
      "loss: tensor(0.8822, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 36\n",
      "loss: tensor(0.9095, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 37\n",
      "loss: tensor(0.8932, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 38\n",
      "loss: tensor(0.9346, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 39\n",
      "loss: tensor(0.8852, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 40\n",
      "loss: tensor(0.9141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 41\n",
      "loss: tensor(0.8996, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 42\n",
      "loss: tensor(0.8924, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 43\n",
      "loss: tensor(0.9064, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 44\n",
      "loss: tensor(0.9040, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 45\n",
      "loss: tensor(1.0061, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 46\n",
      "loss: tensor(0.8626, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 47\n",
      "loss: tensor(0.8868, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9170, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 49\n",
      "loss: tensor(0.9617, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 50\n",
      "loss: tensor(0.9208, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 51\n",
      "loss: tensor(0.8562, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 52\n",
      "loss: tensor(0.9015, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 53\n",
      "loss: tensor(0.8924, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 54\n",
      "loss: tensor(0.8999, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 55\n",
      "loss: tensor(0.8869, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 56\n",
      "loss: tensor(0.8984, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 57\n",
      "loss: tensor(0.9470, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 58\n",
      "loss: tensor(0.8902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 59\n",
      "loss: tensor(0.9746, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 60\n",
      "loss: tensor(0.8804, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 61\n",
      "loss: tensor(0.9534, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 62\n",
      "loss: tensor(0.8833, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 63\n",
      "loss: tensor(0.9081, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 64\n",
      "loss: tensor(0.8799, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 65\n",
      "loss: tensor(1.0510, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 66\n",
      "loss: tensor(0.8480, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 67\n",
      "loss: tensor(0.8987, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 68\n",
      "loss: tensor(0.8574, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 69\n",
      "loss: tensor(0.8989, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 70\n",
      "loss: tensor(0.8926, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 71\n",
      "loss: tensor(0.9862, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 72\n",
      "loss: tensor(0.9557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 73\n",
      "loss: tensor(0.8915, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 74\n",
      "loss: tensor(0.8932, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 75\n",
      "loss: tensor(0.8618, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 76\n",
      "loss: tensor(0.9518, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 77\n",
      "loss: tensor(0.8698, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 78\n",
      "loss: tensor(0.8959, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 79\n",
      "loss: tensor(0.9051, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 80\n",
      "loss: tensor(0.8743, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 81\n",
      "loss: tensor(0.9052, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 82\n",
      "loss: tensor(0.8664, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 83\n",
      "loss: tensor(0.8645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 84\n",
      "loss: tensor(0.8997, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 85\n",
      "loss: tensor(0.8758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 86\n",
      "loss: tensor(0.8660, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 87\n",
      "loss: tensor(0.8998, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 88\n",
      "loss: tensor(0.8848, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 89\n",
      "loss: tensor(0.8981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 90\n",
      "loss: tensor(0.8492, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 91\n",
      "loss: tensor(0.8696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 92\n",
      "loss: tensor(0.8838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 93\n",
      "loss: tensor(0.8845, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 94\n",
      "loss: tensor(0.8811, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 95\n",
      "loss: tensor(0.9443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 96\n",
      "loss: tensor(0.8848, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 97\n",
      "loss: tensor(0.9190, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 98\n",
      "loss: tensor(1.0031, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 99\n",
      "loss: tensor(0.9052, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 0\n",
      "loss: tensor(0.9172, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 1\n",
      "loss: tensor(0.8589, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 2\n",
      "loss: tensor(0.8825, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 3\n",
      "loss: tensor(0.9277, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 4\n",
      "loss: tensor(0.8802, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 5\n",
      "loss: tensor(0.8576, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 6\n",
      "loss: tensor(0.8960, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 7\n",
      "loss: tensor(0.9456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 8\n",
      "loss: tensor(0.8982, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 9\n",
      "loss: tensor(0.8758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 10\n",
      "loss: tensor(0.9004, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 11\n",
      "loss: tensor(0.9008, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 12\n",
      "loss: tensor(0.9092, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 13\n",
      "loss: tensor(0.8987, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 14\n",
      "loss: tensor(0.8861, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 15\n",
      "loss: tensor(0.8882, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 16\n",
      "loss: tensor(0.9214, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 17\n",
      "loss: tensor(0.8716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 18\n",
      "loss: tensor(0.8702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 19\n",
      "loss: tensor(0.8405, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 20\n",
      "loss: tensor(0.9008, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 21\n",
      "loss: tensor(0.9518, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 22\n",
      "loss: tensor(0.9989, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 23\n",
      "loss: tensor(0.9572, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 24\n",
      "loss: tensor(0.9148, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 25\n",
      "loss: tensor(0.9045, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 26\n",
      "loss: tensor(0.8654, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 27\n",
      "loss: tensor(0.8924, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 28\n",
      "loss: tensor(0.8711, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 29\n",
      "loss: tensor(0.9972, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 30\n",
      "loss: tensor(0.8793, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 31\n",
      "loss: tensor(0.8830, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 32\n",
      "loss: tensor(0.8820, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 33\n",
      "loss: tensor(0.8855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 34\n",
      "loss: tensor(0.8835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 35\n",
      "loss: tensor(0.8688, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 36\n",
      "loss: tensor(0.8758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 37\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 38\n",
      "loss: tensor(0.9006, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 39\n",
      "loss: tensor(0.9017, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 40\n",
      "loss: tensor(0.8606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 41\n",
      "loss: tensor(0.8983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 42\n",
      "loss: tensor(0.9379, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 43\n",
      "loss: tensor(0.8903, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 44\n",
      "loss: tensor(0.8990, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 45\n",
      "loss: tensor(0.8936, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 46\n",
      "loss: tensor(0.8495, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 47\n",
      "loss: tensor(0.9090, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 48\n",
      "loss: tensor(0.8689, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 49\n",
      "loss: tensor(0.8736, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 50\n",
      "loss: tensor(0.8890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 51\n",
      "loss: tensor(0.9491, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 52\n",
      "loss: tensor(0.9234, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 53\n",
      "loss: tensor(0.8518, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 54\n",
      "loss: tensor(0.8951, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 55\n",
      "loss: tensor(0.8836, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 56\n",
      "loss: tensor(0.8849, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 57\n",
      "loss: tensor(0.8759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 58\n",
      "loss: tensor(0.8894, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9778, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 60\n",
      "loss: tensor(0.8858, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 61\n",
      "loss: tensor(0.8511, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 62\n",
      "loss: tensor(0.9432, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 63\n",
      "loss: tensor(0.8995, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 64\n",
      "loss: tensor(0.8863, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 65\n",
      "loss: tensor(0.8658, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 66\n",
      "loss: tensor(0.8585, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 67\n",
      "loss: tensor(0.8843, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 68\n",
      "loss: tensor(0.8962, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 69\n",
      "loss: tensor(0.8876, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 70\n",
      "loss: tensor(0.8998, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 71\n",
      "loss: tensor(0.8852, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 72\n",
      "loss: tensor(1.0448, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 73\n",
      "loss: tensor(0.8842, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 74\n",
      "loss: tensor(0.8694, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 75\n",
      "loss: tensor(0.8673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 76\n",
      "loss: tensor(0.8716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 77\n",
      "loss: tensor(0.9531, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 78\n",
      "loss: tensor(0.8740, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 79\n",
      "loss: tensor(0.8905, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 80\n",
      "loss: tensor(0.8772, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 81\n",
      "loss: tensor(0.8862, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 82\n",
      "loss: tensor(0.9242, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 83\n",
      "loss: tensor(0.9089, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 84\n",
      "loss: tensor(0.8967, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 85\n",
      "loss: tensor(0.9508, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 86\n",
      "loss: tensor(0.8922, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 87\n",
      "loss: tensor(0.8950, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 88\n",
      "loss: tensor(0.8520, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 89\n",
      "loss: tensor(0.8776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 90\n",
      "loss: tensor(0.8813, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 91\n",
      "loss: tensor(0.8935, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 92\n",
      "loss: tensor(0.8768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 93\n",
      "loss: tensor(0.8840, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 94\n",
      "loss: tensor(0.9112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 95\n",
      "loss: tensor(0.8601, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 96\n",
      "loss: tensor(0.8611, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 97\n",
      "loss: tensor(0.8806, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 98\n",
      "loss: tensor(0.9003, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 99\n",
      "loss: tensor(0.9636, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 0\n",
      "loss: tensor(0.8966, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 1\n",
      "loss: tensor(0.9938, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 2\n",
      "loss: tensor(0.8716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 3\n",
      "loss: tensor(0.8796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 4\n",
      "loss: tensor(0.8902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 5\n",
      "loss: tensor(0.8938, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 6\n",
      "loss: tensor(0.9491, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 7\n",
      "loss: tensor(0.9014, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 8\n",
      "loss: tensor(0.8840, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 9\n",
      "loss: tensor(0.8613, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 10\n",
      "loss: tensor(0.8551, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 11\n",
      "loss: tensor(0.8712, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 12\n",
      "loss: tensor(0.8878, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 13\n",
      "loss: tensor(1.0368, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 14\n",
      "loss: tensor(0.8979, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 15\n",
      "loss: tensor(0.8849, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 16\n",
      "loss: tensor(0.8847, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 17\n",
      "loss: tensor(0.9036, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 18\n",
      "loss: tensor(0.9592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 19\n",
      "loss: tensor(0.8634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 20\n",
      "loss: tensor(0.8728, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 21\n",
      "loss: tensor(0.8873, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 22\n",
      "loss: tensor(0.9734, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 23\n",
      "loss: tensor(0.9398, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 24\n",
      "loss: tensor(0.8858, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 25\n",
      "loss: tensor(0.8752, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 26\n",
      "loss: tensor(0.8937, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 27\n",
      "loss: tensor(0.9167, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 28\n",
      "loss: tensor(0.9010, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 29\n",
      "loss: tensor(0.8910, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 30\n",
      "loss: tensor(0.8738, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 31\n",
      "loss: tensor(0.8602, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 32\n",
      "loss: tensor(0.8670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 33\n",
      "loss: tensor(0.8846, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 34\n",
      "loss: tensor(0.9395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 35\n",
      "loss: tensor(0.8811, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 36\n",
      "loss: tensor(0.8703, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 37\n",
      "loss: tensor(0.8894, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 38\n",
      "loss: tensor(0.8662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 39\n",
      "loss: tensor(0.8890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 40\n",
      "loss: tensor(0.9000, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 41\n",
      "loss: tensor(0.9028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 42\n",
      "loss: tensor(0.9284, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 43\n",
      "loss: tensor(0.8662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 44\n",
      "loss: tensor(0.9038, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 45\n",
      "loss: tensor(0.8989, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 46\n",
      "loss: tensor(0.8516, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 47\n",
      "loss: tensor(0.8900, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 48\n",
      "loss: tensor(0.8759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 49\n",
      "loss: tensor(0.8448, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 50\n",
      "loss: tensor(0.8912, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 51\n",
      "loss: tensor(0.8528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 52\n",
      "loss: tensor(0.8717, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 53\n",
      "loss: tensor(0.8789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 54\n",
      "loss: tensor(0.9302, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 55\n",
      "loss: tensor(0.9506, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 56\n",
      "loss: tensor(0.8707, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 57\n",
      "loss: tensor(0.8793, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 58\n",
      "loss: tensor(0.8449, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 59\n",
      "loss: tensor(0.8855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 60\n",
      "loss: tensor(0.8759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 61\n",
      "loss: tensor(0.9048, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 62\n",
      "loss: tensor(0.8745, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 63\n",
      "loss: tensor(0.8593, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 64\n",
      "loss: tensor(0.8835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 65\n",
      "loss: tensor(0.8722, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 66\n",
      "loss: tensor(0.8772, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 67\n",
      "loss: tensor(0.8667, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 68\n",
      "loss: tensor(0.8662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 69\n",
      "loss: tensor(0.8524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9881, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 71\n",
      "loss: tensor(0.9382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 72\n",
      "loss: tensor(0.8633, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 73\n",
      "loss: tensor(0.9073, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 74\n",
      "loss: tensor(0.8750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 75\n",
      "loss: tensor(0.9200, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 76\n",
      "loss: tensor(0.8674, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 77\n",
      "loss: tensor(0.8890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 78\n",
      "loss: tensor(0.9375, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 79\n",
      "loss: tensor(0.8668, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 80\n",
      "loss: tensor(0.8905, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 81\n",
      "loss: tensor(0.8828, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 82\n",
      "loss: tensor(0.8775, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 83\n",
      "loss: tensor(0.8502, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 84\n",
      "loss: tensor(0.9110, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 85\n",
      "loss: tensor(0.8519, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 86\n",
      "loss: tensor(0.9147, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 87\n",
      "loss: tensor(0.9058, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 88\n",
      "loss: tensor(0.8591, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 89\n",
      "loss: tensor(0.8746, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 90\n",
      "loss: tensor(0.8601, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 91\n",
      "loss: tensor(0.8849, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 92\n",
      "loss: tensor(0.9126, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 93\n",
      "loss: tensor(0.8393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 94\n",
      "loss: tensor(0.8604, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 95\n",
      "loss: tensor(0.8565, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 96\n",
      "loss: tensor(0.8715, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 97\n",
      "loss: tensor(0.8330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 98\n",
      "loss: tensor(0.8608, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 99\n",
      "loss: tensor(0.8723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 0\n",
      "loss: tensor(0.9679, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 1\n",
      "loss: tensor(0.8418, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 2\n",
      "loss: tensor(0.8785, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 3\n",
      "loss: tensor(0.8561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 4\n",
      "loss: tensor(0.8935, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 5\n",
      "loss: tensor(0.8817, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 6\n",
      "loss: tensor(0.8537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 7\n",
      "loss: tensor(0.8990, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 8\n",
      "loss: tensor(0.8867, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 9\n",
      "loss: tensor(0.8709, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 10\n",
      "loss: tensor(0.8589, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 11\n",
      "loss: tensor(0.9105, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 12\n",
      "loss: tensor(0.8684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 13\n",
      "loss: tensor(0.8623, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 14\n",
      "loss: tensor(0.8952, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 15\n",
      "loss: tensor(0.8744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 16\n",
      "loss: tensor(0.8481, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 17\n",
      "loss: tensor(0.9239, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 18\n",
      "loss: tensor(0.8537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 19\n",
      "loss: tensor(0.8655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 20\n",
      "loss: tensor(0.9036, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 21\n",
      "loss: tensor(0.8817, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 22\n",
      "loss: tensor(0.8783, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 23\n",
      "loss: tensor(0.9406, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 24\n",
      "loss: tensor(0.8788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 25\n",
      "loss: tensor(0.8834, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 26\n",
      "loss: tensor(0.8776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 27\n",
      "loss: tensor(0.8473, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 28\n",
      "loss: tensor(0.9041, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 29\n",
      "loss: tensor(0.8617, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 30\n",
      "loss: tensor(0.8786, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 31\n",
      "loss: tensor(0.8680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 32\n",
      "loss: tensor(0.9302, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 33\n",
      "loss: tensor(0.9054, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 34\n",
      "loss: tensor(0.8892, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 35\n",
      "loss: tensor(0.8820, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 36\n",
      "loss: tensor(0.9399, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 37\n",
      "loss: tensor(0.8724, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 38\n",
      "loss: tensor(0.8689, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 39\n",
      "loss: tensor(0.8862, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 40\n",
      "loss: tensor(0.8691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 41\n",
      "loss: tensor(0.8831, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 42\n",
      "loss: tensor(0.9810, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 43\n",
      "loss: tensor(0.8681, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 44\n",
      "loss: tensor(0.9459, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 45\n",
      "loss: tensor(0.8919, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 46\n",
      "loss: tensor(0.8691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 47\n",
      "loss: tensor(1.0093, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 48\n",
      "loss: tensor(0.8516, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 49\n",
      "loss: tensor(0.8772, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 50\n",
      "loss: tensor(0.8779, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 51\n",
      "loss: tensor(0.8609, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 52\n",
      "loss: tensor(0.8732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 53\n",
      "loss: tensor(0.8718, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 54\n",
      "loss: tensor(0.8473, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 55\n",
      "loss: tensor(0.9235, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 56\n",
      "loss: tensor(0.8725, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 57\n",
      "loss: tensor(0.8516, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 58\n",
      "loss: tensor(0.8491, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 59\n",
      "loss: tensor(0.8413, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 60\n",
      "loss: tensor(0.8614, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 61\n",
      "loss: tensor(0.8858, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 62\n",
      "loss: tensor(0.8670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 63\n",
      "loss: tensor(0.8608, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 64\n",
      "loss: tensor(0.8820, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 65\n",
      "loss: tensor(0.9405, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 66\n",
      "loss: tensor(0.8866, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 67\n",
      "loss: tensor(0.8598, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 68\n",
      "loss: tensor(0.8545, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 69\n",
      "loss: tensor(0.8567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 70\n",
      "loss: tensor(0.9792, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 71\n",
      "loss: tensor(0.8831, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 72\n",
      "loss: tensor(0.8691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 73\n",
      "loss: tensor(0.8602, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 74\n",
      "loss: tensor(0.8707, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 75\n",
      "loss: tensor(0.8395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 76\n",
      "loss: tensor(0.8570, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 77\n",
      "loss: tensor(0.8737, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 78\n",
      "loss: tensor(0.9392, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 79\n",
      "loss: tensor(0.8750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 80\n",
      "loss: tensor(0.8705, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 82\n",
      "loss: tensor(0.8506, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 83\n",
      "loss: tensor(0.8749, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 84\n",
      "loss: tensor(0.8641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 85\n",
      "loss: tensor(0.8306, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 86\n",
      "loss: tensor(0.8565, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 87\n",
      "loss: tensor(0.8670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 88\n",
      "loss: tensor(0.9018, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 89\n",
      "loss: tensor(0.8364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 90\n",
      "loss: tensor(0.9037, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 91\n",
      "loss: tensor(0.8635, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 92\n",
      "loss: tensor(0.8568, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 93\n",
      "loss: tensor(0.9322, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 94\n",
      "loss: tensor(0.8687, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 95\n",
      "loss: tensor(0.8762, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 96\n",
      "loss: tensor(0.8570, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 97\n",
      "loss: tensor(0.8879, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 98\n",
      "loss: tensor(0.9004, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 99\n",
      "loss: tensor(0.8830, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 0\n",
      "loss: tensor(0.9722, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 1\n",
      "loss: tensor(0.8485, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 2\n",
      "loss: tensor(0.8746, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 3\n",
      "loss: tensor(0.8843, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 4\n",
      "loss: tensor(0.8709, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 5\n",
      "loss: tensor(0.8654, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 6\n",
      "loss: tensor(0.8638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 7\n",
      "loss: tensor(0.8973, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 8\n",
      "loss: tensor(0.8790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 9\n",
      "loss: tensor(0.8552, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 10\n",
      "loss: tensor(0.8927, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 11\n",
      "loss: tensor(0.8432, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 12\n",
      "loss: tensor(0.8582, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 13\n",
      "loss: tensor(0.8651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 14\n",
      "loss: tensor(0.8453, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 15\n",
      "loss: tensor(0.8969, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 16\n",
      "loss: tensor(0.8688, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 17\n",
      "loss: tensor(0.8572, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 18\n",
      "loss: tensor(0.8610, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 19\n",
      "loss: tensor(0.8384, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 20\n",
      "loss: tensor(0.9182, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 21\n",
      "loss: tensor(0.8700, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 22\n",
      "loss: tensor(0.9659, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 23\n",
      "loss: tensor(0.8699, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 24\n",
      "loss: tensor(0.8744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 25\n",
      "loss: tensor(0.8524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 26\n",
      "loss: tensor(0.8392, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 27\n",
      "loss: tensor(0.8783, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 28\n",
      "loss: tensor(0.8651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 29\n",
      "loss: tensor(0.8912, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 30\n",
      "loss: tensor(0.8596, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 31\n",
      "loss: tensor(0.8837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 32\n",
      "loss: tensor(0.8605, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 33\n",
      "loss: tensor(0.8622, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 34\n",
      "loss: tensor(0.8678, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 35\n",
      "loss: tensor(0.8329, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 36\n",
      "loss: tensor(0.8773, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 37\n",
      "loss: tensor(0.8655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 38\n",
      "loss: tensor(0.9341, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 39\n",
      "loss: tensor(0.8474, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 40\n",
      "loss: tensor(0.8741, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 41\n",
      "loss: tensor(0.8695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 42\n",
      "loss: tensor(0.8530, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 43\n",
      "loss: tensor(0.8384, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 44\n",
      "loss: tensor(0.9557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 45\n",
      "loss: tensor(0.8544, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 46\n",
      "loss: tensor(0.9251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 47\n",
      "loss: tensor(0.8583, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 48\n",
      "loss: tensor(0.8638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 49\n",
      "loss: tensor(0.9177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 50\n",
      "loss: tensor(0.8266, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 51\n",
      "loss: tensor(0.8719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 52\n",
      "loss: tensor(0.8970, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 53\n",
      "loss: tensor(0.9190, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 54\n",
      "loss: tensor(0.8626, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 55\n",
      "loss: tensor(0.8830, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 56\n",
      "loss: tensor(0.8307, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 57\n",
      "loss: tensor(0.9266, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 58\n",
      "loss: tensor(0.8796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 59\n",
      "loss: tensor(0.8705, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 60\n",
      "loss: tensor(0.8767, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 61\n",
      "loss: tensor(0.8454, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 62\n",
      "loss: tensor(0.8587, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 63\n",
      "loss: tensor(0.9185, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 64\n",
      "loss: tensor(0.8585, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 65\n",
      "loss: tensor(0.8751, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 66\n",
      "loss: tensor(0.8425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 67\n",
      "loss: tensor(0.8744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 68\n",
      "loss: tensor(0.8508, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 69\n",
      "loss: tensor(1.0060, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 70\n",
      "loss: tensor(0.8517, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 71\n",
      "loss: tensor(0.8365, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 72\n",
      "loss: tensor(0.8561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 73\n",
      "loss: tensor(0.8313, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 74\n",
      "loss: tensor(0.8467, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 75\n",
      "loss: tensor(0.8934, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 76\n",
      "loss: tensor(0.8504, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 77\n",
      "loss: tensor(0.8631, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 78\n",
      "loss: tensor(0.8735, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 79\n",
      "loss: tensor(0.8985, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 80\n",
      "loss: tensor(0.8513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 81\n",
      "loss: tensor(0.8493, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 82\n",
      "loss: tensor(0.8680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 83\n",
      "loss: tensor(0.8672, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 84\n",
      "loss: tensor(0.8680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 85\n",
      "loss: tensor(0.8568, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 86\n",
      "loss: tensor(0.9511, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 87\n",
      "loss: tensor(0.8963, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 88\n",
      "loss: tensor(0.8509, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 89\n",
      "loss: tensor(0.8727, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 90\n",
      "loss: tensor(0.8651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 91\n",
      "loss: tensor(0.8541, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9225, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 93\n",
      "loss: tensor(0.9025, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 94\n",
      "loss: tensor(0.8658, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 95\n",
      "loss: tensor(0.8616, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 96\n",
      "loss: tensor(0.8534, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 97\n",
      "loss: tensor(0.8701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 98\n",
      "loss: tensor(0.8566, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 99\n",
      "loss: tensor(0.8574, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 0\n",
      "loss: tensor(0.8396, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 1\n",
      "loss: tensor(0.8376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 2\n",
      "loss: tensor(0.8515, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 3\n",
      "loss: tensor(0.9165, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 4\n",
      "loss: tensor(0.8645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 5\n",
      "loss: tensor(0.8557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 6\n",
      "loss: tensor(0.8273, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 7\n",
      "loss: tensor(0.9667, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 8\n",
      "loss: tensor(0.8486, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 9\n",
      "loss: tensor(0.9144, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 10\n",
      "loss: tensor(0.8214, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 11\n",
      "loss: tensor(0.8674, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 12\n",
      "loss: tensor(0.8555, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 13\n",
      "loss: tensor(0.9046, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 14\n",
      "loss: tensor(0.8556, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 15\n",
      "loss: tensor(0.8618, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 16\n",
      "loss: tensor(0.9959, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 17\n",
      "loss: tensor(0.8685, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 18\n",
      "loss: tensor(0.8414, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 19\n",
      "loss: tensor(0.8720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 20\n",
      "loss: tensor(0.9013, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 21\n",
      "loss: tensor(0.9210, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 22\n",
      "loss: tensor(0.8420, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 23\n",
      "loss: tensor(0.8668, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 24\n",
      "loss: tensor(0.8674, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 25\n",
      "loss: tensor(0.9330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 26\n",
      "loss: tensor(0.8723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 27\n",
      "loss: tensor(0.8508, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 28\n",
      "loss: tensor(0.8476, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 29\n",
      "loss: tensor(0.8509, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 30\n",
      "loss: tensor(0.8741, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 31\n",
      "loss: tensor(0.8733, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 32\n",
      "loss: tensor(0.8705, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 33\n",
      "loss: tensor(0.8495, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 34\n",
      "loss: tensor(0.8587, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 35\n",
      "loss: tensor(0.8586, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 36\n",
      "loss: tensor(0.8554, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 37\n",
      "loss: tensor(0.8876, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 38\n",
      "loss: tensor(0.8451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 39\n",
      "loss: tensor(0.8634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 40\n",
      "loss: tensor(0.8394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 41\n",
      "loss: tensor(0.8581, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 42\n",
      "loss: tensor(0.8473, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 43\n",
      "loss: tensor(0.8959, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 44\n",
      "loss: tensor(0.8705, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 45\n",
      "loss: tensor(0.8731, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 46\n",
      "loss: tensor(0.9148, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 47\n",
      "loss: tensor(0.8495, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 48\n",
      "loss: tensor(0.8734, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 49\n",
      "loss: tensor(0.8736, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 50\n",
      "loss: tensor(0.8388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 51\n",
      "loss: tensor(0.8290, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 52\n",
      "loss: tensor(0.9362, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 53\n",
      "loss: tensor(0.8606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 54\n",
      "loss: tensor(0.8428, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 55\n",
      "loss: tensor(0.8510, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 56\n",
      "loss: tensor(0.9523, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 57\n",
      "loss: tensor(0.8495, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 58\n",
      "loss: tensor(0.8888, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 59\n",
      "loss: tensor(0.8533, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 60\n",
      "loss: tensor(0.8611, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 61\n",
      "loss: tensor(0.8522, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 62\n",
      "loss: tensor(0.8690, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 63\n",
      "loss: tensor(0.8512, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 64\n",
      "loss: tensor(0.8750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 65\n",
      "loss: tensor(0.8549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 66\n",
      "loss: tensor(0.8453, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 67\n",
      "loss: tensor(0.8890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 68\n",
      "loss: tensor(0.8650, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 69\n",
      "loss: tensor(0.8400, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 70\n",
      "loss: tensor(0.8346, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 71\n",
      "loss: tensor(0.8427, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 72\n",
      "loss: tensor(0.8708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 73\n",
      "loss: tensor(0.8817, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 74\n",
      "loss: tensor(0.8493, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 75\n",
      "loss: tensor(0.8886, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 76\n",
      "loss: tensor(0.8493, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 77\n",
      "loss: tensor(0.8510, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 78\n",
      "loss: tensor(0.8539, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 79\n",
      "loss: tensor(0.8449, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 80\n",
      "loss: tensor(0.8607, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 81\n",
      "loss: tensor(0.8548, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 82\n",
      "loss: tensor(0.8867, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 83\n",
      "loss: tensor(0.8776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 84\n",
      "loss: tensor(0.8294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 85\n",
      "loss: tensor(0.9282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 86\n",
      "loss: tensor(0.8674, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 87\n",
      "loss: tensor(0.9152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 88\n",
      "loss: tensor(0.8521, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 89\n",
      "loss: tensor(0.8305, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 90\n",
      "loss: tensor(0.8599, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 91\n",
      "loss: tensor(0.8837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 92\n",
      "loss: tensor(0.8621, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 93\n",
      "loss: tensor(0.8278, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 94\n",
      "loss: tensor(0.9558, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 95\n",
      "loss: tensor(0.8600, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 96\n",
      "loss: tensor(0.8551, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 97\n",
      "loss: tensor(0.8652, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 98\n",
      "loss: tensor(0.8545, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 99\n",
      "loss: tensor(0.8549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 0\n",
      "loss: tensor(0.9106, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 1\n",
      "loss: tensor(0.8480, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 2\n",
      "loss: tensor(0.8612, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8568, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 4\n",
      "loss: tensor(0.8159, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 5\n",
      "loss: tensor(0.8310, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 6\n",
      "loss: tensor(0.8514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 7\n",
      "loss: tensor(0.8432, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 8\n",
      "loss: tensor(0.8509, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 9\n",
      "loss: tensor(0.8736, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 10\n",
      "loss: tensor(0.8352, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 11\n",
      "loss: tensor(0.8249, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 12\n",
      "loss: tensor(0.8653, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 13\n",
      "loss: tensor(0.8638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 14\n",
      "loss: tensor(0.8418, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 15\n",
      "loss: tensor(0.8579, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 16\n",
      "loss: tensor(0.8715, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 17\n",
      "loss: tensor(0.8559, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 18\n",
      "loss: tensor(0.8323, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 19\n",
      "loss: tensor(0.8355, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 20\n",
      "loss: tensor(0.8515, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 21\n",
      "loss: tensor(0.8546, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 22\n",
      "loss: tensor(0.8461, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 23\n",
      "loss: tensor(0.8486, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 24\n",
      "loss: tensor(0.9423, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 25\n",
      "loss: tensor(0.8608, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 26\n",
      "loss: tensor(0.8661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 27\n",
      "loss: tensor(0.8439, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 28\n",
      "loss: tensor(0.8532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 29\n",
      "loss: tensor(0.8451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 30\n",
      "loss: tensor(0.8503, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 31\n",
      "loss: tensor(0.8574, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 32\n",
      "loss: tensor(0.8428, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 33\n",
      "loss: tensor(0.8501, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 34\n",
      "loss: tensor(0.8642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 35\n",
      "loss: tensor(0.8461, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 36\n",
      "loss: tensor(0.8596, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 37\n",
      "loss: tensor(0.9891, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 38\n",
      "loss: tensor(0.8413, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 39\n",
      "loss: tensor(0.8777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 40\n",
      "loss: tensor(0.8390, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 41\n",
      "loss: tensor(0.8592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 42\n",
      "loss: tensor(0.8267, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 43\n",
      "loss: tensor(0.8318, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 44\n",
      "loss: tensor(0.8332, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 45\n",
      "loss: tensor(0.8416, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 46\n",
      "loss: tensor(0.8440, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 47\n",
      "loss: tensor(0.9205, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 48\n",
      "loss: tensor(0.8836, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 49\n",
      "loss: tensor(0.9116, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 50\n",
      "loss: tensor(0.9050, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 51\n",
      "loss: tensor(0.8343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 52\n",
      "loss: tensor(0.8801, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 53\n",
      "loss: tensor(0.8609, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 54\n",
      "loss: tensor(0.8426, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 55\n",
      "loss: tensor(0.8641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 56\n",
      "loss: tensor(0.9147, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 57\n",
      "loss: tensor(0.8442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 58\n",
      "loss: tensor(0.8410, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 59\n",
      "loss: tensor(0.8641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 60\n",
      "loss: tensor(0.8518, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 61\n",
      "loss: tensor(0.8517, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 62\n",
      "loss: tensor(0.8819, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 63\n",
      "loss: tensor(0.8478, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 64\n",
      "loss: tensor(0.8211, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 65\n",
      "loss: tensor(0.8500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 66\n",
      "loss: tensor(0.8549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 67\n",
      "loss: tensor(0.8393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 68\n",
      "loss: tensor(0.8852, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 69\n",
      "loss: tensor(0.8846, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 70\n",
      "loss: tensor(0.8361, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 71\n",
      "loss: tensor(0.8637, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 72\n",
      "loss: tensor(0.8451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 73\n",
      "loss: tensor(0.8399, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 74\n",
      "loss: tensor(0.8756, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 75\n",
      "loss: tensor(0.9200, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 76\n",
      "loss: tensor(0.8544, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 77\n",
      "loss: tensor(0.8579, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 78\n",
      "loss: tensor(0.8785, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 79\n",
      "loss: tensor(0.8999, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 80\n",
      "loss: tensor(0.8426, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 81\n",
      "loss: tensor(0.8612, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 82\n",
      "loss: tensor(0.8395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 83\n",
      "loss: tensor(0.8657, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 84\n",
      "loss: tensor(0.9072, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 85\n",
      "loss: tensor(0.9472, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 86\n",
      "loss: tensor(0.8565, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 87\n",
      "loss: tensor(0.9451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 88\n",
      "loss: tensor(0.8765, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 89\n",
      "loss: tensor(0.8356, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 90\n",
      "loss: tensor(0.8410, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 91\n",
      "loss: tensor(0.8237, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 92\n",
      "loss: tensor(0.8610, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 93\n",
      "loss: tensor(0.8371, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 94\n",
      "loss: tensor(0.8500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 95\n",
      "loss: tensor(0.8674, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 96\n",
      "loss: tensor(0.8542, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 97\n",
      "loss: tensor(0.8485, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 98\n",
      "loss: tensor(0.8549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 99\n",
      "loss: tensor(0.8968, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 0\n",
      "loss: tensor(0.8344, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 1\n",
      "loss: tensor(0.8391, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 2\n",
      "loss: tensor(0.8523, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 3\n",
      "loss: tensor(0.8670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 4\n",
      "loss: tensor(0.8651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 5\n",
      "loss: tensor(0.9185, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 6\n",
      "loss: tensor(0.8564, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 7\n",
      "loss: tensor(0.8552, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 8\n",
      "loss: tensor(0.8431, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 9\n",
      "loss: tensor(0.8424, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 10\n",
      "loss: tensor(0.8291, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 11\n",
      "loss: tensor(0.8579, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 12\n",
      "loss: tensor(0.8210, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 13\n",
      "loss: tensor(0.8651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8389, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 15\n",
      "loss: tensor(0.8465, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 16\n",
      "loss: tensor(0.8531, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 17\n",
      "loss: tensor(0.8088, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 18\n",
      "loss: tensor(0.8492, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 19\n",
      "loss: tensor(0.8527, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 20\n",
      "loss: tensor(0.8564, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 21\n",
      "loss: tensor(0.8804, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 22\n",
      "loss: tensor(0.8179, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 23\n",
      "loss: tensor(0.9837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 24\n",
      "loss: tensor(0.8435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 25\n",
      "loss: tensor(0.8422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 26\n",
      "loss: tensor(0.8814, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 27\n",
      "loss: tensor(0.9116, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 28\n",
      "loss: tensor(0.8641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 29\n",
      "loss: tensor(0.8567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 30\n",
      "loss: tensor(0.8454, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 31\n",
      "loss: tensor(0.8538, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 32\n",
      "loss: tensor(0.8971, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 33\n",
      "loss: tensor(0.9362, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 34\n",
      "loss: tensor(0.8591, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 35\n",
      "loss: tensor(0.8738, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 36\n",
      "loss: tensor(0.8981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 37\n",
      "loss: tensor(0.8382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 38\n",
      "loss: tensor(0.8613, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 39\n",
      "loss: tensor(0.8419, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 40\n",
      "loss: tensor(0.8578, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 41\n",
      "loss: tensor(0.8341, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 42\n",
      "loss: tensor(0.8441, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 43\n",
      "loss: tensor(0.9001, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 44\n",
      "loss: tensor(0.8310, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 45\n",
      "loss: tensor(0.8432, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 46\n",
      "loss: tensor(0.8229, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 47\n",
      "loss: tensor(0.8365, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 48\n",
      "loss: tensor(0.8425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 49\n",
      "loss: tensor(0.9534, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 50\n",
      "loss: tensor(0.8709, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 51\n",
      "loss: tensor(0.8268, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 52\n",
      "loss: tensor(0.8508, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 53\n",
      "loss: tensor(0.8375, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 54\n",
      "loss: tensor(0.8425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 55\n",
      "loss: tensor(0.8247, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 56\n",
      "loss: tensor(0.9134, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 57\n",
      "loss: tensor(0.8300, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 58\n",
      "loss: tensor(0.8703, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 59\n",
      "loss: tensor(0.8586, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 60\n",
      "loss: tensor(0.8337, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 61\n",
      "loss: tensor(0.8426, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 62\n",
      "loss: tensor(0.8353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 63\n",
      "loss: tensor(0.8460, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 64\n",
      "loss: tensor(0.8435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 65\n",
      "loss: tensor(0.8636, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 66\n",
      "loss: tensor(0.8565, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 67\n",
      "loss: tensor(0.8249, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 68\n",
      "loss: tensor(0.8279, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 69\n",
      "loss: tensor(0.8546, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 70\n",
      "loss: tensor(0.8464, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 71\n",
      "loss: tensor(0.9423, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 72\n",
      "loss: tensor(0.8340, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 73\n",
      "loss: tensor(0.8394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 74\n",
      "loss: tensor(0.8391, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 75\n",
      "loss: tensor(0.8452, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 76\n",
      "loss: tensor(0.8207, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 77\n",
      "loss: tensor(0.8349, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 78\n",
      "loss: tensor(0.8602, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 79\n",
      "loss: tensor(0.8688, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 80\n",
      "loss: tensor(0.9177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 81\n",
      "loss: tensor(0.8489, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 82\n",
      "loss: tensor(0.8304, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 83\n",
      "loss: tensor(0.8545, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 84\n",
      "loss: tensor(0.8739, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 85\n",
      "loss: tensor(0.8428, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 86\n",
      "loss: tensor(0.8790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 87\n",
      "loss: tensor(0.8447, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 88\n",
      "loss: tensor(0.8396, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 89\n",
      "loss: tensor(0.8767, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 90\n",
      "loss: tensor(0.8557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 91\n",
      "loss: tensor(0.8874, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 92\n",
      "loss: tensor(0.8443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 93\n",
      "loss: tensor(0.8520, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 94\n",
      "loss: tensor(0.8363, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 95\n",
      "loss: tensor(0.8345, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 96\n",
      "loss: tensor(0.8477, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 97\n",
      "loss: tensor(0.8236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 98\n",
      "loss: tensor(0.8410, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 20 99\n",
      "loss: tensor(0.8516, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 0\n",
      "loss: tensor(0.8357, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 1\n",
      "loss: tensor(0.8388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 2\n",
      "loss: tensor(0.8964, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 3\n",
      "loss: tensor(0.8953, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 4\n",
      "loss: tensor(0.8331, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 5\n",
      "loss: tensor(0.8595, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 6\n",
      "loss: tensor(0.8358, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 7\n",
      "loss: tensor(0.8336, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 8\n",
      "loss: tensor(0.8495, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 9\n",
      "loss: tensor(0.8775, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 10\n",
      "loss: tensor(0.8661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 11\n",
      "loss: tensor(0.8395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 12\n",
      "loss: tensor(0.8245, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 13\n",
      "loss: tensor(0.8313, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 14\n",
      "loss: tensor(0.8268, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 15\n",
      "loss: tensor(0.9259, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 16\n",
      "loss: tensor(0.8585, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 17\n",
      "loss: tensor(0.8294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 18\n",
      "loss: tensor(0.8468, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 19\n",
      "loss: tensor(0.8471, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 20\n",
      "loss: tensor(0.8399, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 21\n",
      "loss: tensor(0.8234, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 22\n",
      "loss: tensor(0.8319, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 23\n",
      "loss: tensor(0.8290, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 24\n",
      "loss: tensor(0.8369, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8551, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 26\n",
      "loss: tensor(0.8284, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 27\n",
      "loss: tensor(0.8509, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 28\n",
      "loss: tensor(0.8566, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 29\n",
      "loss: tensor(0.8725, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 30\n",
      "loss: tensor(0.8393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 31\n",
      "loss: tensor(0.8398, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 32\n",
      "loss: tensor(0.8521, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 33\n",
      "loss: tensor(0.8497, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 34\n",
      "loss: tensor(0.9172, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 35\n",
      "loss: tensor(0.8402, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 36\n",
      "loss: tensor(0.8132, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 37\n",
      "loss: tensor(0.8460, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 38\n",
      "loss: tensor(0.8252, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 39\n",
      "loss: tensor(0.8706, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 40\n",
      "loss: tensor(0.8542, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 41\n",
      "loss: tensor(0.8317, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 42\n",
      "loss: tensor(0.8216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 43\n",
      "loss: tensor(0.8433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 44\n",
      "loss: tensor(0.8412, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 45\n",
      "loss: tensor(0.9750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 46\n",
      "loss: tensor(0.8500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 47\n",
      "loss: tensor(0.8394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 48\n",
      "loss: tensor(0.8391, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 49\n",
      "loss: tensor(0.8376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 50\n",
      "loss: tensor(0.8366, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 51\n",
      "loss: tensor(0.8743, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 52\n",
      "loss: tensor(0.8389, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 53\n",
      "loss: tensor(0.8589, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 54\n",
      "loss: tensor(0.8991, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 55\n",
      "loss: tensor(0.8417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 56\n",
      "loss: tensor(0.8524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 57\n",
      "loss: tensor(0.8640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 58\n",
      "loss: tensor(0.8600, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 59\n",
      "loss: tensor(0.8387, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 60\n",
      "loss: tensor(0.9310, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 61\n",
      "loss: tensor(0.8445, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 62\n",
      "loss: tensor(0.8407, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 63\n",
      "loss: tensor(0.8463, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 64\n",
      "loss: tensor(0.8486, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 65\n",
      "loss: tensor(0.8541, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 66\n",
      "loss: tensor(0.8778, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 67\n",
      "loss: tensor(0.8679, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 68\n",
      "loss: tensor(0.8094, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 69\n",
      "loss: tensor(0.8509, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 70\n",
      "loss: tensor(0.8170, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 71\n",
      "loss: tensor(0.8472, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 72\n",
      "loss: tensor(0.8316, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 73\n",
      "loss: tensor(0.8654, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 74\n",
      "loss: tensor(0.8346, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 75\n",
      "loss: tensor(0.8404, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 76\n",
      "loss: tensor(0.8392, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 77\n",
      "loss: tensor(0.8358, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 78\n",
      "loss: tensor(0.8330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 79\n",
      "loss: tensor(0.8148, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 80\n",
      "loss: tensor(0.8291, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 81\n",
      "loss: tensor(0.8303, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 82\n",
      "loss: tensor(0.8357, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 83\n",
      "loss: tensor(0.8920, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 84\n",
      "loss: tensor(0.8236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 85\n",
      "loss: tensor(0.8156, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 86\n",
      "loss: tensor(0.9289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 87\n",
      "loss: tensor(0.8870, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 88\n",
      "loss: tensor(0.8359, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 89\n",
      "loss: tensor(0.8216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 90\n",
      "loss: tensor(0.8311, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 91\n",
      "loss: tensor(0.8482, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 92\n",
      "loss: tensor(0.8380, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 93\n",
      "loss: tensor(0.8506, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 94\n",
      "loss: tensor(0.8477, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 95\n",
      "loss: tensor(0.8705, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 96\n",
      "loss: tensor(0.8322, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 97\n",
      "loss: tensor(0.8204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 98\n",
      "loss: tensor(0.8298, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 21 99\n",
      "loss: tensor(0.9089, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 0\n",
      "loss: tensor(0.9099, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 1\n",
      "loss: tensor(0.9013, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 2\n",
      "loss: tensor(0.8036, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 3\n",
      "loss: tensor(0.8469, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 4\n",
      "loss: tensor(0.8456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 5\n",
      "loss: tensor(0.8665, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 6\n",
      "loss: tensor(0.8305, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 7\n",
      "loss: tensor(0.8607, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 8\n",
      "loss: tensor(0.8605, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 9\n",
      "loss: tensor(0.8442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 10\n",
      "loss: tensor(0.8141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 11\n",
      "loss: tensor(0.8477, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 12\n",
      "loss: tensor(0.8204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 13\n",
      "loss: tensor(0.8217, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 14\n",
      "loss: tensor(0.8231, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 15\n",
      "loss: tensor(0.8155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 16\n",
      "loss: tensor(0.8386, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 17\n",
      "loss: tensor(0.8498, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 18\n",
      "loss: tensor(0.8490, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 19\n",
      "loss: tensor(0.8275, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 20\n",
      "loss: tensor(0.8289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 21\n",
      "loss: tensor(0.8470, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 22\n",
      "loss: tensor(0.8192, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 23\n",
      "loss: tensor(0.8741, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 24\n",
      "loss: tensor(0.8492, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 25\n",
      "loss: tensor(0.9165, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 26\n",
      "loss: tensor(0.9622, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 27\n",
      "loss: tensor(0.8513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 28\n",
      "loss: tensor(0.8318, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 29\n",
      "loss: tensor(0.8287, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 30\n",
      "loss: tensor(0.8503, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 31\n",
      "loss: tensor(0.8875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 32\n",
      "loss: tensor(0.8318, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 33\n",
      "loss: tensor(0.8767, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 34\n",
      "loss: tensor(0.8410, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 35\n",
      "loss: tensor(0.8341, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8469, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 37\n",
      "loss: tensor(0.8187, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 38\n",
      "loss: tensor(0.8322, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 39\n",
      "loss: tensor(0.8458, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 40\n",
      "loss: tensor(0.8163, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 41\n",
      "loss: tensor(0.8369, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 42\n",
      "loss: tensor(0.9240, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 43\n",
      "loss: tensor(0.8152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 44\n",
      "loss: tensor(0.8680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 45\n",
      "loss: tensor(0.8401, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 46\n",
      "loss: tensor(0.8373, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 47\n",
      "loss: tensor(0.8909, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 48\n",
      "loss: tensor(0.8434, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 49\n",
      "loss: tensor(0.8325, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 50\n",
      "loss: tensor(0.8480, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 51\n",
      "loss: tensor(0.9258, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 52\n",
      "loss: tensor(0.8228, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 53\n",
      "loss: tensor(0.8355, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 54\n",
      "loss: tensor(0.8270, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 55\n",
      "loss: tensor(0.8494, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 56\n",
      "loss: tensor(0.8673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 57\n",
      "loss: tensor(0.8828, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 58\n",
      "loss: tensor(0.8172, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 59\n",
      "loss: tensor(0.8272, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 60\n",
      "loss: tensor(0.8642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 61\n",
      "loss: tensor(0.8295, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 62\n",
      "loss: tensor(0.8370, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 63\n",
      "loss: tensor(0.8293, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 64\n",
      "loss: tensor(0.8321, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 65\n",
      "loss: tensor(0.8462, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 66\n",
      "loss: tensor(0.8403, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 67\n",
      "loss: tensor(0.8526, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 68\n",
      "loss: tensor(0.8376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 69\n",
      "loss: tensor(0.8184, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 70\n",
      "loss: tensor(0.8136, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 71\n",
      "loss: tensor(0.8986, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 72\n",
      "loss: tensor(0.8388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 73\n",
      "loss: tensor(0.8431, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 74\n",
      "loss: tensor(0.8486, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 75\n",
      "loss: tensor(0.8312, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 76\n",
      "loss: tensor(0.8371, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 77\n",
      "loss: tensor(0.8337, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 78\n",
      "loss: tensor(0.8353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 79\n",
      "loss: tensor(0.8317, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 80\n",
      "loss: tensor(0.8564, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 81\n",
      "loss: tensor(0.8434, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 82\n",
      "loss: tensor(0.8614, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 83\n",
      "loss: tensor(0.8325, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 84\n",
      "loss: tensor(0.8232, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 85\n",
      "loss: tensor(0.8753, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 86\n",
      "loss: tensor(0.8305, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 87\n",
      "loss: tensor(0.8330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 88\n",
      "loss: tensor(0.8325, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 89\n",
      "loss: tensor(0.8203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 90\n",
      "loss: tensor(0.8334, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 91\n",
      "loss: tensor(0.8321, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 92\n",
      "loss: tensor(0.8242, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 93\n",
      "loss: tensor(0.8183, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 94\n",
      "loss: tensor(0.8251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 95\n",
      "loss: tensor(0.8435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 96\n",
      "loss: tensor(0.8312, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 97\n",
      "loss: tensor(0.8066, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 98\n",
      "loss: tensor(0.8293, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 22 99\n",
      "loss: tensor(0.8114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 0\n",
      "loss: tensor(0.8492, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 1\n",
      "loss: tensor(0.8114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 2\n",
      "loss: tensor(0.8140, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 3\n",
      "loss: tensor(0.8209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 4\n",
      "loss: tensor(0.8267, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 5\n",
      "loss: tensor(0.9135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 6\n",
      "loss: tensor(0.8938, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 7\n",
      "loss: tensor(0.8214, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 8\n",
      "loss: tensor(0.8302, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 9\n",
      "loss: tensor(0.8402, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 10\n",
      "loss: tensor(0.8380, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 11\n",
      "loss: tensor(0.8412, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 12\n",
      "loss: tensor(0.8453, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 13\n",
      "loss: tensor(0.8461, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 14\n",
      "loss: tensor(0.8329, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 15\n",
      "loss: tensor(0.8324, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 16\n",
      "loss: tensor(0.8376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 17\n",
      "loss: tensor(0.8418, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 18\n",
      "loss: tensor(0.8615, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 19\n",
      "loss: tensor(0.8386, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 20\n",
      "loss: tensor(0.8595, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 21\n",
      "loss: tensor(0.8229, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 22\n",
      "loss: tensor(0.8486, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 23\n",
      "loss: tensor(0.8226, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 24\n",
      "loss: tensor(0.9080, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 25\n",
      "loss: tensor(0.9594, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 26\n",
      "loss: tensor(0.8359, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 27\n",
      "loss: tensor(0.8239, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 28\n",
      "loss: tensor(0.8292, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 29\n",
      "loss: tensor(0.8459, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 30\n",
      "loss: tensor(0.8522, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 31\n",
      "loss: tensor(0.8403, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 32\n",
      "loss: tensor(0.8288, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 33\n",
      "loss: tensor(0.8240, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 34\n",
      "loss: tensor(0.8427, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 35\n",
      "loss: tensor(0.8100, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 36\n",
      "loss: tensor(0.8728, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 37\n",
      "loss: tensor(0.8397, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 38\n",
      "loss: tensor(0.8282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 39\n",
      "loss: tensor(0.8635, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 40\n",
      "loss: tensor(0.8563, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 41\n",
      "loss: tensor(0.8395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 42\n",
      "loss: tensor(0.8281, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 43\n",
      "loss: tensor(0.8277, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 44\n",
      "loss: tensor(0.8352, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 45\n",
      "loss: tensor(0.8147, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 46\n",
      "loss: tensor(0.8325, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8111, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 48\n",
      "loss: tensor(0.8307, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 49\n",
      "loss: tensor(0.8311, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 50\n",
      "loss: tensor(0.8163, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 51\n",
      "loss: tensor(0.8259, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 52\n",
      "loss: tensor(0.8168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 53\n",
      "loss: tensor(0.8309, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 54\n",
      "loss: tensor(0.8176, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 55\n",
      "loss: tensor(0.8077, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 56\n",
      "loss: tensor(0.8154, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 57\n",
      "loss: tensor(0.8155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 58\n",
      "loss: tensor(0.8370, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 59\n",
      "loss: tensor(0.7971, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 60\n",
      "loss: tensor(0.8245, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 61\n",
      "loss: tensor(0.8237, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 62\n",
      "loss: tensor(0.8279, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 63\n",
      "loss: tensor(0.8306, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 64\n",
      "loss: tensor(0.8524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 65\n",
      "loss: tensor(0.8274, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 66\n",
      "loss: tensor(0.8995, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 67\n",
      "loss: tensor(0.8210, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 68\n",
      "loss: tensor(0.8421, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 69\n",
      "loss: tensor(0.8203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 70\n",
      "loss: tensor(0.8133, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 71\n",
      "loss: tensor(0.8034, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 72\n",
      "loss: tensor(0.8201, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 73\n",
      "loss: tensor(0.9203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 74\n",
      "loss: tensor(0.8792, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 75\n",
      "loss: tensor(0.8249, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 76\n",
      "loss: tensor(0.8587, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 77\n",
      "loss: tensor(0.8442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 78\n",
      "loss: tensor(0.8280, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 79\n",
      "loss: tensor(0.8607, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 80\n",
      "loss: tensor(0.8387, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 81\n",
      "loss: tensor(0.8119, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 82\n",
      "loss: tensor(0.9157, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 83\n",
      "loss: tensor(0.8330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 84\n",
      "loss: tensor(0.8251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 85\n",
      "loss: tensor(0.8573, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 86\n",
      "loss: tensor(0.8366, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 87\n",
      "loss: tensor(0.8146, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 88\n",
      "loss: tensor(0.8364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 89\n",
      "loss: tensor(0.8652, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 90\n",
      "loss: tensor(0.8190, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 91\n",
      "loss: tensor(0.8269, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 92\n",
      "loss: tensor(0.8204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 93\n",
      "loss: tensor(0.8091, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 94\n",
      "loss: tensor(0.8277, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 95\n",
      "loss: tensor(0.8374, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 96\n",
      "loss: tensor(0.8763, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 97\n",
      "loss: tensor(0.8451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 98\n",
      "loss: tensor(0.8768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 23 99\n",
      "loss: tensor(0.8248, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 0\n",
      "loss: tensor(0.9553, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 1\n",
      "loss: tensor(0.8477, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 2\n",
      "loss: tensor(0.8557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 3\n",
      "loss: tensor(0.8255, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 4\n",
      "loss: tensor(0.8081, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 5\n",
      "loss: tensor(0.7978, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 6\n",
      "loss: tensor(0.8550, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 7\n",
      "loss: tensor(0.8284, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 8\n",
      "loss: tensor(0.8064, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 9\n",
      "loss: tensor(0.8136, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 10\n",
      "loss: tensor(0.8252, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 11\n",
      "loss: tensor(0.8275, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 12\n",
      "loss: tensor(0.8237, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 13\n",
      "loss: tensor(0.8248, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 14\n",
      "loss: tensor(0.8464, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 15\n",
      "loss: tensor(0.8361, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 16\n",
      "loss: tensor(0.8069, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 17\n",
      "loss: tensor(0.8271, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 18\n",
      "loss: tensor(0.8524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 19\n",
      "loss: tensor(0.9025, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 20\n",
      "loss: tensor(0.8351, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 21\n",
      "loss: tensor(0.8223, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 22\n",
      "loss: tensor(0.8112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 23\n",
      "loss: tensor(0.8232, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 24\n",
      "loss: tensor(0.8413, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 25\n",
      "loss: tensor(0.8103, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 26\n",
      "loss: tensor(0.8546, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 27\n",
      "loss: tensor(0.8313, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 28\n",
      "loss: tensor(0.8500, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 29\n",
      "loss: tensor(0.8264, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 30\n",
      "loss: tensor(0.8438, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 31\n",
      "loss: tensor(0.8178, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 32\n",
      "loss: tensor(0.8367, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 33\n",
      "loss: tensor(0.8379, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 34\n",
      "loss: tensor(0.8320, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 35\n",
      "loss: tensor(0.8221, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 36\n",
      "loss: tensor(0.8192, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 37\n",
      "loss: tensor(0.8247, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 38\n",
      "loss: tensor(0.9122, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 39\n",
      "loss: tensor(0.8234, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 40\n",
      "loss: tensor(0.8108, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 41\n",
      "loss: tensor(0.8409, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 42\n",
      "loss: tensor(0.8277, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 43\n",
      "loss: tensor(0.8370, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 44\n",
      "loss: tensor(0.8243, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 45\n",
      "loss: tensor(0.8101, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 46\n",
      "loss: tensor(0.8340, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 47\n",
      "loss: tensor(0.8253, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 48\n",
      "loss: tensor(0.8232, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 49\n",
      "loss: tensor(0.8346, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 50\n",
      "loss: tensor(0.8731, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 51\n",
      "loss: tensor(0.8225, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 52\n",
      "loss: tensor(0.8205, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 53\n",
      "loss: tensor(0.8231, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 54\n",
      "loss: tensor(0.8357, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 55\n",
      "loss: tensor(0.8786, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 56\n",
      "loss: tensor(0.8231, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 57\n",
      "loss: tensor(0.8340, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.8539, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 59\n",
      "loss: tensor(0.8874, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 60\n",
      "loss: tensor(0.8618, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 61\n",
      "loss: tensor(0.8214, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 62\n",
      "loss: tensor(0.8671, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 63\n",
      "loss: tensor(0.8382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 64\n",
      "loss: tensor(0.8364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 65\n",
      "loss: tensor(0.8323, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 66\n",
      "loss: tensor(0.8230, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 67\n",
      "loss: tensor(0.8301, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 68\n",
      "loss: tensor(0.8173, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 69\n",
      "loss: tensor(0.8339, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 70\n",
      "loss: tensor(0.8536, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 71\n",
      "loss: tensor(0.8144, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 72\n",
      "loss: tensor(0.8193, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 73\n",
      "loss: tensor(0.8051, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 74\n",
      "loss: tensor(0.8088, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 75\n",
      "loss: tensor(0.8021, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 76\n",
      "loss: tensor(0.8058, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 77\n",
      "loss: tensor(0.8290, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 78\n",
      "loss: tensor(0.8142, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 79\n",
      "loss: tensor(0.8172, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 80\n",
      "loss: tensor(0.8282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 81\n",
      "loss: tensor(0.8160, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 82\n",
      "loss: tensor(0.8115, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 83\n",
      "loss: tensor(0.8318, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 84\n",
      "loss: tensor(0.8594, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 85\n",
      "loss: tensor(0.8119, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 86\n",
      "loss: tensor(0.8039, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 87\n",
      "loss: tensor(0.8813, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 88\n",
      "loss: tensor(0.8400, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 89\n",
      "loss: tensor(0.8226, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 90\n",
      "loss: tensor(0.8695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 91\n",
      "loss: tensor(0.8343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 92\n",
      "loss: tensor(0.9052, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 93\n",
      "loss: tensor(0.8264, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 94\n",
      "loss: tensor(0.8292, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 95\n",
      "loss: tensor(0.8215, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 96\n",
      "loss: tensor(0.8247, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 97\n",
      "loss: tensor(0.8932, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 98\n",
      "loss: tensor(0.8185, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 24 99\n",
      "loss: tensor(0.8181, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.6804208845606604\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.6268808728032605\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.6139500488416102\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANaklEQVR4nO3dX4xcZ3nH8e9TLyFNaOSYKsHYoXZUC4oiQZCFEqBSREBAlBIusBvUVm6byjetSKEVOO1NuUBqJETCRUtlJUVRhXDsJGqsXICQm1TckGadUJrEmLgJcpwYkioOrbhoa+XpxZxNl2V2d3ZmzsyZeb4fydo9Z+fP42P/9nnPe96ZicxE0vz7pWkXIGkyDLtUhGGXijDsUhGGXSrCsEtFjBT2iPhoRJyMiFMRcWBcRUkavxj2OntEbAJ+CHwYOAM8BnwqM58eX3mSxmVhhPu+FziVmc8CRMQh4CZg1bBHhCt4pJZlZvTbP8owfhvw/LLtM82+nxMR+yNiMSIWR3guSSMapbP3++3xC507Mw8CB8HOLk3TKJ39DHDFsu3twIujlSOpLaOE/TFgV0TsjIgLgJuBo+MpS9K4DT2Mz8zzEfEnwLeATcDfZ+ZTY6tM0lgNfeltqCfznF1qXRuz8ZJmiGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRhl0qwrBLRRh2qQjDLhVh2KUiDLtUhGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKsKwS0WsG/aIuCIiHo6IExHxVETc2uzfEhHfjohnmq+Xtl+upGFFZq59g4itwNbMfDwifgU4DnwC+H3glcz864g4AFyamZ9f57HWfjJJI8vM6Ld/3c6emWcz8/Hm+/8CTgDbgJuAe5qb3UPvF4CkjlrYyI0jYgdwNfAocHlmnoXeL4SIuGyV++wH9o9WpqRRrTuMf/2GEW8C/hn4YmY+EBGvZubmZT8/l5lrnrc7jJfaN/QwHiAi3gDcD3w9Mx9odv+kOZ9fOq9/aRyFSmrHILPxAdwNnMjMLy/70VFgX/P9PuDB8ZcnaVwGmY3/APAd4N+A15rdf0HvvP0w8DbgNLAnM19Z57EcxkstW20YP/A5+zgYdql9I52zS5p9G7r0pvm2Z8+e1h77yJEjrT22BmNnl4ow7FIRTtAVtjRs7zfEbnNIv5JD/PFygk4qzs4+pybZmbvCEUKPnV0qzs4+Z0bp6NM+d29DxW5vZ5eKM+xSEQ7j58CoQ+3Dhw//wr69e/eO9JhdU2k47zBeKs618TOizYmypS7er8NrftjZpSLs7HrdvJ2n6+fZ2aUi7OwdN6uLWpZmvwepfyO3HbYO2dmlMgy7VISLajpuraHtWpfKujbZ1q/W3ruU9zfuNf6VuKhGKs7O3jErO9okF7qMczSwWt1rdfO1bKTT29nt7FJpXnrrqJWdcXnX7cqy1rUumS118EmOHLU2O7tUhOfsHbPy32OS7x4z7Dn7JM+Rlx+fQeqteP7uObtUnGGXinCCrmMGWSe+1tB0lCF+hXesqczOLhXhBN0UjXoJbRKviNtIZ1/+91l56a3fpbhhFtj0+/+6Vo1O0P0/O7tUhOfsM2iYjr68w23k/kvdepAOv/w201hMs1TrsEty552dXSrCsEtFDDxBFxGbgEXghcy8MSJ2AoeALcDjwO9l5v+s8xhO0K1j6d9j5cRSl96eauVbTw/7VtQOt9sxjgm6W4ETy7ZvB+7IzF3AOeCW4cuT1LaBOntEbAfuAb4IfBb4LeBl4C2ZeT4irgX+KjM/ss7jlO7s8/oKsHF9yISdfjxG7ex3Ap8DXmu23wy8mpnnm+0zwLZ+d4yI/RGxGBGLG6hX0pite+ktIm4EXsrM4xFx3dLuPjft27Yy8yBwsHms+Wxtc2gjS3LH9fr6URfcaG2DXGd/P/DxiLgBuBC4hF6n3xwRC0133w682F6Zkka1oeWyTWf/82Y2/ghwf2Yeioi/A76fmX+7zv3LdfZZP09v60U3g7LDb1wby2U/D3w2Ik7RO4e/e4THktSyDS2XzcxHgEea758F3jv+kiS1wbXxLZn14XtXrHzVnIbnclmpCMOuNe3Zs6cTS3Uz09HSiAy7VITvVNMSu1A7PHdfn+9UIxXnbLxmiktqh2dnl4ow7FIRDuPHzIm5djl0H56dXSrCzq6ZYEcfnZ1dKsLOPoJxvUOLVmdHHx87u1SEYZeKMOxSEYZdKsKwj9mRI0dKfia4us+wS0V46a0lS929C+/yMk3DHgcvuY2fnV0qws6uVg3S0Z3jmAw7u1SEYZeKcBivVm1kiL70Oe9qh51dKsK3kh7CsK92q3gZbtjJN7v88Hwraak4wz6EvXv32nk0cwy7VISz8RNUaQmtC2W6x84uFWHYpSIcxk9BpeH8Rjjp2S47u1TEQJ09IjYDdwFXAQn8IXASuBfYAfwI2JuZ51qpck7NW4d3AU23DdrZvwJ8MzPfAbwLOAEcAI5l5i7gWLMtqaPWXS4bEZcA/wpcmctuHBEngesy82xEbAUeycy3r/NYc7FcdskkPiRiFrq+Hb1bRlkueyXwMvC1iHgiIu6KiIuByzPzbPPgZ4HL+t05IvZHxGJELA5Zu6QxGCTsC8B7gK9m5tXAz9jAkD0zD2bm7szcPWSNksZgkGH8W4DvZuaOZvs36YX91yk+jF9SdTg/6io5h/HtGHoYn5k/Bp6PiKUgXw88DRwF9jX79gEPjqFOSS0Z6PXsEfFuepfeLgCeBf6A3i+Kw8DbgNPAnsx8ZZ3HmcvOvlyFLj9KR7ebt2+1zj7QdfbM/B7Q75z7+lGKkjQ5vlNNy+al03t+Pjt8pxqpODv7BE2iy3eNHX3y7OxScYZdKsLXs7dsnofuDtFni51dKsIJuimaha5v9549TtBJxdnZO2aQbr9Wtx3XaMGOPrvs7FJxdvY5N2ynt7PPLju7VJxhl4pwGF/E8uG8Q/T55jBeKs7OLs0ZO7tUnGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRA4U9Ij4TEU9FxJMR8Y2IuDAidkbEoxHxTETcGxEXtF2spOGtG/aI2AZ8GtidmVcBm4CbgduBOzJzF3AOuKXNQiWNZtBh/ALwyxGxAFwEnAU+CNzX/Pwe4BPjL0/SuKwb9sx8AfgScJpeyH8KHAdezczzzc3OANvaKlLS6AYZxl8K3ATsBN4KXAx8rM9N+74nfETsj4jFiFgcpVBJo1kY4DYfAp7LzJcBIuIB4H3A5ohYaLr7duDFfnfOzIPAwea+fkiENCWDnLOfBq6JiIsiIoDrgaeBh4FPNrfZBzzYTomSxmGgj3+KiC8Avw2cB54A/ojeOfohYEuz73cz87/XeRw7u9Sy1T7+yc96k+aMn/UmFWfYpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRhl0qwrBLRRh2qQjDLhVh2KUiDLtUhGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKmJhws/3H8DPmq+z5FeZvZphNuu25tH82mo/mOjnswNExGJm7p7ok45oFmuG2azbmtvjMF4qwrBLRUwj7Aen8JyjmsWaYTbrtuaWTPycXdJ0OIyXijDsUhETC3tEfDQiTkbEqYg4MKnn3aiIuCIiHo6IExHxVETc2uzfEhHfjohnmq+XTrvWlSJiU0Q8EREPNds7I+LRpuZ7I+KCade4XERsjoj7IuIHzfG+dkaO82ea/xtPRsQ3IuLCrh9rmFDYI2IT8DfAx4B3Ap+KiHdO4rmHcB74s8z8DeAa4I+bWg8AxzJzF3Cs2e6aW4ETy7ZvB+5oaj4H3DKVqlb3FeCbmfkO4F30au/0cY6IbcCngd2ZeRWwCbiZ7h9ryMzW/wDXAt9atn0bcNsknnsMtT8IfBg4CWxt9m0FTk67thV1bqcXjg8CDwFBb1XXQr9/g2n/AS4BnqOZJF62v+vHeRvwPLCF3grUh4CPdPlYL/2Z1DB+6QAtOdPs67SI2AFcDTwKXJ6ZZwGar5dNr7K+7gQ+B7zWbL8ZeDUzzzfbXTvmVwIvA19rTj3uioiL6fhxzswXgC8Bp4GzwE+B43T7WAOTO2ePPvs6fc0vIt4E3A/8aWb+57TrWUtE3Ai8lJnHl+/uc9MuHfMF4D3AVzPzanqvmejUkL2fZg7hJmAn8FbgYnqnpyt16VgDkwv7GeCKZdvbgRcn9NwbFhFvoBf0r2fmA83un0TE1ubnW4GXplVfH+8HPh4RPwIO0RvK3wlsjoilFzt17ZifAc5k5qPN9n30wt/l4wzwIeC5zHw5M/8XeAB4H90+1sDkwv4YsKuZsbyA3oTG0Qk994ZERAB3Aycy88vLfnQU2Nd8v4/euXwnZOZtmbk9M3fQO7b/lJm/AzwMfLK5Wddq/jHwfES8vdl1PfA0HT7OjdPANRFxUfN/Zanuzh7r101wYuMG4IfAvwN/Oe3JijXq/AC9Idj3ge81f26gdw58DHim+bpl2rWuUv91wEPN91cC/wKcAo4Ab5x2fStqfTew2BzrfwQunYXjDHwB+AHwJPAPwBu7fqwz0+WyUhWuoJOKMOxSEYZdKsKwS0UYdqkIwy4VYdilIv4PCYBWtFdjvd4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.6086775128646854\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.511404366243076\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.45355183878633665\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.4997028670498058\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.7005453251179201\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.7026803938930296\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.4784224618594875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.3117666942193363\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANDklEQVR4nO3dX6xlZXnH8e+vcxwpWDKMDXScoWVIJ1pDopiJQWkTApoqNcIFjBjbTFuauWkj2jYI7ZUXTSQ1BS8akwnWkMYIM0gK4UJjptC7jswIbYFxhIIZRkahBWzjRdOJTy/2Os3pdB/OPmf/W/u8309ycs5aZ/95WMzvPO/7rrX3TlUhafP7uXkXIGk2DLvUCMMuNcKwS40w7FIjDLvUiLHCnuQjSU4meT7JHZMqStLkZaPn2ZNsAb4PfBg4DTwBfLKqnp1ceZImZWmM+74feL6qXgBIcj9wA7Bq2JN4BY80ZVWVYfvHGcbvBF5asX262/d/JDmQ5FiSY2M8l6QxjdPZh/31+H+du6oOAgfBzi7N0zid/TRw6YrtXcDL45UjaVrGCfsTwJ4ku5NsBW4BHplMWZImbcPD+Ko6m+SPgG8BW4C/qapnJlaZpIna8Km3DT2Zc3Zp6qaxGi9pgRh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcasTTvAjQbN99888Qe6/DhwxN7LM2OnV1qRKpqdk+WzO7JFtQkO3CfOBqYnarKsP12dqkRdvY52qxdfKPs/pOx4c6e5NIkjyU5keSZJLd1+7cn+XaS57rvF026aEmTs2ZnT7ID2FFV303yC8Bx4Ebgd4HXquoLSe4ALqqqz63xWHZ27OjjsPuvbcOdvarOVNV3u5//EzgB7ARuAO7rbnYfgz8AknpqXefZk1wGXAkcBS6pqjMw+IOQ5OJV7nMAODBemZLGNfICXZK3Af8A/EVVPZTkjaratuL3r1fVm87bWx/GrzZ8X4Rh/SINnxep1mkY69RbkrcA3wC+VlUPdbt/3M3nl+f1r0yiUEnTMcoCXRjMyV+rqs+s2P+XwL+vWKDbXlW3r/FYdnYWo5OPYpE66CLVOq7VOvsoc/argd8B/iXJU92+PwO+ABxKcitwCtgc/4KlTcqLaqbs0KFDU3vsUUYI8+pofeukfatnmrxcVmqcnX1KJtXR5zW/n1Qn7EtH7Usds2Bnlxpn2KVGOIyfsFGG74t06m3Sw18XDKfPYbzUODv7GNa7CLdIHf3NLNLiXUsdfZmdXWqcnX0D1tPRN0s3H6avHb7Fbr6SnV1qnGGXGuEwfh0cvg/Xt+G8w3iH8VLT/PinNWy2i2SmYfm/f94ddd7P33d2dqkRdvZV2NEXhx19NHZ2qRF29nNM851l9OZWjpTs1pNnZ5caYdilRjiM3wAX5oZzGN5vdnapEXb2jgtzkzXuhTZ9uVBnM7GzS42ws6+Dc/V+seuvj51dakTTL3Ft9T3k+mI9nXn5tnbztfkSV6lxhl1qhAt0mpv1nF5z+D4+O7vUiCY7uxfQqEV2dqkRTXb29fB0mzYLO7vUCMMuNWLksCfZkuTJJI9227uTHE3yXJIHkmydXplq3aFDh1xYHdN6OvttwIkV23cBd1fVHuB14NZJFiZpskYKe5JdwG8B93bbAa4FHuxuch9w4zQKlDQZo3b2e4DbgZ91228H3qiqs932aWDnsDsmOZDkWJJjY1UqaSxrnnpL8jHglao6nuSa5d1Dbjr0FW1VdRA42D3WXF/15pyvn3xXmtkY5Tz71cDHk1wPnAdcyKDTb0uy1HX3XcDL0ytT0rjWDHtV3QncCdB19j+tqk8lOQzcBNwP7AcenmKdaty+ffvmXcLCG+c8++eAP07yPIM5/FcmU5KkaVjX5bJV9TjwePfzC8D7J1+SpGnw2vhVeE28Nhsvl5Ua0VTY9+3b50KPmtVU2KWWOWfX3HkxzWzY2aVGGHapEYZdaoRhlxph2KVGGHapEZ56W8Xy6SAvm52eUU65eRHU5NjZpUY0GXYvm1WLmgy71CLDLjXCBTrN1KjXwTvNmjw7u9QIO/saVnYiT8NtnK9smz87u9SIpjv7ynmhHyAxHXb0/rCzS41ourOrX1yBny47u9QIwy41IlWz+2DVeX+K6yhGWajzFNzaNrIw5zB+Mqpq2Kcs29mlVtjZV2GHX7+Nnmazo0+WnV1qnKfexuC72QzY0ReDnV1qhHP2Naz3MtqWurwr7v3knF1qnGGXGuEwfh3WM6TfzMN5h+/95jBeatxIp96SbAPuBa4ACvh94CTwAHAZ8ANgX1W9PpUqF9BmOy3n6bXFN2pn/xLwzap6F/Ae4ARwB3CkqvYAR7ptST215pw9yYXAPwGX14obJzkJXFNVZ5LsAB6vqneu8VgLPWdf1sLcfdx3mLGjz884c/bLgVeBryZ5Msm9SS4ALqmqM92DnwEuHnbnJAeSHEtybIO1S5qAUcK+BLwP+HJVXQn8lHUM2avqYFXtraq9G6xR0gSMMoz/JeAfq+qybvs3GIT9V2l0GH+uabxZ5SyG/5N+M0iH7v2w4WF8Vf0IeCnJcpCvA54FHgH2d/v2Aw9PoE5JUzLSRTVJ3svg1NtW4AXg9xj8oTgE/DJwCri5ql5b43E2ZWcfZpZvTT1sFDDLt3C2o/fLap19pPPsVfUUMGzOfd04RUmaHS+XnbLN/OETdvR+8nJZqXG+U41GYhdffHZ2qRGGXWqEC3RzsAiLdg7bF5cLdFLj7Ow9MO9ObxffXOzsUuPs7AtoPSMBu3Z77OxS4+zs0iZjZ5caZ9ilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWrESGFP8tkkzyR5OsnXk5yXZHeSo0meS/JAkq3TLlbSxq0Z9iQ7gU8De6vqCmALcAtwF3B3Ve0BXgdunWahksYz6jB+Cfj5JEvA+cAZ4Frgwe739wE3Tr48SZOyZtir6ofAF4FTDEL+E+A48EZVne1udhrYOa0iJY1vlGH8RcANwG7gHcAFwEeH3HTohzYmOZDkWJJj4xQqaTxLI9zmQ8CLVfUqQJKHgA8C25Isdd19F/DysDtX1UHgYHdfP8VVmpNR5uyngKuSnJ8kwHXAs8BjwE3dbfYDD0+nREmTMNLnsyf5PPAJ4CzwJPAHDObo9wPbu32/XVX/tcbj2NmlKVvt89lHCvukGHZp+lYLu1fQSY0w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjlmb8fP8G/LT7vkh+kcWrGRazbmsez6+s9ouZfj47QJJjVbV3pk86pkWsGRazbmueHofxUiMMu9SIeYT94Byec1yLWDMsZt3WPCUzn7NLmg+H8VIjDLvUiJmFPclHkpxM8nySO2b1vOuV5NIkjyU5keSZJLd1+7cn+XaS57rvF8271nMl2ZLkySSPdtu7kxztan4gydZ517hSkm1JHkzyve54f2BBjvNnu38bTyf5epLz+n6sYUZhT7IF+Gvgo8C7gU8mefcsnnsDzgJ/UlW/BlwF/GFX6x3AkaraAxzptvvmNuDEiu27gLu7ml8Hbp1LVav7EvDNqnoX8B4Gtff6OCfZCXwa2FtVVwBbgFvo/7GGqpr6F/AB4Fsrtu8E7pzFc0+g9oeBDwMngR3dvh3AyXnXdk6duxiE41rgUSAMrupaGvb/YN5fwIXAi3SLxCv29/047wReArYzuAL1UeA3+3ysl79mNYxfPkDLTnf7ei3JZcCVwFHgkqo6A9B9v3h+lQ11D3A78LNu++3AG1V1ttvu2zG/HHgV+Go39bg3yQX0/DhX1Q+BLwKngDPAT4Dj9PtYA7Obs2fIvl6f80vyNuAbwGeq6j/mXc+bSfIx4JWqOr5y95Cb9umYLwHvA75cVVcyeM1Er4bsw3RrCDcAu4F3ABcwmJ6eq0/HGphd2E8Dl67Y3gW8PKPnXrckb2EQ9K9V1UPd7h8n2dH9fgfwyrzqG+Jq4ONJfgDcz2Aofw+wLcnyi536dsxPA6er6mi3/SCD8Pf5OAN8CHixql6tqv8GHgI+SL+PNTC7sD8B7OlWLLcyWNB4ZEbPvS5JAnwFOFFVf7XiV48A+7uf9zOYy/dCVd1ZVbuq6jIGx/bvq+pTwGPATd3N+lbzj4CXkryz23Ud8Cw9Ps6dU8BVSc7v/q0s193bY/2/ZriwcT3wfeBfgT+f92LFm9T56wyGYP8MPNV9Xc9gDnwEeK77vn3eta5S/zXAo93PlwPfAZ4HDgNvnXd959T6XuBYd6z/DrhoEY4z8Hnge8DTwN8Cb+37sa4qL5eVWuEVdFIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNeJ/AJBfEuA4Vfy4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.5392465367124557\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.5511263653009201\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.3266977196852899\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.5166555513822378\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.5824422095622834\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.48734304233449954\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAM5ElEQVR4nO3dX4yldX3H8fenuyIFS2BtwHWXliXdaA2JYogBaRMiGpVQ8cLdYlqzbWn2po2obRTam3rRRBIjeNHabKCGNEZggRTChcZQuOhFKcOfWmBdoWiWhVVoBG28aLvx24vzTHu6nmHOzPn3nPm9X8lk5nnm/PnOs/uZ7+/3O8+ZJ1WFpK3vFxZdgKT5MOxSIwy71AjDLjXCsEuNMOxSIyYKe5IPJTma5LkkN0yrKEnTl82+zp5kG/Bd4APAceBR4ONV9cz0ypM0LdsnuO97gOeq6nmAJHcA1wBrhj2JZ/BIM1ZVGbV/kmH8LuCFoe3j3b7/J8nBJCtJViZ4LkkTmqSzj/rt8XOdu6oOAYfAzi4t0iSd/Thw/tD2buClycqRNCuThP1RYG+SPUlOA64F7p9OWZKmbdPD+Ko6meSPgW8C24C/raqnp1aZpKna9Etvm3oy5+zSzM1iNV7SEjHsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9SISa71ph7bt2/fokvYsMOHDy+6hC3Nzi41wivCbAHL2MXHZbffOK8IIzXOzr6EtnInn4SjgAE7u9Q4O3tP2b1no4Xub2eXGmfYpUY4jO8Zh+/zt9WG9g7jpcZ5umwP2M01D3Z2qRHO2RfIjt4vW2Xuvuk5e5LzkzyU5EiSp5Nc3+3fkeRbSZ7tPp8z7aIlTc+6nT3JTmBnVT2e5JeAx4CPAr8H/KiqvpDkBuCcqvrcOo9lZx9iZ++nZe/wm+7sVXWiqh7vvv4P4AiwC7gGuL272e0MfgFI6qkNrcYnuQC4GHgEOK+qTsDgF0KSc9e4z0Hg4GRlSprU2GFP8ibgHuBTVfWTZORI4edU1SHgUPcYDuOlBRnrpbckb2AQ9K9V1b3d7h928/nVef3LsylR0jSMsxof4DbgSFV9aehb9wMHuq8PAPdNvzxJ0zLOMP5y4BPAvyZ5stv3Z8AXgLuSXAccA1xalnps3bBX1T8Ca03Qr5xuOZJmxdNlpUb4RhjpFMMnOy37CTbD7OxSIwy71AjDLjXCsEuNcIFOOsVWWpQbZmeXGmHYpUYYdqkRhl1qhGGXGmHYpUb40pvU2aovua2ys0uNMOxSIwy71Ajn7GreVp+rr7KzS40w7FIjHMZvAdO6Zlwrw1lo62ddZWeXGuH12Xtgo515EVd/3WqdcKv9PMM2fRVXSVuDnb3n7rrrrkWXsKZl7I7LWPNG2dmlxtnZe6DP3Xscy9Atl6HGabGzS40z7FIjDLsmtm/fvoW8HKiNMexSI1ygW6BpLcz1+XTZRS+MLfr5F8EFOqlxdvYF6FtHH8e0OuS8O62d/f/Y2aVGGHapEWMP45NsA1aAF6vq6iR7gDuAHcDjwCeq6r/WeQyH8WxsGN/nl7QmHSLPaojd4tB92DSG8dcDR4a2bwJurqq9wKvAdZsvT9KsjdXZk+wGbgf+EvgM8FvAK8BbqupkksuAv6iqD67zOE139nE6ep87+VoW3eFb7+SnmrSz3wJ8FvhZt/1m4LWqOtltHwd2jbpjkoNJVpKsbKBeSVO27t+gS3I18HJVPZbkitXdI246smtX1SHgUPdYTXf2tSxjN9fyGecPTl4OfCTJVcDpwFkMOv3ZSbZ33X038NLsypQ0qQ2dVNN19j/tVuMPA/dU1R1J/gb4dlX99Tr3b66zv948fat19HnPvZ2rjzaLk2o+B3wmyXMM5vC3TfBYkmZsQ383vqoeBh7uvn4eeM/0S5I0C14kYkaW/U9NbcaoaclGhtoOy2fL02WlRhh2zZR/xaY/DLvUCOfs6o3hdY79+/cvsJKtyc4uNcLOvgAtzmFXf2ZX3BfHzi41wrBLjTDsUiMMu9QIw74Ahw8fdqFKc2fYpUYYdqkRhl1qhGGXGuEZdAvQ4hl0Wjw7u9QIO7t6w3e6zZadXWqEYZ+R/fv326nUK4ZdaoRz9gVYPVW2pVV5Tw9ePDu71AjDLjXCYbwWzoXM+bCzS43Y0FVcJ36yBq/iOmytS0Jt5YW6cRbm7OzTNYuruEpaIs7Ze2C4+22VLm9H7x87u9QI5+wLNM5lnZep09vN+8E5u9Q4wy41wgW6nluG8+gdvi8HO7vUiLE6e5KzgVuBi4AC/gA4CtwJXAB8H9hfVa/OpMotarXbjbNQN6p79rnbq3/G7exfBr5RVW8H3gkcAW4AHqyqvcCD3baknlr3pbckZwH/AlxYQzdOchS4oqpOJNkJPFxVb1vnsXzpbR3jdPlTzbvDb+S96c7V52+Sl94uBF4BvprkiSS3JjkTOK+qTnQPfgI4d9SdkxxMspJkZZO1S5qCccK+HXg38JWquhj4KRsYslfVoaq6pKou2WSNkqZgnGH8W4B/qqoLuu3fZBD2X8Nh/MxtZlg/7PWG+NP+U1EO2fth08P4qvoB8EKS1SBfCTwD3A8c6PYdAO6bQp2SZmSsc+OTvIvBS2+nAc8Dv8/gF8VdwK8Ax4B9VfWjdR7Hzr5Jk3b4WbKj98tanX2s19mr6klg1Jz7ykmKkjQ/vuttiS2q29vJ+813vUmNs7NvAbPo8Hbv5WVnlxpn2KVGOIyXthiH8VLjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUiLHCnuTTSZ5O8lSSryc5PcmeJI8keTbJnUlOm3WxkjZv3bAn2QV8Erikqi4CtgHXAjcBN1fVXuBV4LpZFippMuMO47cDv5hkO3AGcAJ4H3B39/3bgY9OvzxJ07Ju2KvqReCLwDEGIf8x8BjwWlWd7G52HNg1qyIlTW6cYfw5wDXAHuCtwJnAh0fctNa4/8EkK0lWJilU0mS2j3Gb9wPfq6pXAJLcC7wXODvJ9q677wZeGnXnqjoEHOruO/IXgqTZG2fOfgy4NMkZSQJcCTwDPAR8rLvNAeC+2ZQoaRpStX6zTfJ54LeBk8ATwB8ymKPfAezo9v1uVf3nOo9jZ5dmrKoyav9YYZ8Wwy7N3lph9ww6qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRGGXWrE9jk/378DP+0+L5NfZvlqhuWs25on86trfWOu12cHSLJSVZfM9UkntIw1w3LWbc2z4zBeaoRhlxqxiLAfWsBzTmoZa4blrNuaZ2Tuc3ZJi+EwXmqEYZcaMbewJ/lQkqNJnktyw7yed6OSnJ/koSRHkjyd5Ppu/44k30rybPf5nEXXeqok25I8keSBbntPkke6mu9MctqiaxyW5Owkdyf5Tne8L1uS4/zp7v/GU0m+nuT0vh9rmFPYk2wD/gr4MPAO4ONJ3jGP596Ek8CfVNWvA5cCf9TVegPwYFXtBR7stvvmeuDI0PZNwM1dza8C1y2kqrV9GfhGVb0deCeD2nt9nJPsAj4JXFJVFwHbgGvp/7GGqpr5B3AZ8M2h7RuBG+fx3FOo/T7gA8BRYGe3bydwdNG1nVLnbgbheB/wABAGZ3VtH/VvsOgP4Czge3SLxEP7+36cdwEvADsYnIH6APDBPh/r1Y95DeNXD9Cq492+XktyAXAx8AhwXlWdAOg+n7u4yka6Bfgs8LNu+83Aa1V1stvu2zG/EHgF+Go39bg1yZn0/DhX1YvAF4FjwAngx8Bj9PtYA/Obs2fEvl6/5pfkTcA9wKeq6ieLruf1JLkaeLmqHhvePeKmfTrm24F3A1+pqosZvGeiV0P2Ubo1hGuAPcBbgTMZTE9P1adjDcwv7MeB84e2dwMvzem5NyzJGxgE/WtVdW+3+4dJdnbf3wm8vKj6Rrgc+EiS7wN3MBjK3wKcnWT1zU59O+bHgeNV9Ui3fTeD8Pf5OAO8H/heVb1SVf8N3Au8l34fa2B+YX8U2NutWJ7GYEHj/jk994YkCXAbcKSqvjT0rfuBA93XBxjM5Xuhqm6sqt1VdQGDY/sPVfU7wEPAx7qb9a3mHwAvJHlbt+tK4Bl6fJw7x4BLk5zR/V9Zrbu3x/p/zXFh4yrgu8C/AX++6MWK16nzNxgMwb4NPNl9XMVgDvwg8Gz3eceia12j/iuAB7qvLwT+GXgOOAy8cdH1nVLru4CV7lj/PXDOMhxn4PPAd4CngL8D3tj3Y11Vni4rtcIz6KRGGHapEYZdaoRhlxph2KVGGHapEYZdasT/ADhR4J2EG7p2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.6997342388152851\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.6566424853486142\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_dice: 0.3613845257533595\n",
      "val_dice: 0.5454637970567078\n",
      "Test for Batch Size:  2\n",
      "epoch, iteration: 0 0\n",
      "loss: tensor(1.4196, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 1\n",
      "loss: tensor(1.4185, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 2\n",
      "loss: tensor(1.4164, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 3\n",
      "loss: tensor(1.4075, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 4\n",
      "loss: tensor(1.4081, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 5\n",
      "loss: tensor(1.3877, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 6\n",
      "loss: tensor(1.3914, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 7\n",
      "loss: tensor(1.3890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 8\n",
      "loss: tensor(1.3906, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 9\n",
      "loss: tensor(1.3797, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 10\n",
      "loss: tensor(1.3837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 11\n",
      "loss: tensor(1.3814, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 12\n",
      "loss: tensor(1.3761, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 13\n",
      "loss: tensor(1.3733, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 14\n",
      "loss: tensor(1.3709, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 15\n",
      "loss: tensor(1.3625, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 16\n",
      "loss: tensor(1.3534, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 17\n",
      "loss: tensor(1.3533, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 18\n",
      "loss: tensor(1.3335, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 19\n",
      "loss: tensor(1.3281, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 20\n",
      "loss: tensor(1.3202, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 21\n",
      "loss: tensor(1.3107, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 22\n",
      "loss: tensor(1.3455, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 23\n",
      "loss: tensor(1.3362, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 24\n",
      "loss: tensor(1.3343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 25\n",
      "loss: tensor(1.3232, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 26\n",
      "loss: tensor(1.3300, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 27\n",
      "loss: tensor(1.3377, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 28\n",
      "loss: tensor(1.3441, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 29\n",
      "loss: tensor(1.3291, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 30\n",
      "loss: tensor(1.3130, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 31\n",
      "loss: tensor(1.3115, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 32\n",
      "loss: tensor(1.3046, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 33\n",
      "loss: tensor(1.2865, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 34\n",
      "loss: tensor(1.2946, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 35\n",
      "loss: tensor(1.3005, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 36\n",
      "loss: tensor(1.3244, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 37\n",
      "loss: tensor(1.3043, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 38\n",
      "loss: tensor(1.2895, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 39\n",
      "loss: tensor(1.3209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 40\n",
      "loss: tensor(1.2905, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 41\n",
      "loss: tensor(1.2958, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 42\n",
      "loss: tensor(1.2611, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 43\n",
      "loss: tensor(1.2859, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 44\n",
      "loss: tensor(1.2730, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 45\n",
      "loss: tensor(1.2835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 46\n",
      "loss: tensor(1.2934, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 47\n",
      "loss: tensor(1.2603, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 48\n",
      "loss: tensor(1.2916, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 49\n",
      "loss: tensor(1.2869, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 0\n",
      "loss: tensor(1.2642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 1\n",
      "loss: tensor(1.2824, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 2\n",
      "loss: tensor(1.2408, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 3\n",
      "loss: tensor(1.2735, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 4\n",
      "loss: tensor(1.2682, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 5\n",
      "loss: tensor(1.2604, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 6\n",
      "loss: tensor(1.2379, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 7\n",
      "loss: tensor(1.2779, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 8\n",
      "loss: tensor(1.2403, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 9\n",
      "loss: tensor(1.2698, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 10\n",
      "loss: tensor(1.2602, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 11\n",
      "loss: tensor(1.2448, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 12\n",
      "loss: tensor(1.2353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 13\n",
      "loss: tensor(1.2221, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 14\n",
      "loss: tensor(1.2441, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 15\n",
      "loss: tensor(1.2614, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 16\n",
      "loss: tensor(1.2420, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 17\n",
      "loss: tensor(1.2339, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 18\n",
      "loss: tensor(1.2222, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 19\n",
      "loss: tensor(1.2382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 20\n",
      "loss: tensor(1.2104, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 21\n",
      "loss: tensor(1.2340, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 22\n",
      "loss: tensor(1.2435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 23\n",
      "loss: tensor(1.2329, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 24\n",
      "loss: tensor(1.2283, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 25\n",
      "loss: tensor(1.2317, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 26\n",
      "loss: tensor(1.2505, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 27\n",
      "loss: tensor(1.2231, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 28\n",
      "loss: tensor(1.2312, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 29\n",
      "loss: tensor(1.2443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 30\n",
      "loss: tensor(1.2141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 31\n",
      "loss: tensor(1.2263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 32\n",
      "loss: tensor(1.2275, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 33\n",
      "loss: tensor(1.2239, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 34\n",
      "loss: tensor(1.1958, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 35\n",
      "loss: tensor(1.2335, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 36\n",
      "loss: tensor(1.2090, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 37\n",
      "loss: tensor(1.2204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 38\n",
      "loss: tensor(1.2181, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 39\n",
      "loss: tensor(1.2152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 40\n",
      "loss: tensor(1.1983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 41\n",
      "loss: tensor(1.2035, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 42\n",
      "loss: tensor(1.2284, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 43\n",
      "loss: tensor(1.1936, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 44\n",
      "loss: tensor(1.2002, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 45\n",
      "loss: tensor(1.2118, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 46\n",
      "loss: tensor(1.1935, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 47\n",
      "loss: tensor(1.1716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 48\n",
      "loss: tensor(1.1827, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 49\n",
      "loss: tensor(1.1819, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 0\n",
      "loss: tensor(1.2220, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 1\n",
      "loss: tensor(1.1749, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 2\n",
      "loss: tensor(1.1792, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 3\n",
      "loss: tensor(1.1858, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 4\n",
      "loss: tensor(1.1890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 5\n",
      "loss: tensor(1.1888, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 6\n",
      "loss: tensor(1.1747, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 7\n",
      "loss: tensor(1.1901, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 8\n",
      "loss: tensor(1.1833, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 9\n",
      "loss: tensor(1.1914, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 10\n",
      "loss: tensor(1.1653, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 11\n",
      "loss: tensor(1.1833, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 2 12\n",
      "loss: tensor(1.1835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 13\n",
      "loss: tensor(1.1779, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 14\n",
      "loss: tensor(1.1611, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 15\n",
      "loss: tensor(1.1690, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 16\n",
      "loss: tensor(1.1773, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 17\n",
      "loss: tensor(1.1972, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 18\n",
      "loss: tensor(1.1453, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 19\n",
      "loss: tensor(1.1622, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 20\n",
      "loss: tensor(1.1648, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 21\n",
      "loss: tensor(1.1895, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 22\n",
      "loss: tensor(1.1635, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 23\n",
      "loss: tensor(1.1478, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 24\n",
      "loss: tensor(1.1643, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 25\n",
      "loss: tensor(1.1557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 26\n",
      "loss: tensor(1.1564, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 27\n",
      "loss: tensor(1.1552, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 28\n",
      "loss: tensor(1.1611, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 29\n",
      "loss: tensor(1.1527, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 30\n",
      "loss: tensor(1.1548, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 31\n",
      "loss: tensor(1.1483, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 32\n",
      "loss: tensor(1.1571, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 33\n",
      "loss: tensor(1.1304, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 34\n",
      "loss: tensor(1.1405, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 35\n",
      "loss: tensor(1.1639, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 36\n",
      "loss: tensor(1.1538, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 37\n",
      "loss: tensor(1.1443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 38\n",
      "loss: tensor(1.1374, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 39\n",
      "loss: tensor(1.1425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 40\n",
      "loss: tensor(1.1339, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 41\n",
      "loss: tensor(1.1358, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 42\n",
      "loss: tensor(1.1307, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 43\n",
      "loss: tensor(1.1416, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 44\n",
      "loss: tensor(1.1393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 45\n",
      "loss: tensor(1.1486, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 46\n",
      "loss: tensor(1.1420, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 47\n",
      "loss: tensor(1.1492, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 48\n",
      "loss: tensor(1.1172, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 49\n",
      "loss: tensor(1.1253, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 0\n",
      "loss: tensor(1.1425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 1\n",
      "loss: tensor(1.1527, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 2\n",
      "loss: tensor(1.1380, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 3\n",
      "loss: tensor(1.1365, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 4\n",
      "loss: tensor(1.1163, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 5\n",
      "loss: tensor(1.1397, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 6\n",
      "loss: tensor(1.1254, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 7\n",
      "loss: tensor(1.1243, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 8\n",
      "loss: tensor(1.1382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 9\n",
      "loss: tensor(1.1159, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 10\n",
      "loss: tensor(1.1221, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 11\n",
      "loss: tensor(1.1055, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 12\n",
      "loss: tensor(1.1135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 13\n",
      "loss: tensor(1.1154, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 14\n",
      "loss: tensor(1.1251, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 15\n",
      "loss: tensor(1.1120, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 16\n",
      "loss: tensor(1.1165, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 17\n",
      "loss: tensor(1.1267, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 18\n",
      "loss: tensor(1.1249, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 19\n",
      "loss: tensor(1.1080, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 20\n",
      "loss: tensor(1.1385, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 21\n",
      "loss: tensor(1.1143, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 22\n",
      "loss: tensor(1.1127, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 23\n",
      "loss: tensor(1.1141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 24\n",
      "loss: tensor(1.1153, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 25\n",
      "loss: tensor(1.1025, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 26\n",
      "loss: tensor(1.1117, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 27\n",
      "loss: tensor(1.1097, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 28\n",
      "loss: tensor(1.1098, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 29\n",
      "loss: tensor(1.1040, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 30\n",
      "loss: tensor(1.1024, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 31\n",
      "loss: tensor(1.1065, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 32\n",
      "loss: tensor(1.1366, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 33\n",
      "loss: tensor(1.1190, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 34\n",
      "loss: tensor(1.0980, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 35\n",
      "loss: tensor(1.1096, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 36\n",
      "loss: tensor(1.0875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 37\n",
      "loss: tensor(1.1014, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 38\n",
      "loss: tensor(1.0839, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 39\n",
      "loss: tensor(1.0949, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 40\n",
      "loss: tensor(1.1080, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 41\n",
      "loss: tensor(1.1005, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 42\n",
      "loss: tensor(1.0910, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 43\n",
      "loss: tensor(1.0947, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 44\n",
      "loss: tensor(1.0950, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 45\n",
      "loss: tensor(1.0961, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 46\n",
      "loss: tensor(1.0898, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 47\n",
      "loss: tensor(1.1155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 48\n",
      "loss: tensor(1.0878, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 49\n",
      "loss: tensor(1.0788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 0\n",
      "loss: tensor(1.0905, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 1\n",
      "loss: tensor(1.1144, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 2\n",
      "loss: tensor(1.0917, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 3\n",
      "loss: tensor(1.0838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 4\n",
      "loss: tensor(1.0773, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 5\n",
      "loss: tensor(1.1028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 6\n",
      "loss: tensor(1.0788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 7\n",
      "loss: tensor(1.0803, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 8\n",
      "loss: tensor(1.0835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 9\n",
      "loss: tensor(1.0767, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 10\n",
      "loss: tensor(1.0846, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 11\n",
      "loss: tensor(1.0718, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 12\n",
      "loss: tensor(1.0771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 13\n",
      "loss: tensor(1.1135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 14\n",
      "loss: tensor(1.0879, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 15\n",
      "loss: tensor(1.0625, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 16\n",
      "loss: tensor(1.0790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 17\n",
      "loss: tensor(1.0843, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 18\n",
      "loss: tensor(1.0947, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 19\n",
      "loss: tensor(1.0836, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 20\n",
      "loss: tensor(1.0879, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 21\n",
      "loss: tensor(1.0745, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 22\n",
      "loss: tensor(1.0721, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 23\n",
      "loss: tensor(1.0710, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 24\n",
      "loss: tensor(1.0607, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 4 25\n",
      "loss: tensor(1.0708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 26\n",
      "loss: tensor(1.0738, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 27\n",
      "loss: tensor(1.0742, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 28\n",
      "loss: tensor(1.0835, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 29\n",
      "loss: tensor(1.0745, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 30\n",
      "loss: tensor(1.0586, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 31\n",
      "loss: tensor(1.0592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 32\n",
      "loss: tensor(1.0767, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 33\n",
      "loss: tensor(1.0675, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 34\n",
      "loss: tensor(1.1058, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 35\n",
      "loss: tensor(1.0565, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 36\n",
      "loss: tensor(1.0514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 37\n",
      "loss: tensor(1.0656, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 38\n",
      "loss: tensor(1.0660, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 39\n",
      "loss: tensor(1.0804, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 40\n",
      "loss: tensor(1.0910, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 41\n",
      "loss: tensor(1.0660, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 42\n",
      "loss: tensor(1.0467, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 43\n",
      "loss: tensor(1.0751, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 44\n",
      "loss: tensor(1.0764, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 45\n",
      "loss: tensor(1.0966, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 46\n",
      "loss: tensor(1.0672, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 47\n",
      "loss: tensor(1.0645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 48\n",
      "loss: tensor(1.0784, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 49\n",
      "loss: tensor(1.0964, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 0\n",
      "loss: tensor(1.0567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 1\n",
      "loss: tensor(1.0653, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 2\n",
      "loss: tensor(1.0487, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 3\n",
      "loss: tensor(1.0633, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 4\n",
      "loss: tensor(1.0636, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 5\n",
      "loss: tensor(1.0606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 6\n",
      "loss: tensor(1.0891, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 7\n",
      "loss: tensor(1.0512, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 8\n",
      "loss: tensor(1.0662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 9\n",
      "loss: tensor(1.0595, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 10\n",
      "loss: tensor(1.0451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 11\n",
      "loss: tensor(1.0483, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 12\n",
      "loss: tensor(1.0586, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 13\n",
      "loss: tensor(1.0537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 14\n",
      "loss: tensor(1.0519, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 15\n",
      "loss: tensor(1.0687, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 16\n",
      "loss: tensor(1.0456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 17\n",
      "loss: tensor(1.0992, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 18\n",
      "loss: tensor(1.0548, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 19\n",
      "loss: tensor(1.0632, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 20\n",
      "loss: tensor(1.0528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 21\n",
      "loss: tensor(1.0823, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 22\n",
      "loss: tensor(1.0555, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 23\n",
      "loss: tensor(1.0452, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 24\n",
      "loss: tensor(1.0567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 25\n",
      "loss: tensor(1.0404, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 26\n",
      "loss: tensor(1.0428, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 27\n",
      "loss: tensor(1.0529, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 28\n",
      "loss: tensor(1.0569, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 29\n",
      "loss: tensor(1.0347, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 30\n",
      "loss: tensor(1.0342, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 31\n",
      "loss: tensor(1.0514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 32\n",
      "loss: tensor(1.0767, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 33\n",
      "loss: tensor(1.0394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 34\n",
      "loss: tensor(1.0645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 35\n",
      "loss: tensor(1.0447, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 36\n",
      "loss: tensor(1.0482, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 37\n",
      "loss: tensor(1.0549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 38\n",
      "loss: tensor(1.0164, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 39\n",
      "loss: tensor(1.0420, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 40\n",
      "loss: tensor(1.0294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 41\n",
      "loss: tensor(1.0298, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 42\n",
      "loss: tensor(1.0571, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 43\n",
      "loss: tensor(1.0419, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 44\n",
      "loss: tensor(1.0498, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 45\n",
      "loss: tensor(1.0402, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 46\n",
      "loss: tensor(1.0616, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 47\n",
      "loss: tensor(1.0641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 48\n",
      "loss: tensor(1.0471, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 49\n",
      "loss: tensor(1.0369, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 0\n",
      "loss: tensor(1.0428, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 1\n",
      "loss: tensor(1.0557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 2\n",
      "loss: tensor(1.0320, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 3\n",
      "loss: tensor(1.0272, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 4\n",
      "loss: tensor(1.0537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 5\n",
      "loss: tensor(1.0521, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 6\n",
      "loss: tensor(1.0684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 7\n",
      "loss: tensor(1.0592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 8\n",
      "loss: tensor(1.0454, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 9\n",
      "loss: tensor(1.0282, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 10\n",
      "loss: tensor(1.0372, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 11\n",
      "loss: tensor(1.0688, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 12\n",
      "loss: tensor(1.0464, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 13\n",
      "loss: tensor(1.0443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 14\n",
      "loss: tensor(1.0382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 15\n",
      "loss: tensor(1.0453, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 16\n",
      "loss: tensor(1.0400, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 17\n",
      "loss: tensor(1.0789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 18\n",
      "loss: tensor(1.0473, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 19\n",
      "loss: tensor(1.0506, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 20\n",
      "loss: tensor(1.0430, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 21\n",
      "loss: tensor(1.0151, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 22\n",
      "loss: tensor(1.0236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 23\n",
      "loss: tensor(1.0305, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 24\n",
      "loss: tensor(1.0117, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 25\n",
      "loss: tensor(1.0134, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 26\n",
      "loss: tensor(1.0162, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 27\n",
      "loss: tensor(1.0325, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 28\n",
      "loss: tensor(1.0218, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 29\n",
      "loss: tensor(1.0208, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 30\n",
      "loss: tensor(1.0176, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 31\n",
      "loss: tensor(1.0109, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 32\n",
      "loss: tensor(1.0375, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 33\n",
      "loss: tensor(1.0256, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 34\n",
      "loss: tensor(1.0186, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 35\n",
      "loss: tensor(1.0564, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 36\n",
      "loss: tensor(1.0123, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 37\n",
      "loss: tensor(1.0047, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 6 38\n",
      "loss: tensor(1.0249, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 39\n",
      "loss: tensor(1.0194, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 40\n",
      "loss: tensor(0.9999, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 41\n",
      "loss: tensor(1.0369, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 42\n",
      "loss: tensor(1.0340, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 43\n",
      "loss: tensor(1.0261, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 44\n",
      "loss: tensor(1.0154, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 45\n",
      "loss: tensor(1.0286, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 46\n",
      "loss: tensor(1.0105, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 47\n",
      "loss: tensor(1.0226, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 48\n",
      "loss: tensor(1.0204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 49\n",
      "loss: tensor(1.0386, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 0\n",
      "loss: tensor(1.0180, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 1\n",
      "loss: tensor(1.0344, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 2\n",
      "loss: tensor(1.0131, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 3\n",
      "loss: tensor(1.0383, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 4\n",
      "loss: tensor(1.0058, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 5\n",
      "loss: tensor(1.0173, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 6\n",
      "loss: tensor(1.0780, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 7\n",
      "loss: tensor(1.0168, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 8\n",
      "loss: tensor(1.0114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 9\n",
      "loss: tensor(1.0002, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 10\n",
      "loss: tensor(1.0294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 11\n",
      "loss: tensor(1.0107, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 12\n",
      "loss: tensor(1.0503, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 13\n",
      "loss: tensor(1.0215, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 14\n",
      "loss: tensor(1.0422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 15\n",
      "loss: tensor(1.0197, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 16\n",
      "loss: tensor(0.9946, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 17\n",
      "loss: tensor(1.0140, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 18\n",
      "loss: tensor(1.0016, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 19\n",
      "loss: tensor(0.9983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 20\n",
      "loss: tensor(1.0062, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 21\n",
      "loss: tensor(1.0007, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 22\n",
      "loss: tensor(1.0360, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 23\n",
      "loss: tensor(1.0422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 24\n",
      "loss: tensor(1.0250, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 25\n",
      "loss: tensor(1.0080, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 26\n",
      "loss: tensor(1.0258, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 27\n",
      "loss: tensor(1.0379, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 28\n",
      "loss: tensor(1.0185, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 29\n",
      "loss: tensor(1.0261, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 30\n",
      "loss: tensor(1.0103, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 31\n",
      "loss: tensor(1.0412, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 32\n",
      "loss: tensor(0.9983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 33\n",
      "loss: tensor(0.9903, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 34\n",
      "loss: tensor(0.9898, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 35\n",
      "loss: tensor(1.0236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 36\n",
      "loss: tensor(1.0144, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 37\n",
      "loss: tensor(1.0051, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 38\n",
      "loss: tensor(0.9993, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 39\n",
      "loss: tensor(0.9965, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 40\n",
      "loss: tensor(0.9981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 41\n",
      "loss: tensor(1.0063, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 42\n",
      "loss: tensor(1.0218, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 43\n",
      "loss: tensor(0.9912, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 44\n",
      "loss: tensor(1.0038, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 45\n",
      "loss: tensor(0.9733, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 46\n",
      "loss: tensor(1.0225, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 47\n",
      "loss: tensor(1.0353, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 48\n",
      "loss: tensor(1.0024, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 49\n",
      "loss: tensor(0.9904, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 0\n",
      "loss: tensor(1.0140, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 1\n",
      "loss: tensor(0.9938, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 2\n",
      "loss: tensor(0.9752, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 3\n",
      "loss: tensor(1.0720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 4\n",
      "loss: tensor(0.9970, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 5\n",
      "loss: tensor(0.9997, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 6\n",
      "loss: tensor(1.0316, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 7\n",
      "loss: tensor(0.9878, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 8\n",
      "loss: tensor(0.9823, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 9\n",
      "loss: tensor(0.9758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 10\n",
      "loss: tensor(1.0159, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 11\n",
      "loss: tensor(1.0233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 12\n",
      "loss: tensor(1.0254, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 13\n",
      "loss: tensor(1.0091, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 14\n",
      "loss: tensor(1.0052, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 15\n",
      "loss: tensor(1.0000, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 16\n",
      "loss: tensor(0.9844, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 17\n",
      "loss: tensor(1.0061, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 18\n",
      "loss: tensor(0.9799, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 19\n",
      "loss: tensor(1.0000, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 20\n",
      "loss: tensor(0.9740, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 21\n",
      "loss: tensor(1.0019, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 22\n",
      "loss: tensor(0.9915, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 23\n",
      "loss: tensor(1.0051, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 24\n",
      "loss: tensor(0.9898, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 25\n",
      "loss: tensor(0.9887, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 26\n",
      "loss: tensor(1.0207, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 27\n",
      "loss: tensor(1.0186, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 28\n",
      "loss: tensor(1.0092, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 29\n",
      "loss: tensor(0.9932, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 30\n",
      "loss: tensor(1.0086, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 31\n",
      "loss: tensor(0.9958, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 32\n",
      "loss: tensor(0.9974, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 33\n",
      "loss: tensor(1.0039, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 34\n",
      "loss: tensor(1.0057, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 35\n",
      "loss: tensor(0.9864, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 36\n",
      "loss: tensor(1.0147, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 37\n",
      "loss: tensor(1.0068, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 38\n",
      "loss: tensor(0.9938, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 39\n",
      "loss: tensor(1.0137, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 40\n",
      "loss: tensor(0.9696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 41\n",
      "loss: tensor(1.0202, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 42\n",
      "loss: tensor(1.0112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 43\n",
      "loss: tensor(0.9963, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 44\n",
      "loss: tensor(1.0383, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 45\n",
      "loss: tensor(1.0018, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 46\n",
      "loss: tensor(0.9807, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 47\n",
      "loss: tensor(0.9809, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 48\n",
      "loss: tensor(0.9810, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 49\n",
      "loss: tensor(0.9726, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 0\n",
      "loss: tensor(0.9918, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 9 1\n",
      "loss: tensor(0.9758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 2\n",
      "loss: tensor(1.0156, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 3\n",
      "loss: tensor(0.9932, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 4\n",
      "loss: tensor(0.9710, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 5\n",
      "loss: tensor(0.9782, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 6\n",
      "loss: tensor(1.0095, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 7\n",
      "loss: tensor(0.9877, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 8\n",
      "loss: tensor(0.9759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 9\n",
      "loss: tensor(0.9897, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 10\n",
      "loss: tensor(0.9845, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 11\n",
      "loss: tensor(1.0375, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 12\n",
      "loss: tensor(0.9874, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 13\n",
      "loss: tensor(1.0243, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 14\n",
      "loss: tensor(0.9684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 15\n",
      "loss: tensor(1.0041, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 16\n",
      "loss: tensor(0.9764, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 17\n",
      "loss: tensor(0.9881, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 18\n",
      "loss: tensor(0.9695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 19\n",
      "loss: tensor(1.0204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 20\n",
      "loss: tensor(0.9746, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 21\n",
      "loss: tensor(0.9878, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 22\n",
      "loss: tensor(0.9942, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 23\n",
      "loss: tensor(0.9614, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 24\n",
      "loss: tensor(0.9915, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 25\n",
      "loss: tensor(1.0190, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 26\n",
      "loss: tensor(0.9842, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 27\n",
      "loss: tensor(0.9934, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 28\n",
      "loss: tensor(0.9774, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 29\n",
      "loss: tensor(1.0476, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 30\n",
      "loss: tensor(0.9680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 31\n",
      "loss: tensor(0.9504, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 32\n",
      "loss: tensor(1.0040, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 33\n",
      "loss: tensor(1.0079, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 34\n",
      "loss: tensor(1.0197, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 35\n",
      "loss: tensor(0.9957, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 36\n",
      "loss: tensor(0.9718, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 37\n",
      "loss: tensor(1.0028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 38\n",
      "loss: tensor(0.9630, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 39\n",
      "loss: tensor(0.9816, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 40\n",
      "loss: tensor(1.0074, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 41\n",
      "loss: tensor(0.9632, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 42\n",
      "loss: tensor(0.9637, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 43\n",
      "loss: tensor(0.9787, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 44\n",
      "loss: tensor(0.9916, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 45\n",
      "loss: tensor(0.9852, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 46\n",
      "loss: tensor(0.9931, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 47\n",
      "loss: tensor(0.9925, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 48\n",
      "loss: tensor(1.0502, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 49\n",
      "loss: tensor(0.9596, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 0\n",
      "loss: tensor(0.9864, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 1\n",
      "loss: tensor(0.9989, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 2\n",
      "loss: tensor(0.9698, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 3\n",
      "loss: tensor(0.9771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 4\n",
      "loss: tensor(0.9746, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 5\n",
      "loss: tensor(1.0112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 6\n",
      "loss: tensor(0.9775, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 7\n",
      "loss: tensor(0.9820, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 8\n",
      "loss: tensor(1.0005, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 9\n",
      "loss: tensor(0.9570, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 10\n",
      "loss: tensor(0.9781, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 11\n",
      "loss: tensor(0.9756, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 12\n",
      "loss: tensor(0.9914, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 13\n",
      "loss: tensor(0.9546, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 14\n",
      "loss: tensor(0.9685, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 15\n",
      "loss: tensor(0.9783, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 16\n",
      "loss: tensor(0.9908, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 17\n",
      "loss: tensor(0.9708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 18\n",
      "loss: tensor(0.9734, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 19\n",
      "loss: tensor(0.9875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 20\n",
      "loss: tensor(1.0458, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 21\n",
      "loss: tensor(0.9872, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 22\n",
      "loss: tensor(0.9568, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 23\n",
      "loss: tensor(0.9463, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 24\n",
      "loss: tensor(0.9621, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 25\n",
      "loss: tensor(0.9767, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 26\n",
      "loss: tensor(0.9690, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 27\n",
      "loss: tensor(0.9784, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 28\n",
      "loss: tensor(0.9586, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 29\n",
      "loss: tensor(0.9924, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 30\n",
      "loss: tensor(0.9838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 31\n",
      "loss: tensor(1.0008, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 32\n",
      "loss: tensor(0.9988, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 33\n",
      "loss: tensor(0.9659, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 34\n",
      "loss: tensor(0.9867, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 35\n",
      "loss: tensor(0.9908, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 36\n",
      "loss: tensor(0.9530, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 37\n",
      "loss: tensor(0.9505, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 38\n",
      "loss: tensor(0.9807, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 39\n",
      "loss: tensor(1.0060, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 40\n",
      "loss: tensor(1.0281, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 41\n",
      "loss: tensor(0.9755, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 42\n",
      "loss: tensor(0.9920, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 43\n",
      "loss: tensor(0.9626, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 44\n",
      "loss: tensor(0.9799, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 45\n",
      "loss: tensor(0.9788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 46\n",
      "loss: tensor(0.9503, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 47\n",
      "loss: tensor(1.0016, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 48\n",
      "loss: tensor(0.9550, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 10 49\n",
      "loss: tensor(1.0169, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 0\n",
      "loss: tensor(0.9861, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 1\n",
      "loss: tensor(0.9982, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 2\n",
      "loss: tensor(0.9554, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 3\n",
      "loss: tensor(0.9876, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 4\n",
      "loss: tensor(0.9532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 5\n",
      "loss: tensor(1.0279, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 6\n",
      "loss: tensor(0.9773, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 7\n",
      "loss: tensor(1.0103, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 8\n",
      "loss: tensor(0.9718, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 9\n",
      "loss: tensor(0.9797, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 10\n",
      "loss: tensor(0.9985, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 11\n",
      "loss: tensor(0.9417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 12\n",
      "loss: tensor(0.9538, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 11 13\n",
      "loss: tensor(0.9631, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 14\n",
      "loss: tensor(0.9856, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 15\n",
      "loss: tensor(0.9567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 16\n",
      "loss: tensor(0.9752, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 17\n",
      "loss: tensor(0.9744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 18\n",
      "loss: tensor(1.0113, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 19\n",
      "loss: tensor(0.9691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 20\n",
      "loss: tensor(0.9798, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 21\n",
      "loss: tensor(0.9629, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 22\n",
      "loss: tensor(0.9435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 23\n",
      "loss: tensor(0.9671, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 24\n",
      "loss: tensor(0.9533, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 25\n",
      "loss: tensor(0.9724, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 26\n",
      "loss: tensor(0.9843, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 27\n",
      "loss: tensor(1.0513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 28\n",
      "loss: tensor(0.9425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 29\n",
      "loss: tensor(1.0009, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 30\n",
      "loss: tensor(0.9825, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 31\n",
      "loss: tensor(0.9598, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 32\n",
      "loss: tensor(0.9646, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 33\n",
      "loss: tensor(0.9439, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 34\n",
      "loss: tensor(0.9603, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 35\n",
      "loss: tensor(0.9627, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 36\n",
      "loss: tensor(0.9573, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 37\n",
      "loss: tensor(0.9967, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 38\n",
      "loss: tensor(0.9667, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 39\n",
      "loss: tensor(0.9624, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 40\n",
      "loss: tensor(0.9655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 41\n",
      "loss: tensor(0.9386, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 42\n",
      "loss: tensor(0.9491, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 43\n",
      "loss: tensor(0.9837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 44\n",
      "loss: tensor(0.9695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 45\n",
      "loss: tensor(0.9717, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 46\n",
      "loss: tensor(0.9566, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 47\n",
      "loss: tensor(0.9477, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 48\n",
      "loss: tensor(0.9346, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 11 49\n",
      "loss: tensor(0.9801, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 0\n",
      "loss: tensor(0.9913, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 1\n",
      "loss: tensor(0.9890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 2\n",
      "loss: tensor(1.0086, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 3\n",
      "loss: tensor(0.9723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 4\n",
      "loss: tensor(0.9941, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 5\n",
      "loss: tensor(0.9782, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 6\n",
      "loss: tensor(0.9796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 7\n",
      "loss: tensor(0.9320, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 8\n",
      "loss: tensor(0.9516, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 9\n",
      "loss: tensor(0.9657, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 10\n",
      "loss: tensor(1.0150, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 11\n",
      "loss: tensor(0.9537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 12\n",
      "loss: tensor(0.9585, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 13\n",
      "loss: tensor(0.9514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 14\n",
      "loss: tensor(0.9521, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 15\n",
      "loss: tensor(0.9540, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 16\n",
      "loss: tensor(0.9776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 17\n",
      "loss: tensor(1.0090, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 18\n",
      "loss: tensor(0.9567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 19\n",
      "loss: tensor(0.9553, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 20\n",
      "loss: tensor(0.9511, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 21\n",
      "loss: tensor(0.9502, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 22\n",
      "loss: tensor(0.9592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 23\n",
      "loss: tensor(0.9720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 24\n",
      "loss: tensor(0.9345, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 25\n",
      "loss: tensor(0.9671, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 26\n",
      "loss: tensor(0.9343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 27\n",
      "loss: tensor(0.9398, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 28\n",
      "loss: tensor(0.9779, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 29\n",
      "loss: tensor(0.9762, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 30\n",
      "loss: tensor(1.0412, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 31\n",
      "loss: tensor(0.9588, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 32\n",
      "loss: tensor(0.9446, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 33\n",
      "loss: tensor(0.9714, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 34\n",
      "loss: tensor(0.9781, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 35\n",
      "loss: tensor(1.0131, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 36\n",
      "loss: tensor(0.9427, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 37\n",
      "loss: tensor(0.9597, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 38\n",
      "loss: tensor(0.9394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 39\n",
      "loss: tensor(0.9372, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 40\n",
      "loss: tensor(0.9741, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 41\n",
      "loss: tensor(0.9699, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 42\n",
      "loss: tensor(0.9679, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 43\n",
      "loss: tensor(0.9447, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 44\n",
      "loss: tensor(0.9784, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 45\n",
      "loss: tensor(0.9853, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 46\n",
      "loss: tensor(0.9528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 47\n",
      "loss: tensor(0.9306, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 48\n",
      "loss: tensor(0.9591, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 12 49\n",
      "loss: tensor(0.9456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 0\n",
      "loss: tensor(0.9822, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 1\n",
      "loss: tensor(0.9921, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 2\n",
      "loss: tensor(0.9708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 3\n",
      "loss: tensor(0.9522, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 4\n",
      "loss: tensor(1.0060, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 5\n",
      "loss: tensor(0.9494, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 6\n",
      "loss: tensor(0.9543, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 7\n",
      "loss: tensor(0.9333, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 8\n",
      "loss: tensor(0.9341, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 9\n",
      "loss: tensor(1.0506, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 10\n",
      "loss: tensor(0.9638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 11\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 12\n",
      "loss: tensor(0.9787, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 13\n",
      "loss: tensor(0.9514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 14\n",
      "loss: tensor(0.9594, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 15\n",
      "loss: tensor(0.9479, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 16\n",
      "loss: tensor(0.9450, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 17\n",
      "loss: tensor(0.9321, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 18\n",
      "loss: tensor(0.9312, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 19\n",
      "loss: tensor(0.9390, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 20\n",
      "loss: tensor(0.9810, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 21\n",
      "loss: tensor(0.9646, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 22\n",
      "loss: tensor(0.9789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 23\n",
      "loss: tensor(0.9493, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 13 24\n",
      "loss: tensor(1.0150, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 25\n",
      "loss: tensor(0.9409, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 26\n",
      "loss: tensor(0.9541, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 27\n",
      "loss: tensor(0.9514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 28\n",
      "loss: tensor(0.9888, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 29\n",
      "loss: tensor(0.9647, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 30\n",
      "loss: tensor(0.9611, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 31\n",
      "loss: tensor(0.9832, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 32\n",
      "loss: tensor(0.9489, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 33\n",
      "loss: tensor(0.9484, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 34\n",
      "loss: tensor(0.9382, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 35\n",
      "loss: tensor(0.9448, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 36\n",
      "loss: tensor(0.9502, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 37\n",
      "loss: tensor(0.9479, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 38\n",
      "loss: tensor(0.9452, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 39\n",
      "loss: tensor(0.9618, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 40\n",
      "loss: tensor(0.9597, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 41\n",
      "loss: tensor(0.9140, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 42\n",
      "loss: tensor(0.9792, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 43\n",
      "loss: tensor(0.9558, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 44\n",
      "loss: tensor(0.9433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 45\n",
      "loss: tensor(0.9462, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 46\n",
      "loss: tensor(0.9533, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 47\n",
      "loss: tensor(0.9629, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 48\n",
      "loss: tensor(0.9529, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 13 49\n",
      "loss: tensor(0.9410, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 0\n",
      "loss: tensor(1.0012, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 1\n",
      "loss: tensor(0.9570, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 2\n",
      "loss: tensor(0.9593, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 3\n",
      "loss: tensor(0.9437, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 4\n",
      "loss: tensor(0.9724, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 5\n",
      "loss: tensor(0.9384, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 6\n",
      "loss: tensor(0.9363, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 7\n",
      "loss: tensor(0.9316, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 8\n",
      "loss: tensor(0.9487, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 9\n",
      "loss: tensor(0.9233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 10\n",
      "loss: tensor(0.9366, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 11\n",
      "loss: tensor(0.9289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 12\n",
      "loss: tensor(0.9522, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 13\n",
      "loss: tensor(0.9513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 14\n",
      "loss: tensor(0.9283, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 15\n",
      "loss: tensor(0.9578, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 16\n",
      "loss: tensor(0.9304, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 17\n",
      "loss: tensor(0.9471, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 18\n",
      "loss: tensor(0.9443, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 19\n",
      "loss: tensor(0.9370, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 20\n",
      "loss: tensor(0.9701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 21\n",
      "loss: tensor(0.9621, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 22\n",
      "loss: tensor(0.9501, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 23\n",
      "loss: tensor(0.9230, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 24\n",
      "loss: tensor(0.9522, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 25\n",
      "loss: tensor(0.9404, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 26\n",
      "loss: tensor(0.9750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 27\n",
      "loss: tensor(0.9850, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 28\n",
      "loss: tensor(0.9597, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 29\n",
      "loss: tensor(0.9538, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 30\n",
      "loss: tensor(0.9521, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 31\n",
      "loss: tensor(0.9887, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 32\n",
      "loss: tensor(0.9502, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 33\n",
      "loss: tensor(0.9345, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 34\n",
      "loss: tensor(0.9653, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 35\n",
      "loss: tensor(0.9327, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 36\n",
      "loss: tensor(1.0156, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 37\n",
      "loss: tensor(0.9682, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 38\n",
      "loss: tensor(0.9456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 39\n",
      "loss: tensor(0.9387, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 40\n",
      "loss: tensor(0.9286, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 41\n",
      "loss: tensor(1.0274, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 42\n",
      "loss: tensor(0.9584, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 43\n",
      "loss: tensor(0.9422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 44\n",
      "loss: tensor(0.9794, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 45\n",
      "loss: tensor(0.9347, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 46\n",
      "loss: tensor(0.9590, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 47\n",
      "loss: tensor(0.9590, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 48\n",
      "loss: tensor(0.9377, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 14 49\n",
      "loss: tensor(0.9387, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 0\n",
      "loss: tensor(0.9609, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 1\n",
      "loss: tensor(0.9483, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 2\n",
      "loss: tensor(0.9777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 3\n",
      "loss: tensor(0.9708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 4\n",
      "loss: tensor(0.9528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 5\n",
      "loss: tensor(0.9436, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 6\n",
      "loss: tensor(0.9436, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 7\n",
      "loss: tensor(0.9313, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 8\n",
      "loss: tensor(0.9522, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 9\n",
      "loss: tensor(0.9451, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 10\n",
      "loss: tensor(0.9053, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 11\n",
      "loss: tensor(0.9450, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 12\n",
      "loss: tensor(0.9716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 13\n",
      "loss: tensor(0.9537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 14\n",
      "loss: tensor(0.9225, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 15\n",
      "loss: tensor(0.9455, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 16\n",
      "loss: tensor(0.9930, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 17\n",
      "loss: tensor(0.9684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 18\n",
      "loss: tensor(0.9215, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 19\n",
      "loss: tensor(0.9489, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 20\n",
      "loss: tensor(0.9302, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 21\n",
      "loss: tensor(0.9178, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 22\n",
      "loss: tensor(0.9547, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 23\n",
      "loss: tensor(0.9431, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 24\n",
      "loss: tensor(0.9595, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 25\n",
      "loss: tensor(0.9519, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 26\n",
      "loss: tensor(0.9492, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 27\n",
      "loss: tensor(0.9712, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 28\n",
      "loss: tensor(0.9323, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 29\n",
      "loss: tensor(0.9538, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 30\n",
      "loss: tensor(0.9242, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 31\n",
      "loss: tensor(0.9331, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 32\n",
      "loss: tensor(0.9583, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 33\n",
      "loss: tensor(0.9122, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 34\n",
      "loss: tensor(0.9344, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 15 35\n",
      "loss: tensor(0.9601, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 36\n",
      "loss: tensor(0.9336, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 37\n",
      "loss: tensor(0.9297, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 38\n",
      "loss: tensor(0.9790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 39\n",
      "loss: tensor(0.9983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 40\n",
      "loss: tensor(0.9419, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 41\n",
      "loss: tensor(1.0175, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 42\n",
      "loss: tensor(0.9078, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 43\n",
      "loss: tensor(0.9354, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 44\n",
      "loss: tensor(0.9116, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 45\n",
      "loss: tensor(0.9575, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 46\n",
      "loss: tensor(0.9528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 47\n",
      "loss: tensor(0.9548, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 48\n",
      "loss: tensor(0.9757, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 15 49\n",
      "loss: tensor(0.9311, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 0\n",
      "loss: tensor(0.9163, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 1\n",
      "loss: tensor(0.9162, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 2\n",
      "loss: tensor(0.9395, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 3\n",
      "loss: tensor(0.9257, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 4\n",
      "loss: tensor(0.9712, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 5\n",
      "loss: tensor(0.9591, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 6\n",
      "loss: tensor(0.9194, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 7\n",
      "loss: tensor(0.9425, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 8\n",
      "loss: tensor(0.9056, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 9\n",
      "loss: tensor(0.9470, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 10\n",
      "loss: tensor(0.9612, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 11\n",
      "loss: tensor(0.9456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 12\n",
      "loss: tensor(0.9700, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 13\n",
      "loss: tensor(1.0157, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 14\n",
      "loss: tensor(0.9259, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 15\n",
      "loss: tensor(0.9698, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 16\n",
      "loss: tensor(0.9229, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 17\n",
      "loss: tensor(0.9350, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 18\n",
      "loss: tensor(0.9218, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 19\n",
      "loss: tensor(0.9356, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 20\n",
      "loss: tensor(0.9423, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 21\n",
      "loss: tensor(1.0072, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 22\n",
      "loss: tensor(0.9360, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 23\n",
      "loss: tensor(0.9476, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 24\n",
      "loss: tensor(0.9122, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 25\n",
      "loss: tensor(0.9437, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 26\n",
      "loss: tensor(0.9360, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 27\n",
      "loss: tensor(0.9064, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 28\n",
      "loss: tensor(0.9389, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 29\n",
      "loss: tensor(0.9466, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 30\n",
      "loss: tensor(0.9422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 31\n",
      "loss: tensor(0.9247, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 32\n",
      "loss: tensor(0.9283, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 33\n",
      "loss: tensor(0.9324, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 34\n",
      "loss: tensor(0.9357, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 35\n",
      "loss: tensor(0.9668, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 36\n",
      "loss: tensor(0.9394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 37\n",
      "loss: tensor(0.9634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 38\n",
      "loss: tensor(0.9193, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 39\n",
      "loss: tensor(0.9615, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 40\n",
      "loss: tensor(0.9218, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 41\n",
      "loss: tensor(0.9394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 42\n",
      "loss: tensor(0.9580, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 43\n",
      "loss: tensor(0.9320, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 44\n",
      "loss: tensor(0.9615, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 45\n",
      "loss: tensor(1.0125, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 46\n",
      "loss: tensor(0.9269, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 47\n",
      "loss: tensor(0.9267, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 48\n",
      "loss: tensor(0.9327, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 16 49\n",
      "loss: tensor(0.9758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 0\n",
      "loss: tensor(0.9028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 1\n",
      "loss: tensor(0.9366, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 2\n",
      "loss: tensor(0.9374, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 3\n",
      "loss: tensor(0.9177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 4\n",
      "loss: tensor(0.8988, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 5\n",
      "loss: tensor(0.9618, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 6\n",
      "loss: tensor(0.9379, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 7\n",
      "loss: tensor(0.9165, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 8\n",
      "loss: tensor(0.9549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 9\n",
      "loss: tensor(0.9253, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 10\n",
      "loss: tensor(0.9537, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 11\n",
      "loss: tensor(0.9535, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 12\n",
      "loss: tensor(0.9557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 13\n",
      "loss: tensor(0.9944, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 14\n",
      "loss: tensor(0.9396, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 15\n",
      "loss: tensor(0.9805, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 16\n",
      "loss: tensor(0.9285, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 17\n",
      "loss: tensor(0.9273, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 18\n",
      "loss: tensor(0.9313, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 19\n",
      "loss: tensor(0.9517, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 20\n",
      "loss: tensor(0.9483, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 21\n",
      "loss: tensor(0.9141, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 22\n",
      "loss: tensor(1.0025, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 23\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 24\n",
      "loss: tensor(0.9640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 25\n",
      "loss: tensor(0.9717, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 26\n",
      "loss: tensor(0.9356, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 27\n",
      "loss: tensor(0.9596, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 28\n",
      "loss: tensor(0.9197, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 29\n",
      "loss: tensor(0.9224, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 30\n",
      "loss: tensor(0.9343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 31\n",
      "loss: tensor(0.9632, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 32\n",
      "loss: tensor(0.9210, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 33\n",
      "loss: tensor(0.9182, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 34\n",
      "loss: tensor(0.9758, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 35\n",
      "loss: tensor(0.9442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 36\n",
      "loss: tensor(0.9360, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 37\n",
      "loss: tensor(0.9288, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 38\n",
      "loss: tensor(0.9676, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 39\n",
      "loss: tensor(0.9475, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 40\n",
      "loss: tensor(0.9373, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 41\n",
      "loss: tensor(0.8938, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 42\n",
      "loss: tensor(0.9155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 43\n",
      "loss: tensor(0.9363, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 44\n",
      "loss: tensor(0.9333, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 45\n",
      "loss: tensor(0.9383, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 17 46\n",
      "loss: tensor(0.9039, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 47\n",
      "loss: tensor(0.9213, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 48\n",
      "loss: tensor(0.9402, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 17 49\n",
      "loss: tensor(0.9237, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 0\n",
      "loss: tensor(0.9763, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 1\n",
      "loss: tensor(0.9088, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 2\n",
      "loss: tensor(0.9160, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 3\n",
      "loss: tensor(0.9606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 4\n",
      "loss: tensor(0.9221, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 5\n",
      "loss: tensor(0.9201, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 6\n",
      "loss: tensor(0.8992, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 7\n",
      "loss: tensor(0.9541, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 8\n",
      "loss: tensor(0.9311, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 9\n",
      "loss: tensor(0.9248, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 10\n",
      "loss: tensor(0.9207, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 11\n",
      "loss: tensor(0.9400, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 12\n",
      "loss: tensor(0.9627, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 13\n",
      "loss: tensor(0.9274, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 14\n",
      "loss: tensor(0.9370, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 15\n",
      "loss: tensor(0.9487, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 16\n",
      "loss: tensor(0.9385, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 17\n",
      "loss: tensor(0.9928, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 18\n",
      "loss: tensor(0.9944, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 19\n",
      "loss: tensor(0.9409, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 20\n",
      "loss: tensor(0.9010, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 21\n",
      "loss: tensor(0.9411, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 22\n",
      "loss: tensor(0.9561, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 23\n",
      "loss: tensor(0.9661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 24\n",
      "loss: tensor(0.9042, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 25\n",
      "loss: tensor(0.9238, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 26\n",
      "loss: tensor(0.9433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 27\n",
      "loss: tensor(0.9033, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 28\n",
      "loss: tensor(0.9286, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 29\n",
      "loss: tensor(0.9266, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 30\n",
      "loss: tensor(0.9661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 31\n",
      "loss: tensor(0.9081, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 32\n",
      "loss: tensor(0.9311, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 33\n",
      "loss: tensor(0.9278, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 34\n",
      "loss: tensor(0.9411, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 35\n",
      "loss: tensor(0.9900, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 36\n",
      "loss: tensor(0.9567, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 37\n",
      "loss: tensor(0.9253, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 38\n",
      "loss: tensor(0.9212, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 39\n",
      "loss: tensor(0.9519, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 40\n",
      "loss: tensor(0.9242, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 41\n",
      "loss: tensor(0.9082, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 42\n",
      "loss: tensor(0.9124, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 43\n",
      "loss: tensor(0.9022, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 44\n",
      "loss: tensor(0.9057, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 45\n",
      "loss: tensor(0.9112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 46\n",
      "loss: tensor(0.9414, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 47\n",
      "loss: tensor(0.9531, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 48\n",
      "loss: tensor(0.9165, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 18 49\n",
      "loss: tensor(0.9114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 0\n",
      "loss: tensor(0.9566, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 1\n",
      "loss: tensor(0.9263, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 2\n",
      "loss: tensor(0.9364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 3\n",
      "loss: tensor(0.9388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 4\n",
      "loss: tensor(1.0303, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 5\n",
      "loss: tensor(0.9318, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 6\n",
      "loss: tensor(0.9117, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 7\n",
      "loss: tensor(0.9362, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 8\n",
      "loss: tensor(0.9429, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 9\n",
      "loss: tensor(0.9584, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 10\n",
      "loss: tensor(0.9108, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 11\n",
      "loss: tensor(0.9165, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 12\n",
      "loss: tensor(0.8959, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 13\n",
      "loss: tensor(0.9277, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 14\n",
      "loss: tensor(0.9232, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 15\n",
      "loss: tensor(0.9547, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 16\n",
      "loss: tensor(0.9294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 17\n",
      "loss: tensor(0.9345, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 18\n",
      "loss: tensor(0.9236, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 19\n",
      "loss: tensor(0.9147, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 20\n",
      "loss: tensor(0.9581, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 21\n",
      "loss: tensor(0.9532, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 22\n",
      "loss: tensor(0.9326, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 23\n",
      "loss: tensor(0.9049, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 24\n",
      "loss: tensor(0.8792, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 25\n",
      "loss: tensor(0.9169, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 26\n",
      "loss: tensor(0.9458, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 27\n",
      "loss: tensor(0.9189, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 28\n",
      "loss: tensor(0.9594, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 29\n",
      "loss: tensor(0.9465, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 30\n",
      "loss: tensor(0.9919, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 31\n",
      "loss: tensor(0.9182, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 32\n",
      "loss: tensor(0.9253, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 33\n",
      "loss: tensor(0.9417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 34\n",
      "loss: tensor(0.9154, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 35\n",
      "loss: tensor(0.9208, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 19 36\n",
      "loss: tensor(0.9017, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-89bec9ee949a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test for Batch Size: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUNet3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mvalLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SGD\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mmeanDice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname_opti\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname_activation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmeanDice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalLoss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-88b796306df0>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(model, num_workers, batch_size, epochs, learning_rate, optimizer_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# Then write your BACKWARD & OPTIMIZE below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m# Note: Compute Loss and Optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m           \u001b[1;31m# calculate gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m          \u001b[1;31m# update model's params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "name_loss = '_CrossEntropy'\n",
    "#name_loss = '_Tversky'\n",
    "\n",
    "name_opti = '_SGD'#\n",
    "#name_opti = '_ADAM'\n",
    "#name_opti = '_ADAGRAD'\n",
    "\n",
    "name_activation = '_RELU'\n",
    "#name_activation = '_TANH'\n",
    "#name_activation = '_LEAKYRELU'\n",
    "\n",
    "file_name = name_activation + name_loss + name_opti + '.csv'\n",
    "\n",
    "with open(file_name, 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Learning Rate\", \"Batch Size\",\"Epochs\",\"Loss Function\", \"Optimizer\",\"Activation\",\"Mean Dice\",\"Validation Loss\"])\n",
    "    lr_search = [0.01]\n",
    "    batch_search = [1,2,4,8]\n",
    "    for lr in lr_search:\n",
    "        print(\"Test for Learning Rate: \", lr)\n",
    "        for batch in batch_search:\n",
    "            print(\"Test for Batch Size: \", batch)\n",
    "            model = UNet3D()\n",
    "            valLoss, epochs = learn(model,num_workers = 0, batch_size = batch,epochs = 25,learning_rate = lr, optimizer_name = \"SGD\")\n",
    "            meanDice = evaluate(model)\n",
    "            writer.writerow([lr,batch,epochs,name_loss[1:],name_opti[1:],name_activation[1:],meanDice,valLoss])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZcsrwmVjy5k"
   },
   "source": [
    "### 3.2 Submission\n",
    "\n",
    "Kaggle requires your submission to be in a specific CSV format. To help ensure your submissions are in the correct format, we have provided some helper functions to do this for you. For those interested, the png images are run-length encoded and saved in a CSV to the specifications required by our competition.\n",
    "\n",
    "It is sufficient to use this helper function. To do so, save your 80 predicted masks into a directory. ONLY the 80 predicted masks should be in this directory. Call the submission_converter function with the first argument as the directory containing your masks, and the second the directory in which you wish to save your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "uHDVbgu0qW_V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def rle_encoding(x):\n",
    "    '''\n",
    "    *** Credit to https://www.kaggle.com/rakhlin/fast-run-length-encoding-python ***\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev + 1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def submission_converter(mask_directory, path_to_save):\n",
    "    writer = open(os.path.join(path_to_save, \"submission.csv\"), 'w')\n",
    "    writer.write('id,encoding\\n')\n",
    "\n",
    "    files = os.listdir(mask_directory)\n",
    "\n",
    "    for file in files:\n",
    "        name = file[:-4]\n",
    "        mask = cv2.imread(os.path.join(mask_directory, file), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        mask1 = (mask == 1)\n",
    "        mask2 = (mask == 2)\n",
    "        mask3 = (mask == 3)\n",
    "\n",
    "        encoded_mask1 = rle_encoding(mask1)\n",
    "        encoded_mask1 = ' '.join(str(e) for e in encoded_mask1)\n",
    "        encoded_mask2 = rle_encoding(mask2)\n",
    "        encoded_mask2 = ' '.join(str(e) for e in encoded_mask2)\n",
    "        encoded_mask3 = rle_encoding(mask3)\n",
    "        encoded_mask3 = ' '.join(str(e) for e in encoded_mask3)\n",
    "\n",
    "        writer.write(name + '1,' + encoded_mask1 + \"\\n\")\n",
    "        writer.write(name + '2,' + encoded_mask2 + \"\\n\")\n",
    "        writer.write(name + '3,' + encoded_mask3 + \"\\n\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 0 0\n",
      "loss: tensor(1.4067, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 1\n",
      "loss: tensor(1.3456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 2\n",
      "loss: tensor(1.3332, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 3\n",
      "loss: tensor(1.2774, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 4\n",
      "loss: tensor(1.2780, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 5\n",
      "loss: tensor(1.2805, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 6\n",
      "loss: tensor(1.2308, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 7\n",
      "loss: tensor(1.2035, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 8\n",
      "loss: tensor(1.2043, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 9\n",
      "loss: tensor(1.1719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 10\n",
      "loss: tensor(1.1513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 11\n",
      "loss: tensor(1.1456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 12\n",
      "loss: tensor(1.1415, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 13\n",
      "loss: tensor(1.1598, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 14\n",
      "loss: tensor(1.0967, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 15\n",
      "loss: tensor(1.1289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 16\n",
      "loss: tensor(1.1151, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 17\n",
      "loss: tensor(1.1691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 18\n",
      "loss: tensor(1.0973, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 19\n",
      "loss: tensor(1.0888, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 20\n",
      "loss: tensor(1.0768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 21\n",
      "loss: tensor(1.0645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 22\n",
      "loss: tensor(1.0278, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 23\n",
      "loss: tensor(1.0474, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 24\n",
      "loss: tensor(1.0778, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 25\n",
      "loss: tensor(1.0381, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 26\n",
      "loss: tensor(1.0336, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 27\n",
      "loss: tensor(1.0446, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 28\n",
      "loss: tensor(1.0075, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 29\n",
      "loss: tensor(1.0514, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 30\n",
      "loss: tensor(1.0488, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 31\n",
      "loss: tensor(1.0183, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 32\n",
      "loss: tensor(1.0470, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 33\n",
      "loss: tensor(1.0233, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 34\n",
      "loss: tensor(1.0367, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 35\n",
      "loss: tensor(1.0146, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 36\n",
      "loss: tensor(0.9971, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 37\n",
      "loss: tensor(0.9957, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 38\n",
      "loss: tensor(1.0234, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 39\n",
      "loss: tensor(0.9678, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 40\n",
      "loss: tensor(0.9645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 41\n",
      "loss: tensor(0.9748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 42\n",
      "loss: tensor(1.0005, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 43\n",
      "loss: tensor(0.9582, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 44\n",
      "loss: tensor(1.0182, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 45\n",
      "loss: tensor(0.9732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 46\n",
      "loss: tensor(0.9549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 47\n",
      "loss: tensor(0.9798, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 48\n",
      "loss: tensor(0.9791, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 49\n",
      "loss: tensor(0.9279, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 50\n",
      "loss: tensor(0.9590, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 51\n",
      "loss: tensor(0.9635, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 52\n",
      "loss: tensor(1.0182, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 53\n",
      "loss: tensor(0.9844, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 54\n",
      "loss: tensor(0.9588, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 55\n",
      "loss: tensor(0.9609, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 56\n",
      "loss: tensor(0.9361, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 57\n",
      "loss: tensor(0.9357, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 58\n",
      "loss: tensor(0.9706, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 59\n",
      "loss: tensor(0.9549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 60\n",
      "loss: tensor(0.9459, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 61\n",
      "loss: tensor(0.9600, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 62\n",
      "loss: tensor(0.9598, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 63\n",
      "loss: tensor(0.9456, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 64\n",
      "loss: tensor(0.9359, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 65\n",
      "loss: tensor(0.9810, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 66\n",
      "loss: tensor(0.9512, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 67\n",
      "loss: tensor(0.9450, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 68\n",
      "loss: tensor(0.9118, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 69\n",
      "loss: tensor(0.9426, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 70\n",
      "loss: tensor(0.9372, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 71\n",
      "loss: tensor(0.9488, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 72\n",
      "loss: tensor(0.9170, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 73\n",
      "loss: tensor(0.9528, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 74\n",
      "loss: tensor(0.9399, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 75\n",
      "loss: tensor(0.9538, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 76\n",
      "loss: tensor(0.9464, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 77\n",
      "loss: tensor(0.9234, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 78\n",
      "loss: tensor(0.9642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 79\n",
      "loss: tensor(0.8969, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 80\n",
      "loss: tensor(0.9453, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 81\n",
      "loss: tensor(1.0381, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 82\n",
      "loss: tensor(0.9147, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 83\n",
      "loss: tensor(0.9286, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 84\n",
      "loss: tensor(0.9275, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 85\n",
      "loss: tensor(0.9415, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 86\n",
      "loss: tensor(0.9368, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 87\n",
      "loss: tensor(0.9243, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 88\n",
      "loss: tensor(0.9244, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 89\n",
      "loss: tensor(0.8981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 90\n",
      "loss: tensor(0.9112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 91\n",
      "loss: tensor(0.8924, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 92\n",
      "loss: tensor(0.8872, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 93\n",
      "loss: tensor(1.0388, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 94\n",
      "loss: tensor(0.9934, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 95\n",
      "loss: tensor(0.8916, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 96\n",
      "loss: tensor(0.9256, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 97\n",
      "loss: tensor(0.9837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 98\n",
      "loss: tensor(0.9119, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 0 99\n",
      "loss: tensor(0.9337, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 0\n",
      "loss: tensor(0.9017, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 1\n",
      "loss: tensor(0.8881, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 2\n",
      "loss: tensor(0.9516, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 3\n",
      "loss: tensor(0.9855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 4\n",
      "loss: tensor(0.9814, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 5\n",
      "loss: tensor(0.9326, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 6\n",
      "loss: tensor(0.8790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 7\n",
      "loss: tensor(0.9182, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 8\n",
      "loss: tensor(0.9068, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 9\n",
      "loss: tensor(0.9119, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 10\n",
      "loss: tensor(0.8813, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 11\n",
      "loss: tensor(0.8826, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 12\n",
      "loss: tensor(0.8747, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 1 13\n",
      "loss: tensor(0.9135, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 14\n",
      "loss: tensor(0.9096, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 15\n",
      "loss: tensor(0.8760, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 16\n",
      "loss: tensor(0.9345, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 17\n",
      "loss: tensor(0.9247, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 18\n",
      "loss: tensor(0.9113, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 19\n",
      "loss: tensor(0.9394, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 20\n",
      "loss: tensor(0.8888, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 21\n",
      "loss: tensor(0.8754, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 22\n",
      "loss: tensor(0.8744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 23\n",
      "loss: tensor(0.9188, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 24\n",
      "loss: tensor(0.8796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 25\n",
      "loss: tensor(0.8826, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 26\n",
      "loss: tensor(1.0224, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 27\n",
      "loss: tensor(0.9027, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 28\n",
      "loss: tensor(0.9090, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 29\n",
      "loss: tensor(0.9152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 30\n",
      "loss: tensor(0.8863, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 31\n",
      "loss: tensor(0.8878, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 32\n",
      "loss: tensor(0.9120, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 33\n",
      "loss: tensor(0.9062, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 34\n",
      "loss: tensor(0.8765, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 35\n",
      "loss: tensor(0.9683, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 36\n",
      "loss: tensor(0.9086, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 37\n",
      "loss: tensor(0.8901, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 38\n",
      "loss: tensor(0.8917, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 39\n",
      "loss: tensor(0.8937, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 40\n",
      "loss: tensor(0.9629, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 41\n",
      "loss: tensor(0.8520, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 42\n",
      "loss: tensor(0.8581, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 43\n",
      "loss: tensor(0.8944, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 44\n",
      "loss: tensor(0.8893, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 45\n",
      "loss: tensor(0.8781, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 46\n",
      "loss: tensor(0.8721, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 47\n",
      "loss: tensor(0.8771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 48\n",
      "loss: tensor(0.9143, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 49\n",
      "loss: tensor(0.9294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 50\n",
      "loss: tensor(0.8711, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 51\n",
      "loss: tensor(0.8895, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 52\n",
      "loss: tensor(0.9873, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 53\n",
      "loss: tensor(0.8899, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 54\n",
      "loss: tensor(0.9558, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 55\n",
      "loss: tensor(0.8983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 56\n",
      "loss: tensor(0.8890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 57\n",
      "loss: tensor(0.8721, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 58\n",
      "loss: tensor(0.8648, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 59\n",
      "loss: tensor(0.9966, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 60\n",
      "loss: tensor(0.8912, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 61\n",
      "loss: tensor(0.8681, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 62\n",
      "loss: tensor(0.9123, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 63\n",
      "loss: tensor(1.0017, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 64\n",
      "loss: tensor(0.9646, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 65\n",
      "loss: tensor(0.9097, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 66\n",
      "loss: tensor(0.9564, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 67\n",
      "loss: tensor(0.9063, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 68\n",
      "loss: tensor(0.8864, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 69\n",
      "loss: tensor(0.8825, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 70\n",
      "loss: tensor(0.8870, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 71\n",
      "loss: tensor(0.8829, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 72\n",
      "loss: tensor(0.9048, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 73\n",
      "loss: tensor(0.8817, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 74\n",
      "loss: tensor(0.9330, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 75\n",
      "loss: tensor(0.8907, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 76\n",
      "loss: tensor(0.8490, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 77\n",
      "loss: tensor(0.8722, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 78\n",
      "loss: tensor(0.9161, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 79\n",
      "loss: tensor(0.8793, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 80\n",
      "loss: tensor(0.9187, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 81\n",
      "loss: tensor(0.8726, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 82\n",
      "loss: tensor(0.8624, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 83\n",
      "loss: tensor(0.8662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 84\n",
      "loss: tensor(0.8596, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 85\n",
      "loss: tensor(0.8549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 86\n",
      "loss: tensor(0.8696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 87\n",
      "loss: tensor(0.8733, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 88\n",
      "loss: tensor(0.8675, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 89\n",
      "loss: tensor(0.8982, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 90\n",
      "loss: tensor(0.9290, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 91\n",
      "loss: tensor(0.8681, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 92\n",
      "loss: tensor(0.8466, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 93\n",
      "loss: tensor(0.8467, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 94\n",
      "loss: tensor(0.8336, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 95\n",
      "loss: tensor(0.8503, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 96\n",
      "loss: tensor(0.9037, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 97\n",
      "loss: tensor(0.9023, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 98\n",
      "loss: tensor(1.0032, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 1 99\n",
      "loss: tensor(0.8557, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 0\n",
      "loss: tensor(0.8956, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 1\n",
      "loss: tensor(0.8956, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 2\n",
      "loss: tensor(0.8729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 3\n",
      "loss: tensor(0.8512, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 4\n",
      "loss: tensor(0.8460, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 5\n",
      "loss: tensor(0.9024, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 6\n",
      "loss: tensor(0.8524, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 7\n",
      "loss: tensor(0.8752, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 8\n",
      "loss: tensor(0.8474, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 9\n",
      "loss: tensor(0.9248, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 10\n",
      "loss: tensor(0.9417, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 11\n",
      "loss: tensor(0.8697, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 12\n",
      "loss: tensor(0.8768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 13\n",
      "loss: tensor(0.8579, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 14\n",
      "loss: tensor(0.8364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 15\n",
      "loss: tensor(0.8562, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 16\n",
      "loss: tensor(0.8959, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 17\n",
      "loss: tensor(0.8580, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 18\n",
      "loss: tensor(0.8663, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 19\n",
      "loss: tensor(0.8670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 20\n",
      "loss: tensor(0.8562, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 21\n",
      "loss: tensor(0.8457, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 22\n",
      "loss: tensor(0.8296, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 23\n",
      "loss: tensor(0.8226, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 24\n",
      "loss: tensor(0.8544, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 25\n",
      "loss: tensor(0.8541, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 2 26\n",
      "loss: tensor(0.8422, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 27\n",
      "loss: tensor(0.8831, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 28\n",
      "loss: tensor(0.9563, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 29\n",
      "loss: tensor(0.8560, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 30\n",
      "loss: tensor(0.8384, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 31\n",
      "loss: tensor(0.8827, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 32\n",
      "loss: tensor(0.8670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 33\n",
      "loss: tensor(0.8419, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 34\n",
      "loss: tensor(0.8341, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 35\n",
      "loss: tensor(0.8214, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 36\n",
      "loss: tensor(0.8574, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 37\n",
      "loss: tensor(0.8433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 38\n",
      "loss: tensor(0.8854, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 39\n",
      "loss: tensor(0.8593, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 40\n",
      "loss: tensor(0.8364, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 41\n",
      "loss: tensor(0.8308, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 42\n",
      "loss: tensor(0.8745, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 43\n",
      "loss: tensor(0.8549, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 44\n",
      "loss: tensor(0.8386, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 45\n",
      "loss: tensor(0.8365, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 46\n",
      "loss: tensor(0.9247, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 47\n",
      "loss: tensor(0.8354, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 48\n",
      "loss: tensor(0.9442, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 49\n",
      "loss: tensor(0.8354, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 50\n",
      "loss: tensor(0.8432, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 51\n",
      "loss: tensor(0.8349, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 52\n",
      "loss: tensor(0.8356, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 53\n",
      "loss: tensor(0.8310, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 54\n",
      "loss: tensor(0.8356, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 55\n",
      "loss: tensor(0.8433, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 56\n",
      "loss: tensor(0.8393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 57\n",
      "loss: tensor(0.8507, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 58\n",
      "loss: tensor(0.8327, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 59\n",
      "loss: tensor(0.8349, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 60\n",
      "loss: tensor(0.8359, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 61\n",
      "loss: tensor(0.8134, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 62\n",
      "loss: tensor(0.8794, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 63\n",
      "loss: tensor(0.8435, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 64\n",
      "loss: tensor(0.9571, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 65\n",
      "loss: tensor(0.8260, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 66\n",
      "loss: tensor(0.8181, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 67\n",
      "loss: tensor(0.8547, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 68\n",
      "loss: tensor(0.8385, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 69\n",
      "loss: tensor(0.8319, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 70\n",
      "loss: tensor(0.8276, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 71\n",
      "loss: tensor(0.8613, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 72\n",
      "loss: tensor(0.8349, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 73\n",
      "loss: tensor(0.8431, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 74\n",
      "loss: tensor(0.8343, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 75\n",
      "loss: tensor(0.8155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 76\n",
      "loss: tensor(1.0209, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 77\n",
      "loss: tensor(0.8709, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 78\n",
      "loss: tensor(0.8582, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 79\n",
      "loss: tensor(0.8980, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 80\n",
      "loss: tensor(0.8376, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 81\n",
      "loss: tensor(0.8496, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 82\n",
      "loss: tensor(0.8224, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 83\n",
      "loss: tensor(0.8289, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 84\n",
      "loss: tensor(0.8207, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 85\n",
      "loss: tensor(0.8370, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 86\n",
      "loss: tensor(0.8309, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 87\n",
      "loss: tensor(0.8232, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 88\n",
      "loss: tensor(0.8317, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 89\n",
      "loss: tensor(0.8259, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 90\n",
      "loss: tensor(0.8115, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 91\n",
      "loss: tensor(0.9393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 92\n",
      "loss: tensor(0.8698, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 93\n",
      "loss: tensor(0.8378, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 94\n",
      "loss: tensor(0.8550, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 95\n",
      "loss: tensor(0.8262, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 96\n",
      "loss: tensor(0.8676, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 97\n",
      "loss: tensor(0.8265, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 98\n",
      "loss: tensor(0.8316, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 2 99\n",
      "loss: tensor(0.8203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 0\n",
      "loss: tensor(0.8267, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 1\n",
      "loss: tensor(0.8151, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 2\n",
      "loss: tensor(0.8082, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 3\n",
      "loss: tensor(0.8188, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 4\n",
      "loss: tensor(0.8292, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 5\n",
      "loss: tensor(0.8152, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 6\n",
      "loss: tensor(0.9783, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 7\n",
      "loss: tensor(0.8301, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 8\n",
      "loss: tensor(0.8294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 9\n",
      "loss: tensor(0.8420, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 10\n",
      "loss: tensor(0.8338, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 11\n",
      "loss: tensor(0.8071, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 12\n",
      "loss: tensor(0.8044, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 13\n",
      "loss: tensor(0.8574, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 14\n",
      "loss: tensor(0.8075, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 15\n",
      "loss: tensor(0.8132, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 16\n",
      "loss: tensor(0.8359, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 17\n",
      "loss: tensor(0.8167, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 18\n",
      "loss: tensor(0.8090, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 19\n",
      "loss: tensor(0.8102, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 20\n",
      "loss: tensor(0.8203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 21\n",
      "loss: tensor(0.8294, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 22\n",
      "loss: tensor(0.8158, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 23\n",
      "loss: tensor(0.8292, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 24\n",
      "loss: tensor(0.8491, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 25\n",
      "loss: tensor(0.8147, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 26\n",
      "loss: tensor(0.8019, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 27\n",
      "loss: tensor(0.8120, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 28\n",
      "loss: tensor(0.8193, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 29\n",
      "loss: tensor(0.8064, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 30\n",
      "loss: tensor(0.8108, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 31\n",
      "loss: tensor(0.8058, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 32\n",
      "loss: tensor(0.8204, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 33\n",
      "loss: tensor(0.8059, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 34\n",
      "loss: tensor(0.8112, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 35\n",
      "loss: tensor(0.8419, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 36\n",
      "loss: tensor(0.7878, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 37\n",
      "loss: tensor(0.8481, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 38\n",
      "loss: tensor(0.8996, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 3 39\n",
      "loss: tensor(0.8196, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 40\n",
      "loss: tensor(0.8259, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 41\n",
      "loss: tensor(0.7989, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 42\n",
      "loss: tensor(0.8011, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 43\n",
      "loss: tensor(0.7983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 44\n",
      "loss: tensor(0.8051, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 45\n",
      "loss: tensor(0.7902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 46\n",
      "loss: tensor(0.8116, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 47\n",
      "loss: tensor(0.8076, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 48\n",
      "loss: tensor(0.8136, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 49\n",
      "loss: tensor(0.8562, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 50\n",
      "loss: tensor(0.8246, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 51\n",
      "loss: tensor(0.8027, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 52\n",
      "loss: tensor(0.8122, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 53\n",
      "loss: tensor(0.8118, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 54\n",
      "loss: tensor(0.7941, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 55\n",
      "loss: tensor(0.7978, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 56\n",
      "loss: tensor(0.8107, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 57\n",
      "loss: tensor(0.8155, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 58\n",
      "loss: tensor(0.8997, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 59\n",
      "loss: tensor(0.8706, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 60\n",
      "loss: tensor(0.7981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 61\n",
      "loss: tensor(0.8075, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 62\n",
      "loss: tensor(0.8708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 63\n",
      "loss: tensor(0.8171, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 64\n",
      "loss: tensor(0.8008, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 65\n",
      "loss: tensor(0.7870, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 66\n",
      "loss: tensor(0.8539, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 67\n",
      "loss: tensor(0.8194, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 68\n",
      "loss: tensor(0.8303, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 69\n",
      "loss: tensor(0.8192, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 70\n",
      "loss: tensor(0.8031, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 71\n",
      "loss: tensor(0.8142, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 72\n",
      "loss: tensor(0.8612, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 73\n",
      "loss: tensor(0.8203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 74\n",
      "loss: tensor(0.8526, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 75\n",
      "loss: tensor(0.8393, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 76\n",
      "loss: tensor(0.8203, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 77\n",
      "loss: tensor(0.8098, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 78\n",
      "loss: tensor(0.7934, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 79\n",
      "loss: tensor(0.8285, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 80\n",
      "loss: tensor(0.8131, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 81\n",
      "loss: tensor(0.8074, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 82\n",
      "loss: tensor(0.8102, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 83\n",
      "loss: tensor(0.7941, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 84\n",
      "loss: tensor(0.7987, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 85\n",
      "loss: tensor(0.8037, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 86\n",
      "loss: tensor(0.8496, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 87\n",
      "loss: tensor(0.7925, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 88\n",
      "loss: tensor(0.7933, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 89\n",
      "loss: tensor(0.7933, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 90\n",
      "loss: tensor(0.8277, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 91\n",
      "loss: tensor(0.8513, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 92\n",
      "loss: tensor(0.8189, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 93\n",
      "loss: tensor(0.8106, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 94\n",
      "loss: tensor(0.7975, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 95\n",
      "loss: tensor(0.7902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 96\n",
      "loss: tensor(0.7920, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 97\n",
      "loss: tensor(0.8354, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 98\n",
      "loss: tensor(0.7986, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 3 99\n",
      "loss: tensor(0.7977, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 0\n",
      "loss: tensor(0.7801, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 1\n",
      "loss: tensor(0.8081, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 2\n",
      "loss: tensor(0.8087, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 3\n",
      "loss: tensor(0.7920, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 4\n",
      "loss: tensor(0.8029, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 5\n",
      "loss: tensor(0.7819, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 6\n",
      "loss: tensor(0.8056, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 7\n",
      "loss: tensor(0.8072, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 8\n",
      "loss: tensor(0.8462, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 9\n",
      "loss: tensor(0.7855, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 10\n",
      "loss: tensor(0.8276, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 11\n",
      "loss: tensor(0.7947, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 12\n",
      "loss: tensor(0.7982, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 13\n",
      "loss: tensor(0.7930, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 14\n",
      "loss: tensor(0.8338, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 15\n",
      "loss: tensor(0.7929, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 16\n",
      "loss: tensor(0.7981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 17\n",
      "loss: tensor(0.7903, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 18\n",
      "loss: tensor(0.8084, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 19\n",
      "loss: tensor(0.8024, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 20\n",
      "loss: tensor(0.8005, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 21\n",
      "loss: tensor(0.8562, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 22\n",
      "loss: tensor(0.7943, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 23\n",
      "loss: tensor(0.7866, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 24\n",
      "loss: tensor(0.7839, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 25\n",
      "loss: tensor(0.8156, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 26\n",
      "loss: tensor(0.8042, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 27\n",
      "loss: tensor(0.7934, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 28\n",
      "loss: tensor(0.7916, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 29\n",
      "loss: tensor(0.8713, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 30\n",
      "loss: tensor(0.8011, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 31\n",
      "loss: tensor(0.7928, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 32\n",
      "loss: tensor(0.7878, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 33\n",
      "loss: tensor(0.7856, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 34\n",
      "loss: tensor(0.8048, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 35\n",
      "loss: tensor(0.9488, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 36\n",
      "loss: tensor(0.8171, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 37\n",
      "loss: tensor(0.8045, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 38\n",
      "loss: tensor(0.7910, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 39\n",
      "loss: tensor(0.7921, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 40\n",
      "loss: tensor(0.7875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 41\n",
      "loss: tensor(0.8094, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 42\n",
      "loss: tensor(0.8356, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 43\n",
      "loss: tensor(0.8297, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 44\n",
      "loss: tensor(0.8571, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 45\n",
      "loss: tensor(0.8096, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 46\n",
      "loss: tensor(0.7894, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 47\n",
      "loss: tensor(0.7895, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 48\n",
      "loss: tensor(0.8075, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 49\n",
      "loss: tensor(0.7985, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 50\n",
      "loss: tensor(0.7980, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 51\n",
      "loss: tensor(0.8112, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 4 52\n",
      "loss: tensor(0.7983, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 53\n",
      "loss: tensor(0.8045, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 54\n",
      "loss: tensor(0.7819, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 55\n",
      "loss: tensor(0.8172, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 56\n",
      "loss: tensor(0.7838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 57\n",
      "loss: tensor(0.7942, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 58\n",
      "loss: tensor(0.7943, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 59\n",
      "loss: tensor(0.7875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 60\n",
      "loss: tensor(0.7733, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 61\n",
      "loss: tensor(0.7832, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 62\n",
      "loss: tensor(0.8114, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 63\n",
      "loss: tensor(0.7903, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 64\n",
      "loss: tensor(0.8060, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 65\n",
      "loss: tensor(0.7976, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 66\n",
      "loss: tensor(0.8144, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 67\n",
      "loss: tensor(0.7866, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 68\n",
      "loss: tensor(0.7851, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 69\n",
      "loss: tensor(0.7932, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 70\n",
      "loss: tensor(0.8120, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 71\n",
      "loss: tensor(0.7938, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 72\n",
      "loss: tensor(0.7951, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 73\n",
      "loss: tensor(0.8464, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 74\n",
      "loss: tensor(0.7981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 75\n",
      "loss: tensor(0.7950, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 76\n",
      "loss: tensor(0.8058, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 77\n",
      "loss: tensor(0.7832, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 78\n",
      "loss: tensor(0.7916, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 79\n",
      "loss: tensor(0.8017, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 80\n",
      "loss: tensor(0.7913, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 81\n",
      "loss: tensor(0.7926, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 82\n",
      "loss: tensor(0.7793, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 83\n",
      "loss: tensor(0.8089, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 84\n",
      "loss: tensor(0.7848, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 85\n",
      "loss: tensor(0.7952, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 86\n",
      "loss: tensor(0.8086, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 87\n",
      "loss: tensor(0.8157, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 88\n",
      "loss: tensor(0.7905, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 89\n",
      "loss: tensor(0.7892, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 90\n",
      "loss: tensor(0.7795, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 91\n",
      "loss: tensor(0.7803, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 92\n",
      "loss: tensor(0.7776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 93\n",
      "loss: tensor(0.7936, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 94\n",
      "loss: tensor(0.7981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 95\n",
      "loss: tensor(0.8662, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 96\n",
      "loss: tensor(0.7980, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 97\n",
      "loss: tensor(0.7825, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 98\n",
      "loss: tensor(0.7902, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 4 99\n",
      "loss: tensor(0.7964, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 0\n",
      "loss: tensor(0.8013, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 1\n",
      "loss: tensor(0.7919, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 2\n",
      "loss: tensor(0.7861, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 3\n",
      "loss: tensor(0.7882, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 4\n",
      "loss: tensor(0.7973, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 5\n",
      "loss: tensor(0.7874, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 6\n",
      "loss: tensor(0.7739, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 7\n",
      "loss: tensor(0.7819, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 8\n",
      "loss: tensor(0.7887, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 9\n",
      "loss: tensor(0.7981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 10\n",
      "loss: tensor(0.8050, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 11\n",
      "loss: tensor(0.7806, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 12\n",
      "loss: tensor(0.7844, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 13\n",
      "loss: tensor(0.7866, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 14\n",
      "loss: tensor(0.7822, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 15\n",
      "loss: tensor(0.8031, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 16\n",
      "loss: tensor(0.7954, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 17\n",
      "loss: tensor(0.7807, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 18\n",
      "loss: tensor(0.7861, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 19\n",
      "loss: tensor(0.8327, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 20\n",
      "loss: tensor(0.7731, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 21\n",
      "loss: tensor(0.7828, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 22\n",
      "loss: tensor(0.7819, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 23\n",
      "loss: tensor(0.7710, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 24\n",
      "loss: tensor(0.7800, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 25\n",
      "loss: tensor(0.9097, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 26\n",
      "loss: tensor(0.7871, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 27\n",
      "loss: tensor(0.7908, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 28\n",
      "loss: tensor(0.7788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 29\n",
      "loss: tensor(0.7774, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 30\n",
      "loss: tensor(0.7937, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 31\n",
      "loss: tensor(0.7845, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 32\n",
      "loss: tensor(0.7746, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 33\n",
      "loss: tensor(0.7838, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 34\n",
      "loss: tensor(0.7789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 35\n",
      "loss: tensor(0.8659, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 36\n",
      "loss: tensor(0.8028, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 37\n",
      "loss: tensor(0.7858, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 38\n",
      "loss: tensor(0.7850, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 39\n",
      "loss: tensor(0.7815, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 40\n",
      "loss: tensor(0.7753, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 41\n",
      "loss: tensor(0.8265, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 42\n",
      "loss: tensor(0.7787, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 43\n",
      "loss: tensor(0.7723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 44\n",
      "loss: tensor(0.7906, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 45\n",
      "loss: tensor(0.7886, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 46\n",
      "loss: tensor(0.7857, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 47\n",
      "loss: tensor(0.7774, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 48\n",
      "loss: tensor(0.7748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 49\n",
      "loss: tensor(0.8177, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 50\n",
      "loss: tensor(0.7766, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 51\n",
      "loss: tensor(0.7840, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 52\n",
      "loss: tensor(0.8154, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 53\n",
      "loss: tensor(0.7808, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 54\n",
      "loss: tensor(0.7889, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 55\n",
      "loss: tensor(0.7813, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 56\n",
      "loss: tensor(0.7748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 57\n",
      "loss: tensor(0.7806, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 58\n",
      "loss: tensor(0.7771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 59\n",
      "loss: tensor(0.7874, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 60\n",
      "loss: tensor(0.7876, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 61\n",
      "loss: tensor(0.7837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 62\n",
      "loss: tensor(0.7900, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 63\n",
      "loss: tensor(0.7790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 64\n",
      "loss: tensor(0.7850, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 5 65\n",
      "loss: tensor(0.7804, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 66\n",
      "loss: tensor(0.8014, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 67\n",
      "loss: tensor(0.7877, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 68\n",
      "loss: tensor(0.7800, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 69\n",
      "loss: tensor(0.7779, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 70\n",
      "loss: tensor(0.7751, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 71\n",
      "loss: tensor(0.7806, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 72\n",
      "loss: tensor(0.7906, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 73\n",
      "loss: tensor(0.7799, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 74\n",
      "loss: tensor(0.7803, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 75\n",
      "loss: tensor(0.7764, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 76\n",
      "loss: tensor(0.7723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 77\n",
      "loss: tensor(0.8039, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 78\n",
      "loss: tensor(0.7789, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 79\n",
      "loss: tensor(0.7890, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 80\n",
      "loss: tensor(0.7861, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 81\n",
      "loss: tensor(0.7888, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 82\n",
      "loss: tensor(0.7794, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 83\n",
      "loss: tensor(0.7713, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 84\n",
      "loss: tensor(0.7968, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 85\n",
      "loss: tensor(0.8079, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 86\n",
      "loss: tensor(0.7680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 87\n",
      "loss: tensor(0.8007, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 88\n",
      "loss: tensor(0.7931, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 89\n",
      "loss: tensor(0.7702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 90\n",
      "loss: tensor(0.7812, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 91\n",
      "loss: tensor(0.7741, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 92\n",
      "loss: tensor(0.7672, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 93\n",
      "loss: tensor(0.8270, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 94\n",
      "loss: tensor(0.8111, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 95\n",
      "loss: tensor(0.7920, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 96\n",
      "loss: tensor(0.7984, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 97\n",
      "loss: tensor(0.7698, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 98\n",
      "loss: tensor(0.7909, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 5 99\n",
      "loss: tensor(0.7772, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 0\n",
      "loss: tensor(0.7808, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 1\n",
      "loss: tensor(0.7655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 2\n",
      "loss: tensor(0.8310, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 3\n",
      "loss: tensor(0.7748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 4\n",
      "loss: tensor(0.7833, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 5\n",
      "loss: tensor(0.7816, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 6\n",
      "loss: tensor(0.7776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 7\n",
      "loss: tensor(0.7817, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 8\n",
      "loss: tensor(0.7773, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 9\n",
      "loss: tensor(0.7773, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 10\n",
      "loss: tensor(0.7968, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 11\n",
      "loss: tensor(0.7820, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 12\n",
      "loss: tensor(0.7744, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 13\n",
      "loss: tensor(0.7784, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 14\n",
      "loss: tensor(0.7742, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 15\n",
      "loss: tensor(0.7730, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 16\n",
      "loss: tensor(0.7754, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 17\n",
      "loss: tensor(0.7742, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 18\n",
      "loss: tensor(0.8042, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 19\n",
      "loss: tensor(0.7763, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 20\n",
      "loss: tensor(0.7812, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 21\n",
      "loss: tensor(0.7843, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 22\n",
      "loss: tensor(0.7786, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 23\n",
      "loss: tensor(0.7803, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 24\n",
      "loss: tensor(0.7682, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 25\n",
      "loss: tensor(0.7815, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 26\n",
      "loss: tensor(0.7763, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 27\n",
      "loss: tensor(0.7727, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 28\n",
      "loss: tensor(0.8036, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 29\n",
      "loss: tensor(0.7901, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 30\n",
      "loss: tensor(0.7951, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 31\n",
      "loss: tensor(0.7659, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 32\n",
      "loss: tensor(0.7766, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 33\n",
      "loss: tensor(0.7774, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 34\n",
      "loss: tensor(0.7776, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 35\n",
      "loss: tensor(0.8115, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 36\n",
      "loss: tensor(0.7714, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 37\n",
      "loss: tensor(0.7979, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 38\n",
      "loss: tensor(0.7889, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 39\n",
      "loss: tensor(0.7946, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 40\n",
      "loss: tensor(0.7813, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 41\n",
      "loss: tensor(0.7747, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 42\n",
      "loss: tensor(0.7930, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 43\n",
      "loss: tensor(0.7638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 44\n",
      "loss: tensor(0.7660, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 45\n",
      "loss: tensor(0.7729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 46\n",
      "loss: tensor(0.7649, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 47\n",
      "loss: tensor(0.7691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 48\n",
      "loss: tensor(0.7732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 49\n",
      "loss: tensor(0.7730, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 50\n",
      "loss: tensor(0.7641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 51\n",
      "loss: tensor(0.7729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 52\n",
      "loss: tensor(0.7760, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 53\n",
      "loss: tensor(0.7750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 54\n",
      "loss: tensor(0.7797, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 55\n",
      "loss: tensor(0.7812, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 56\n",
      "loss: tensor(0.7771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 57\n",
      "loss: tensor(0.7759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 58\n",
      "loss: tensor(0.7724, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 59\n",
      "loss: tensor(0.7788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 60\n",
      "loss: tensor(0.7863, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 61\n",
      "loss: tensor(0.7828, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 62\n",
      "loss: tensor(0.7702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 63\n",
      "loss: tensor(0.7790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 64\n",
      "loss: tensor(0.7821, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 65\n",
      "loss: tensor(0.7982, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 66\n",
      "loss: tensor(0.7681, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 67\n",
      "loss: tensor(0.7729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 68\n",
      "loss: tensor(0.7750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 69\n",
      "loss: tensor(0.7759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 70\n",
      "loss: tensor(0.7695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 71\n",
      "loss: tensor(0.7750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 72\n",
      "loss: tensor(0.7723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 73\n",
      "loss: tensor(0.7757, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 74\n",
      "loss: tensor(0.7791, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 75\n",
      "loss: tensor(0.7768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 76\n",
      "loss: tensor(0.7643, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 77\n",
      "loss: tensor(0.7768, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 6 78\n",
      "loss: tensor(0.7685, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 79\n",
      "loss: tensor(0.7692, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 80\n",
      "loss: tensor(0.7948, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 81\n",
      "loss: tensor(0.7643, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 82\n",
      "loss: tensor(0.7804, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 83\n",
      "loss: tensor(0.7911, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 84\n",
      "loss: tensor(0.7764, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 85\n",
      "loss: tensor(0.7771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 86\n",
      "loss: tensor(0.7805, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 87\n",
      "loss: tensor(0.7707, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 88\n",
      "loss: tensor(0.7689, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 89\n",
      "loss: tensor(0.7824, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 90\n",
      "loss: tensor(0.7772, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 91\n",
      "loss: tensor(0.7846, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 92\n",
      "loss: tensor(0.7984, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 93\n",
      "loss: tensor(0.7978, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 94\n",
      "loss: tensor(0.7691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 95\n",
      "loss: tensor(0.7769, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 96\n",
      "loss: tensor(0.7700, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 97\n",
      "loss: tensor(0.7824, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 98\n",
      "loss: tensor(0.7790, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 6 99\n",
      "loss: tensor(0.7695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 0\n",
      "loss: tensor(0.7683, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 1\n",
      "loss: tensor(0.7632, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 2\n",
      "loss: tensor(0.7748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 3\n",
      "loss: tensor(0.7680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 4\n",
      "loss: tensor(0.7802, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 5\n",
      "loss: tensor(0.7739, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 6\n",
      "loss: tensor(0.7824, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 7\n",
      "loss: tensor(0.7683, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 8\n",
      "loss: tensor(0.7648, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 9\n",
      "loss: tensor(0.7657, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 10\n",
      "loss: tensor(0.7805, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 11\n",
      "loss: tensor(0.7657, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 12\n",
      "loss: tensor(0.7959, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 13\n",
      "loss: tensor(0.7875, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 14\n",
      "loss: tensor(0.7661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 15\n",
      "loss: tensor(0.7735, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 16\n",
      "loss: tensor(0.7722, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 17\n",
      "loss: tensor(0.7640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 18\n",
      "loss: tensor(0.7644, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 19\n",
      "loss: tensor(0.8322, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 20\n",
      "loss: tensor(0.7849, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 21\n",
      "loss: tensor(0.7912, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 22\n",
      "loss: tensor(0.7639, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 23\n",
      "loss: tensor(0.7822, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 24\n",
      "loss: tensor(0.7749, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 25\n",
      "loss: tensor(0.7725, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 26\n",
      "loss: tensor(0.7863, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 27\n",
      "loss: tensor(0.8216, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 28\n",
      "loss: tensor(0.7858, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 29\n",
      "loss: tensor(0.7797, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 30\n",
      "loss: tensor(0.7778, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 31\n",
      "loss: tensor(0.7691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 32\n",
      "loss: tensor(0.7768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 33\n",
      "loss: tensor(0.7638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 34\n",
      "loss: tensor(0.7947, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 35\n",
      "loss: tensor(0.7702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 36\n",
      "loss: tensor(0.7649, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 37\n",
      "loss: tensor(0.7794, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 38\n",
      "loss: tensor(0.8097, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 39\n",
      "loss: tensor(0.7978, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 40\n",
      "loss: tensor(0.7771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 41\n",
      "loss: tensor(0.7788, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 42\n",
      "loss: tensor(0.7919, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 43\n",
      "loss: tensor(0.7759, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 44\n",
      "loss: tensor(0.7893, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 45\n",
      "loss: tensor(0.7694, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 46\n",
      "loss: tensor(0.7671, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 47\n",
      "loss: tensor(0.7699, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 48\n",
      "loss: tensor(0.7874, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 49\n",
      "loss: tensor(0.7676, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 50\n",
      "loss: tensor(0.7823, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 51\n",
      "loss: tensor(0.7700, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 52\n",
      "loss: tensor(0.7680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 53\n",
      "loss: tensor(0.7869, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 54\n",
      "loss: tensor(0.7745, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 55\n",
      "loss: tensor(0.7768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 56\n",
      "loss: tensor(0.7626, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 57\n",
      "loss: tensor(0.7809, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 58\n",
      "loss: tensor(0.7777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 59\n",
      "loss: tensor(0.7784, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 60\n",
      "loss: tensor(0.7799, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 61\n",
      "loss: tensor(0.7697, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 62\n",
      "loss: tensor(0.7846, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 63\n",
      "loss: tensor(0.7741, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 64\n",
      "loss: tensor(0.7701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 65\n",
      "loss: tensor(0.7616, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 66\n",
      "loss: tensor(0.7778, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 67\n",
      "loss: tensor(0.7693, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 68\n",
      "loss: tensor(0.7713, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 69\n",
      "loss: tensor(0.7702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 70\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 71\n",
      "loss: tensor(0.7763, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 72\n",
      "loss: tensor(0.7750, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 73\n",
      "loss: tensor(0.7764, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 74\n",
      "loss: tensor(0.7685, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 75\n",
      "loss: tensor(0.7660, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 76\n",
      "loss: tensor(0.7847, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 77\n",
      "loss: tensor(0.7659, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 78\n",
      "loss: tensor(0.7673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 79\n",
      "loss: tensor(0.7676, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 80\n",
      "loss: tensor(0.7700, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 81\n",
      "loss: tensor(0.7663, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 82\n",
      "loss: tensor(0.7686, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 83\n",
      "loss: tensor(0.7622, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 84\n",
      "loss: tensor(0.7771, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 85\n",
      "loss: tensor(0.7660, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 86\n",
      "loss: tensor(0.7692, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 87\n",
      "loss: tensor(0.7719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 88\n",
      "loss: tensor(0.7731, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 89\n",
      "loss: tensor(0.7693, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 90\n",
      "loss: tensor(0.7650, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 7 91\n",
      "loss: tensor(0.7684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 92\n",
      "loss: tensor(0.7664, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 93\n",
      "loss: tensor(0.7705, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 94\n",
      "loss: tensor(0.7656, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 95\n",
      "loss: tensor(0.7669, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 96\n",
      "loss: tensor(0.7706, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 97\n",
      "loss: tensor(0.7710, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 98\n",
      "loss: tensor(0.7670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 7 99\n",
      "loss: tensor(0.7659, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 0\n",
      "loss: tensor(0.7626, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 1\n",
      "loss: tensor(0.7721, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 2\n",
      "loss: tensor(0.7714, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 3\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 4\n",
      "loss: tensor(0.7702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 5\n",
      "loss: tensor(0.7584, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 6\n",
      "loss: tensor(0.7677, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 7\n",
      "loss: tensor(0.7663, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 8\n",
      "loss: tensor(0.7614, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 9\n",
      "loss: tensor(0.7693, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 10\n",
      "loss: tensor(0.7648, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 11\n",
      "loss: tensor(0.7696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 12\n",
      "loss: tensor(0.7732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 13\n",
      "loss: tensor(0.7650, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 14\n",
      "loss: tensor(0.7674, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 15\n",
      "loss: tensor(0.7818, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 16\n",
      "loss: tensor(0.7708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 17\n",
      "loss: tensor(0.7981, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 18\n",
      "loss: tensor(0.7657, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 19\n",
      "loss: tensor(0.7837, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 20\n",
      "loss: tensor(0.7653, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 21\n",
      "loss: tensor(0.7607, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 22\n",
      "loss: tensor(0.7629, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 23\n",
      "loss: tensor(0.7609, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 24\n",
      "loss: tensor(0.7641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 25\n",
      "loss: tensor(0.7634, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 26\n",
      "loss: tensor(0.7606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 27\n",
      "loss: tensor(0.7802, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 28\n",
      "loss: tensor(0.7711, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 29\n",
      "loss: tensor(0.7688, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 30\n",
      "loss: tensor(0.7616, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 31\n",
      "loss: tensor(0.7701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 32\n",
      "loss: tensor(0.7712, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 33\n",
      "loss: tensor(0.7647, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 34\n",
      "loss: tensor(0.7680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 35\n",
      "loss: tensor(0.7677, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 36\n",
      "loss: tensor(0.7737, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 37\n",
      "loss: tensor(0.7644, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 38\n",
      "loss: tensor(0.7748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 39\n",
      "loss: tensor(0.7748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 40\n",
      "loss: tensor(0.7807, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 41\n",
      "loss: tensor(0.7736, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 42\n",
      "loss: tensor(0.7653, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 43\n",
      "loss: tensor(0.7912, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 44\n",
      "loss: tensor(0.7802, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 45\n",
      "loss: tensor(0.7757, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 46\n",
      "loss: tensor(0.7638, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 47\n",
      "loss: tensor(0.7671, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 48\n",
      "loss: tensor(0.7642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 49\n",
      "loss: tensor(0.7720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 50\n",
      "loss: tensor(0.7612, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 51\n",
      "loss: tensor(0.7626, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 52\n",
      "loss: tensor(0.7729, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 53\n",
      "loss: tensor(0.7702, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 54\n",
      "loss: tensor(0.7768, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 55\n",
      "loss: tensor(0.7639, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 56\n",
      "loss: tensor(0.7714, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 57\n",
      "loss: tensor(0.7796, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 58\n",
      "loss: tensor(0.7701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 59\n",
      "loss: tensor(0.7826, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 60\n",
      "loss: tensor(0.7850, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 61\n",
      "loss: tensor(0.7599, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 62\n",
      "loss: tensor(0.7829, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 63\n",
      "loss: tensor(0.7673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 64\n",
      "loss: tensor(0.7632, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 65\n",
      "loss: tensor(0.7650, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 66\n",
      "loss: tensor(0.7708, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 67\n",
      "loss: tensor(0.7673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 68\n",
      "loss: tensor(0.7823, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 69\n",
      "loss: tensor(0.7748, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 70\n",
      "loss: tensor(0.7940, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 71\n",
      "loss: tensor(0.7707, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 72\n",
      "loss: tensor(0.7727, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 73\n",
      "loss: tensor(0.7695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 74\n",
      "loss: tensor(0.7658, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 75\n",
      "loss: tensor(0.7732, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 76\n",
      "loss: tensor(0.7720, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 77\n",
      "loss: tensor(0.7649, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 78\n",
      "loss: tensor(0.7617, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 79\n",
      "loss: tensor(0.7631, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 80\n",
      "loss: tensor(0.7696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 81\n",
      "loss: tensor(0.7735, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 82\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 83\n",
      "loss: tensor(0.7648, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 84\n",
      "loss: tensor(0.7640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 85\n",
      "loss: tensor(0.7736, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 86\n",
      "loss: tensor(0.7723, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 87\n",
      "loss: tensor(0.7653, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 88\n",
      "loss: tensor(0.7777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 89\n",
      "loss: tensor(0.7639, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 90\n",
      "loss: tensor(0.8047, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 91\n",
      "loss: tensor(0.7713, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 92\n",
      "loss: tensor(0.7645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 93\n",
      "loss: tensor(0.7847, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 94\n",
      "loss: tensor(0.7701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 95\n",
      "loss: tensor(0.7696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 96\n",
      "loss: tensor(0.7730, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 97\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 98\n",
      "loss: tensor(0.7633, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 8 99\n",
      "loss: tensor(0.7642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 0\n",
      "loss: tensor(0.7691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 1\n",
      "loss: tensor(0.7606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 2\n",
      "loss: tensor(0.7691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 3\n",
      "loss: tensor(0.7628, grad_fn=<NllLoss2DBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, iteration: 9 4\n",
      "loss: tensor(0.7738, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 5\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 6\n",
      "loss: tensor(0.7669, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 7\n",
      "loss: tensor(0.7785, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 8\n",
      "loss: tensor(0.7635, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 9\n",
      "loss: tensor(0.7604, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 10\n",
      "loss: tensor(0.7725, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 11\n",
      "loss: tensor(0.7655, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 12\n",
      "loss: tensor(0.7648, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 13\n",
      "loss: tensor(0.7601, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 14\n",
      "loss: tensor(0.7645, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 15\n",
      "loss: tensor(0.7602, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 16\n",
      "loss: tensor(0.7592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 17\n",
      "loss: tensor(0.7619, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 18\n",
      "loss: tensor(0.7643, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 19\n",
      "loss: tensor(0.7774, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 20\n",
      "loss: tensor(0.7669, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 21\n",
      "loss: tensor(0.7609, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 22\n",
      "loss: tensor(0.7691, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 23\n",
      "loss: tensor(0.7608, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 24\n",
      "loss: tensor(0.7637, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 25\n",
      "loss: tensor(0.7616, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 26\n",
      "loss: tensor(0.7613, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 27\n",
      "loss: tensor(0.7626, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 28\n",
      "loss: tensor(0.7595, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 29\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 30\n",
      "loss: tensor(0.7598, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 31\n",
      "loss: tensor(0.7684, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 32\n",
      "loss: tensor(0.7612, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 33\n",
      "loss: tensor(0.7849, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 34\n",
      "loss: tensor(0.7786, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 35\n",
      "loss: tensor(0.7753, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 36\n",
      "loss: tensor(0.7825, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 37\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 38\n",
      "loss: tensor(0.7644, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 39\n",
      "loss: tensor(0.7703, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 40\n",
      "loss: tensor(0.7676, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 41\n",
      "loss: tensor(0.7681, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 42\n",
      "loss: tensor(0.7670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 43\n",
      "loss: tensor(0.7618, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 44\n",
      "loss: tensor(0.7629, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 45\n",
      "loss: tensor(0.7716, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 46\n",
      "loss: tensor(0.7633, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 47\n",
      "loss: tensor(0.7719, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 48\n",
      "loss: tensor(0.7639, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 49\n",
      "loss: tensor(0.7628, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 50\n",
      "loss: tensor(0.7680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 51\n",
      "loss: tensor(0.7606, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 52\n",
      "loss: tensor(0.7673, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 53\n",
      "loss: tensor(0.7726, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 54\n",
      "loss: tensor(0.7710, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 55\n",
      "loss: tensor(0.7600, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 56\n",
      "loss: tensor(0.7623, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 57\n",
      "loss: tensor(0.7671, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 58\n",
      "loss: tensor(0.7592, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 59\n",
      "loss: tensor(0.7635, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 60\n",
      "loss: tensor(0.7696, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 61\n",
      "loss: tensor(0.7918, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 62\n",
      "loss: tensor(0.7594, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 63\n",
      "loss: tensor(0.7852, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 64\n",
      "loss: tensor(0.7805, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 65\n",
      "loss: tensor(0.7792, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 66\n",
      "loss: tensor(0.7661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 67\n",
      "loss: tensor(0.7640, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 68\n",
      "loss: tensor(0.7607, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 69\n",
      "loss: tensor(0.7652, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 70\n",
      "loss: tensor(0.7603, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 71\n",
      "loss: tensor(0.7642, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 72\n",
      "loss: tensor(0.7665, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 73\n",
      "loss: tensor(0.7695, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 74\n",
      "loss: tensor(0.7680, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 75\n",
      "loss: tensor(0.7677, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 76\n",
      "loss: tensor(0.7613, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 77\n",
      "loss: tensor(0.7775, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 78\n",
      "loss: tensor(0.7682, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 79\n",
      "loss: tensor(0.7636, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 80\n",
      "loss: tensor(0.7594, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 81\n",
      "loss: tensor(0.7660, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 82\n",
      "loss: tensor(0.7751, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 83\n",
      "loss: tensor(0.7678, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 84\n",
      "loss: tensor(0.7651, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 85\n",
      "loss: tensor(0.7756, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 86\n",
      "loss: tensor(0.7701, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 87\n",
      "loss: tensor(0.7670, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 88\n",
      "loss: tensor(0.7661, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 89\n",
      "loss: tensor(0.7830, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 90\n",
      "loss: tensor(0.7652, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 91\n",
      "loss: tensor(0.7689, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 92\n",
      "loss: tensor(0.7668, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 93\n",
      "loss: tensor(0.7632, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 94\n",
      "loss: tensor(0.7688, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 95\n",
      "loss: tensor(0.7585, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 96\n",
      "loss: tensor(0.7693, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 97\n",
      "loss: tensor(0.7641, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 98\n",
      "loss: tensor(0.7777, grad_fn=<NllLoss2DBackward>)\n",
      "epoch, iteration: 9 99\n",
      "loss: tensor(0.7663, grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = UNet3D()\n",
    "valLoss, epochs = learn(model,num_workers = 0, batch_size = 1,epochs = 10,learning_rate = 0.1, optimizer_name = \"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "-bOn_j_FqW_V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Iteration:  0\n",
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "Iteration:  26\n",
      "Iteration:  27\n",
      "Iteration:  28\n",
      "Iteration:  29\n",
      "Iteration:  30\n",
      "Iteration:  31\n",
      "Iteration:  32\n",
      "Iteration:  33\n",
      "Iteration:  34\n",
      "Iteration:  35\n",
      "Iteration:  36\n",
      "Iteration:  37\n",
      "Iteration:  38\n",
      "Iteration:  39\n",
      "Iteration:  40\n",
      "Iteration:  41\n",
      "Iteration:  42\n",
      "Iteration:  43\n",
      "Iteration:  44\n",
      "Iteration:  45\n",
      "Iteration:  46\n",
      "Iteration:  47\n",
      "Iteration:  48\n",
      "Iteration:  49\n",
      "Iteration:  50\n",
      "Iteration:  51\n",
      "Iteration:  52\n",
      "Iteration:  53\n",
      "Iteration:  54\n",
      "Iteration:  55\n",
      "Iteration:  56\n",
      "Iteration:  57\n",
      "Iteration:  58\n",
      "Iteration:  59\n",
      "Iteration:  60\n",
      "Iteration:  61\n",
      "Iteration:  62\n",
      "Iteration:  63\n",
      "Iteration:  64\n",
      "Iteration:  65\n",
      "Iteration:  66\n",
      "Iteration:  67\n",
      "Iteration:  68\n",
      "Iteration:  69\n",
      "Iteration:  70\n",
      "Iteration:  71\n",
      "Iteration:  72\n",
      "Iteration:  73\n",
      "Iteration:  74\n",
      "Iteration:  75\n",
      "Iteration:  76\n",
      "Iteration:  77\n",
      "Iteration:  78\n",
      "Iteration:  79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = './data/test'\n",
    "test_set = TestDataset(data_path)\n",
    "val_data_loader = DataLoader(dataset = test_set, num_workers=0)\n",
    "print(type(val_data_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval() \n",
    "    batch_dice_list = list()\n",
    "    for iteration, sample in enumerate(val_data_loader):\n",
    "        print(\"Iteration: \", iteration)\n",
    "        img = sample\n",
    "        img = img / 255 - 0.5\n",
    "        y_pred = model(img.reshape(1,1,96,96))\n",
    "        masks = torch.zeros(1,1,96,96)\n",
    "        for index in range(y_pred.shape[0]):\n",
    "            for i in range(y_pred.shape[2]):\n",
    "                for j in range(y_pred.shape[3]):\n",
    "                    masks[index,:,i,j] = torch.argmax(y_pred[index,:,i,j])\n",
    "\n",
    "#         plt.imshow(mask, cmap='gray')\n",
    "#         plt.imshow(masks.squeeze(), cmap='gray')\n",
    "        a = plt.imshow(masks.squeeze(), cmap='gray')\n",
    "        result = plt.savefig('test_results/cmr'+str(121+iteration)+ '_mask' +'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_converter('test_results','submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
