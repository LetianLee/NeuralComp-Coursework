{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2guthgOz-Ssm"
   },
   "source": [
    "# Coursework 2 for Cardiac MR Image Segmentation (2020-2021)\n",
    "\n",
    "After you have gone through the coursework description, this tutorial is designed to further helps you understand the problem and therefore enable you to propose a good solution for this coursework. You will learn:\n",
    "\n",
    "* how to load and save images with OpenCV\n",
    "* how to train a segmentation model with Pytorch\n",
    "* how to evaluate the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsnVbP35-Sso"
   },
   "source": [
    "## 1. Load, show, and save images with OpenCV\n",
    "\n",
    "OpenCV is an open-source computer vision library which helps us to manipulate image data. In this section, we will cover:\n",
    "* Loading an image from file with imread()\n",
    "* Displaying the image with matplotlib plt.imshow()\n",
    "* Saving an image with imwrite()\n",
    "\n",
    "For a more comprehensive study of OpenCV, we encourage you to check the official [OpenCV documentation](https://docs.opencv.org/master/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7ZvSiY3qW_U"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def show_image_mask(img, mask, cmap='gray'): # visualisation\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=cmap)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EN5WJ_XG-Sso"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 #import OpenCV\n",
    "\n",
    "data_dir = './data/train'\n",
    "image = cv2.imread(os.path.join(data_dir,'image','cmr1.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask = cv2.imread(os.path.join(data_dir,'mask','cmr1_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "show_image_mask(image, mask, cmap='gray')\n",
    "plt.pause(1)\n",
    "cv2.imwrite(os.path.join('./','cmr1.png'), mask*85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UDvsGZnYfHS"
   },
   "source": [
    "Note: You will no doubt notice that the mask images appear to be completely black with no sign of any segmentations. This is because the max intensity of pixels in an 8-bit png image is 255 and your image viewer software only sees 255 as white. For those values close to zero, you will only see dark values. This is the case for our masks as the background, the right ventricle, the myocardium, and the left ventricle in each image are 0, 1, 2, and 3, respectively. All of which are close to zero. If we multiply the original mask by 85 and save the result to the directory where this code is, we can see the heart indeed shows up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hULAX3WH-Sss"
   },
   "source": [
    "## 2. Define a segmentation model with Pytorch\n",
    "\n",
    "In this section, we expect you to learn how to:\n",
    "* Define a Segmentation Model\n",
    "* Define a DataLoader that inputs images to the Model\n",
    "* Define training parameters and train the model\n",
    "* Test the trained model with a new input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrKFgoZvUbeg"
   },
   "source": [
    "### 2.1 Define a DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC9s43MqqW_U"
   },
   "source": [
    "Below we provide you with a dataloader to use in your assigment. You will only need to focus on the development of your model and loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYrD95T8qz8T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "        self.mask_files = []\n",
    "        for img_path in self.img_files:\n",
    "            basename = os.path.basename(img_path)\n",
    "            self.mask_files.append(os.path.join(root,'mask',basename[:-4]+'_mask.png'))\n",
    "            \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            mask_path = self.mask_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            label = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float(), torch.from_numpy(label).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82UAfnwSUgc_"
   },
   "source": [
    "### 2.2 Define a Segmenatation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEIkCqdfYnIn"
   },
   "source": [
    "You will need to define your CNN model for segmentation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-W6532hFXa_g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ContBatchNorm3d(nn.modules.batchnorm._BatchNorm):\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.batch_norm(\n",
    "            input, self.running_mean, self.running_var, self.weight, self.bias,\n",
    "            True, self.momentum, self.eps)\n",
    "\n",
    "\n",
    "class LUConv(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, act):\n",
    "        super(LUConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, out_chan, kernel_size=3, padding=1)\n",
    "        self.bn1 = ContBatchNorm3d(out_chan)\n",
    "\n",
    "        if act == 'ReLU':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif act == 'PReLU':\n",
    "            self.activation = nn.PReLU()\n",
    "        elif act == 'LeakyReLU':\n",
    "            self.activation = nn.LeakyReLU()\n",
    "        elif act == 'ELU':\n",
    "            self.activation = nn.ELU(inplace=True)\n",
    "        elif act == 'Tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.bn1(self.conv1(x)))\n",
    "        return out\n",
    "\n",
    "\n",
    "def _make_nConv(in_channel, depth, act, double_chnnel=False):\n",
    "    if double_chnnel:\n",
    "        layer1 = LUConv(in_channel, 32 * (2 ** (depth+1)),act)\n",
    "        layer2 = LUConv(32 * (2 ** (depth+1)), 32 * (2 ** (depth+1)),act)\n",
    "    else:\n",
    "        layer1 = LUConv(in_channel, 32*(2**depth),act)\n",
    "        layer2 = LUConv(32*(2**depth), 32*(2**depth)*2,act)\n",
    "\n",
    "    return nn.Sequential(layer1,layer2)\n",
    "\n",
    "\n",
    "class DownTransition(nn.Module):\n",
    "    def __init__(self, in_channel,depth, act):\n",
    "        super(DownTransition, self).__init__()\n",
    "        self.ops = _make_nConv(in_channel, depth,act)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.current_depth = depth\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.current_depth == 3:\n",
    "            out = self.ops(x)\n",
    "            out_before_pool = out\n",
    "        else:\n",
    "            out_before_pool = self.ops(x)\n",
    "            out = self.maxpool(out_before_pool)\n",
    "        return out, out_before_pool\n",
    "\n",
    "    \n",
    "class UpTransition(nn.Module):\n",
    "    def __init__(self, inChans, outChans, depth,act):\n",
    "        super(UpTransition, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.up_conv = nn.ConvTranspose2d(inChans, outChans, kernel_size=2, stride=2)\n",
    "        self.ops = _make_nConv(inChans+ outChans//2,depth, act, double_chnnel=True)\n",
    "\n",
    "    def forward(self, x, skip_x):\n",
    "        out_up_conv = self.up_conv(x)\n",
    "        concat = torch.cat((out_up_conv,skip_x),1)\n",
    "        out = self.ops(concat)\n",
    "        return out\n",
    "\n",
    "\n",
    "class OutputTransition(nn.Module):\n",
    "    def __init__(self, inChans, n_labels):\n",
    "\n",
    "        super(OutputTransition, self).__init__()\n",
    "        self.final_conv = nn.Conv2d(inChans, n_labels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.sigmoid(self.final_conv(x))\n",
    "        return out\n",
    "\n",
    "    \n",
    "class CNNSEG(nn.Module): # Define your model\n",
    "    def __init__(self, n_class=4, act='ReLU'):\n",
    "        super(CNNSEG, self).__init__()\n",
    "        # fill in the constructor for your model here\n",
    "        self.down_tr64 = DownTransition(1,0,act)\n",
    "        self.down_tr128 = DownTransition(64,1,act)\n",
    "        self.down_tr256 = DownTransition(128,2,act)\n",
    "        self.down_tr512 = DownTransition(256,3,act)\n",
    "\n",
    "        self.up_tr256 = UpTransition(512, 512,2,act)\n",
    "        self.up_tr128 = UpTransition(256,256, 1,act)\n",
    "        self.up_tr64 = UpTransition(128,128,0,act)\n",
    "        self.out_tr = OutputTransition(64, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # fill in the forward function for your model here\n",
    "        self.out64, self.skip_out64 = self.down_tr64(x)\n",
    "        self.out128,self.skip_out128 = self.down_tr128(self.out64)\n",
    "        self.out256,self.skip_out256 = self.down_tr256(self.out128)\n",
    "        self.out512,self.skip_out512 = self.down_tr512(self.out256)\n",
    "\n",
    "        self.out_up_256 = self.up_tr256(self.out512,self.skip_out256)\n",
    "        self.out_up_128 = self.up_tr128(self.out_up_256, self.skip_out128)\n",
    "        self.out_up_64 = self.up_tr64(self.out_up_128, self.skip_out64)\n",
    "        self.out = self.out_tr(self.out_up_64)\n",
    "\n",
    "        return self.out\n",
    "\n",
    "model = CNNSEG() # We can now create a model using your defined segmentation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRdPFTa9a34J"
   },
   "source": [
    "### 2.3 Define a Loss function and optimizer\n",
    "\n",
    "You will need to define a loss function and an optimizer. torch.nn has a variety of readymade loss functions, although you may wish to create your own instead. torch.optim has a variety of optimizers, it is advised that you use one of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRjOZGXRbUFT"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loss function & optimizer\n",
    "\"\"\"\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def sum_tensor(inp, axes, keepdim=False):\n",
    "    # copy from: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/utilities/tensor_utilities.py\n",
    "    axes = np.unique(axes).astype(int)\n",
    "    if keepdim:\n",
    "        for ax in axes:\n",
    "            inp = inp.sum(int(ax), keepdim=True)\n",
    "    else:\n",
    "        for ax in sorted(axes, reverse=True):\n",
    "            inp = inp.sum(int(ax))\n",
    "    return inp\n",
    "\n",
    "def get_tp_fp_fn(net_output, gt, axes=None, mask=None, square=False):\n",
    "    \"\"\"\n",
    "    net_output must be (b, c, x, y(, z)))\n",
    "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
    "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
    "    :param net_output:\n",
    "    :param gt:\n",
    "    :param axes:\n",
    "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
    "    :param square: if True then fp, tp and fn will be squared before summation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = tuple(range(2, len(net_output.size())))\n",
    "\n",
    "    shp_x = net_output.shape\n",
    "    shp_y = gt.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if len(shp_x) != len(shp_y):\n",
    "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
    "\n",
    "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
    "            # if this is the case then gt is probably already a one hot encoding\n",
    "            y_onehot = gt\n",
    "        else:\n",
    "            gt = gt.long()\n",
    "            y_onehot = torch.zeros(shp_x)\n",
    "            if net_output.device.type == \"cuda\":\n",
    "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
    "            y_onehot.scatter_(1, gt, 1)\n",
    "\n",
    "    tp = net_output * y_onehot\n",
    "    fp = net_output * (1 - y_onehot)\n",
    "    fn = (1 - net_output) * y_onehot\n",
    "\n",
    "    if mask is not None:\n",
    "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
    "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
    "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
    "\n",
    "    if square:\n",
    "        tp = tp ** 2\n",
    "        fp = fp ** 2\n",
    "        fn = fn ** 2\n",
    "\n",
    "    tp = sum_tensor(tp, axes, keepdim=False)\n",
    "    fp = sum_tensor(fp, axes, keepdim=False)\n",
    "    fn = sum_tensor(fn, axes, keepdim=False)\n",
    "\n",
    "    return tp, fp, fn\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, apply_nonlin=None, batch_dice=False, do_bg=True, smooth=1.,\n",
    "                 square=False):\n",
    "        \"\"\"\n",
    "        paper: https://arxiv.org/pdf/1706.05721.pdf\n",
    "        \"\"\"\n",
    "        super(TverskyLoss, self).__init__()\n",
    "\n",
    "        self.square = square\n",
    "        self.do_bg = do_bg\n",
    "        self.batch_dice = batch_dice\n",
    "        self.apply_nonlin = apply_nonlin\n",
    "        self.smooth = smooth\n",
    "        self.alpha = 0.61\n",
    "        self.beta = 0.39\n",
    "\n",
    "    def forward(self, x, y, loss_mask=None):\n",
    "        shp_x = x.shape\n",
    "\n",
    "        if self.batch_dice:\n",
    "            axes = [0] + list(range(2, len(shp_x)))\n",
    "        else:\n",
    "            axes = list(range(2, len(shp_x)))\n",
    "\n",
    "        if self.apply_nonlin is not None:\n",
    "            x = self.apply_nonlin(x)\n",
    "\n",
    "        tp, fp, fn = get_tp_fp_fn(x, y, axes, loss_mask, self.square)\n",
    "\n",
    "\n",
    "        tversky = (tp + self.smooth) / (tp + self.alpha*fp + self.beta*fn + self.smooth)\n",
    "\n",
    "        if not self.do_bg:\n",
    "            if self.batch_dice:\n",
    "                tversky = tversky[1:]\n",
    "            else:\n",
    "                tversky = tversky[:, 1:]\n",
    "        tversky = tversky.mean()\n",
    "\n",
    "        return 1-tversky\n",
    "\n",
    "    \n",
    "def get_loss_func(loss_name):\n",
    "    if loss_name == \"Tversky\":\n",
    "        return TverskyLoss()\n",
    "    if loss_name == \"CrossEntropy\":\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "def get_optimizer(model, method, learning_rate):\n",
    "    if method == \"SGD\":\n",
    "        return optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    elif method == \"Adam\":\n",
    "        return optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    elif method == \"AdaGrad\":\n",
    "        return optim.Adagrad(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grDz3fR1qW_V"
   },
   "source": [
    "### 2.4 Training\n",
    "\n",
    "As most of you will use CPUs to train the model, expect your models to take **30 minutes to train if not longer depending on network architecture**. To save time, you should not be using all training data until your model is well developed. If you are running your model on a GPU training should be significantly faster. During the training process, you may want to save the checkpoints as follows:\n",
    "\n",
    "```\n",
    "# Saving checkpoints for validation/testing\n",
    "torch.save(model.state_dict(), path)\n",
    "```\n",
    "The saved checkpoints can be used to load at a later date for validation and testing. Here we give some example code for training a model. Note that you need to specify the max iterations you want to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCb4bxVVchxf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, num_workers = 0, batch_size = 4,epochs = 25,learning_rate = 1, optimizer_name = \"Adam\", loss_name=\"Tversky\", target=None):\n",
    "\n",
    "    # Get Data Loader for Training Set\n",
    "    data_path = './data/train'\n",
    "    train_set = TrainDataset(data_path)\n",
    "    training_data_loader = DataLoader(dataset=train_set, num_workers=num_workers, batch_size=batch_size, \n",
    "                                      shuffle=True,drop_last = True)\n",
    "\n",
    "    # Get Loss Function and Optimizer\n",
    "    loss_func = get_loss_func(loss_name)\n",
    "    optimizer = get_optimizer(model, optimizer_name, learning_rate)\n",
    "\n",
    "    # Initializes empty containers\n",
    "    loss_list_train = list()\n",
    "    loss_list_val = list()\n",
    "    dice_list_train = list()\n",
    "    dice_list_val = list()\n",
    "    \n",
    "    # Train the Model\n",
    "    # Epoch loop\n",
    "    for e in range(epochs):\n",
    "        iteration_dice_list = list()\n",
    "        \n",
    "        # Iteration loop\n",
    "        for iteration, sample in enumerate(training_data_loader):\n",
    "            print(\"Epoch, Iteration:\", e, iteration)\n",
    "            \n",
    "            # Fetch images and labels.  \n",
    "            img, mask = sample\n",
    "            \n",
    "            # show_image_mask(img[0,...].squeeze(), mask[0,...].squeeze()) # visualise all data in training set\n",
    "            # plt.pause(1)\n",
    "\n",
    "            \n",
    "            # Write your FORWARD below\n",
    "            # Note: Input image to your model and ouput the predicted mask and Your predicted mask should have 4 channels\n",
    "            model.train()                                          # Set the model to training mode\n",
    "            optimizer.zero_grad()                                  # Avoid accumulating gradients\n",
    "            img = img / 255 - 0.5                                  # Normalization\n",
    "            y_pred = model(img.reshape(batch_size,1,96,96))        # Forward pass\n",
    "            \n",
    "            \n",
    "            # Then write your BACKWARD & OPTIMIZE below\n",
    "            # Note: Compute Loss and Optimize\n",
    "            loss = loss_func(y_pred , mask.long())                 # Compute Loss\n",
    "            loss.backward()                                        # Calculate Gradients\n",
    "            optimizer.step()                                       # Update Model's Params\n",
    "            \n",
    "            masks_pred = torch.argmax(y_pred, dim=1)               # Merge four channels into one channel\n",
    "            iteration_dice = see_dice(mask.numpy(), masks_pred.squeeze().numpy())    # Compute Dice\n",
    "            \n",
    "            # Record the Loss and Dice of training set for each iteration\n",
    "            iteration_dice_list.append(iteration_dice)\n",
    "            loss_list_train.append(loss)\n",
    "            print(\"Iteration Loss:\",loss)\n",
    "        \n",
    "        # Record the Dice of training set for each epoch (Take the mean dice of each iteration)\n",
    "        epoch_dice = np.mean(iteration_dice_list)\n",
    "        dice_list_train.append(epoch_dice)\n",
    "        print(\"Epoch Dice:\", epoch_dice)\n",
    "        \n",
    "        # Evaluate by validation set\n",
    "        val_dice, val_loss = evaluate(model, loss_func)\n",
    "        loss_list_val.append(val_loss)\n",
    "        dice_list_val.append(val_dice)\n",
    "        \n",
    "        # Check the validation dice with target dice\n",
    "        if target:\n",
    "            if val_dice > target:                                          # Find a desirable dice\n",
    "                model_params_path = \"net_params.pth\"\n",
    "                torch.save(model.state_dict(), model_params_path)          # Save the model\n",
    "                print(\"The model parameters have been saved.\")\n",
    "                break\n",
    "    \n",
    "    # Plot Loss and Dice both in Training set and Validation set\n",
    "    fig, axs = plt.subplots(nrows = 1, ncols = 2, sharex=False, sharey=False, figsize=(12, 5))\n",
    "    # Plot Loss\n",
    "    axs[0].plot(loss_list_train, \"b-\", label=u\"Train Loss\") \n",
    "    X = (np.arange(len(loss_list_val))+1) * int(100/batch_size)\n",
    "    axs[0].plot(X, loss_list_val, \"ro-\", label=u\"Val Loss\") \n",
    "    axs[0].set_xlabel('Iteration')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend(loc=\"upper right\")\n",
    "    # Plot Dice \n",
    "    axs[1].plot(dice_list_train, \"bo-\", label=u\"Train Dice\") \n",
    "    for x,y in enumerate(dice_list_train):\n",
    "        if x % max(int(len(dice_list_train)/5),1) == 0 or x == len(dice_list_train)-1:\n",
    "            axs[1].text(x, y, '%.3f' % y, fontdict={'fontsize':10})\n",
    "    axs[1].plot(dice_list_val, \"ro-\", label=u\"Val Dice\") \n",
    "    for x,y in enumerate(dice_list_val):\n",
    "        if x % max(int(len(dice_list_val)/5),1) == 0 or x == len(dice_list_val)-1:\n",
    "            axs[1].text(x, y, '%.3f' % y, fontdict={'fontsize':10})\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_ylabel('Dice')\n",
    "    axs[1].legend(loc=\"lower right\")\n",
    "    plt.suptitle('Comparing Loss and Dice', fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    return dice_list_val[-1], loss_list_val[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCZP-xof-Sst"
   },
   "source": [
    "### 2.5 Testing\n",
    "\n",
    "When validating the trained checkpoints (models), remember to change the model status as **Evaluation Mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGmhTdkciDt0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVS22lrjqW_V"
   },
   "outputs": [],
   "source": [
    "# In this block you are expected to write code to load saved model and deploy it to all data in test set to \n",
    "# produce segmentation masks in png images valued 0,1,2,3, which will be used for the submission to Kaggle.\n",
    "\n",
    "def test(model):\n",
    "    \n",
    "    # Get Data Loader for Test Set\n",
    "    data_path = './data/test'\n",
    "    num_workers = 0\n",
    "    batch_size = 2\n",
    "    test_set = TestDataset(data_path)\n",
    "    test_data_loader = DataLoader(dataset=test_set, num_workers=num_workers,batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Setting\n",
    "    i_png = 120\n",
    "    folder = './test_results'\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    # Load saved model\n",
    "    model_params_path = \"net_params.pth\"\n",
    "    model.load_state_dict(torch.load(model_params_path))\n",
    "\n",
    "    # Test Model\n",
    "    with torch.no_grad():               # fix the model's params\n",
    "        model.eval()                    # set model to evaluation mode\n",
    "\n",
    "        for iteration, sample in enumerate(test_data_loader):\n",
    "            img = sample                                          # Fetch images and labels\n",
    "\n",
    "            # plt.imshow(img[0,...].squeeze(), cmap='gray')       # visualise all images in test set\n",
    "            # plt.pause(1)\n",
    "\n",
    "            # Produce Segmentation Masks\n",
    "            img = img / 255 - 0.5                                 # Normalization\n",
    "            y_pred = model(img.reshape(batch_size,1,96,96))       # Forward pass\n",
    "            masks = torch.argmax(y_pred, dim=1)                   # Merge four channels into one channel\n",
    "\n",
    "            # Save png images\n",
    "            masks = masks.squeeze()\n",
    "            for mask in masks:\n",
    "                i_png = i_png + 1\n",
    "                cv2.imwrite(os.path.join(folder,'cmr%s_mask.png' % i_png), mask.numpy())\n",
    "    \n",
    "    print(\"Saved image successfully\")\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsycVbIuUov3"
   },
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "As we will automatically evaluate your predicted test makes on Kaggle, in this section we expect you to learn:\n",
    "* what is the Dice score used on Kaggle to measure your models performance\n",
    "* how to submit your predicted masks to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NicQyj47jsD1"
   },
   "source": [
    "### 3.1 Dice Score\n",
    "\n",
    "To evaluate the quality of the predicted masks, the Dice score is adopted. Dice score on two masks A and B is defined as the intersection ratio between the overlap area and the average area of two masks. A higher Dice suggests a better registration.\n",
    "\n",
    "$Dice (A, B)= \\frac{2|A \\cap B|}{|A| + |B|} $\n",
    "\n",
    "However, in our coursework, we have three labels in each mask, we will compute the Dice score for each label and then average the three of them as the final score. Below we have given you `categorical_dice` for free so you can test your results before submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzOY4GROqW_V"
   },
   "outputs": [],
   "source": [
    "def categorical_dice(mask1, mask2, label_class=1):\n",
    "    \"\"\"\n",
    "    Dice score of a specified class between two volumes of label masks.\n",
    "    (classes are encoded but by label class number not one-hot )\n",
    "    Note: stacks of 2D slices are considered volumes.\n",
    "\n",
    "    Args:\n",
    "        mask1: N label masks, numpy array shaped (H, W, N)\n",
    "        mask2: N label masks, numpy array shaped (H, W, N)\n",
    "        label_class: the class over which to calculate dice scores\n",
    "\n",
    "    Returns:\n",
    "        volume_dice\n",
    "    \"\"\"\n",
    "    mask1_pos = (mask1 == label_class).astype(np.float32)\n",
    "    mask2_pos = (mask2 == label_class).astype(np.float32)\n",
    "    dice = 2 * np.sum(mask1_pos * mask2_pos) / (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dice between two masks in 3 labels\n",
    "def see_dice(mask1, mask2):\n",
    "    dice_list = list()\n",
    "    for i in range(1, 4):\n",
    "        dice = categorical_dice(mask1, mask2, label_class=i)\n",
    "        dice_list.append(dice)\n",
    "    return np.mean(dice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_func, num_workers = 0, imshow=False):\n",
    "    \n",
    "    # Get Data Loader for Validation Set\n",
    "    data_path = './data/val'\n",
    "    val_set = TrainDataset(data_path)\n",
    "    val_data_loader = DataLoader(dataset=val_set, num_workers=num_workers, shuffle=True)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():               # fix the model's params\n",
    "        model.eval()                    # set model to evaluation mode\n",
    "        batch_dice_list = list()\n",
    "        for iteration, sample in enumerate(val_data_loader):\n",
    "            img, mask = sample                                   # Fetch images and labels\n",
    "            img = img/255 - 0.5                                  # Normalization\n",
    "            y_pred = model(img.reshape(1,1,96,96))               # Forward pass\n",
    "            val_loss = loss_func(y_pred , mask.long())           # Compute validation loss\n",
    "            masks = torch.argmax(y_pred, dim=1)                  # Merge four channels into one channel\n",
    "            \n",
    "            # Plot the true mask and the predicted mask\n",
    "            if imshow:\n",
    "                fig, axs = plt.subplots(nrows = 1, ncols = 2, sharex=True, sharey=True, figsize=(12, 5))\n",
    "                axs[0].set_title(\"True Mask\")\n",
    "                axs[1].set_title(\"Predicted Mask\")\n",
    "                axs[0].imshow(mask.squeeze(), cmap='gray')\n",
    "                axs[1].imshow(masks.squeeze(), cmap='gray')\n",
    "                plt.show()\n",
    "            \n",
    "            # Record the dice for each iteration\n",
    "            batch_dice = see_dice(mask.numpy(), masks.squeeze().numpy())       # Compute Dice\n",
    "            batch_dice_list.append(batch_dice)\n",
    "            print(\"Batch Dice:\",batch_dice)\n",
    "\n",
    "        # Record the dice of the entire validation set\n",
    "        val_dice = np.mean(batch_dice_list)\n",
    "        print(\"Validation Dice:\",val_dice)\n",
    "        \n",
    "        return val_dice, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZcsrwmVjy5k"
   },
   "source": [
    "### 3.2 Submission\n",
    "\n",
    "Kaggle requires your submission to be in a specific CSV format. To help ensure your submissions are in the correct format, we have provided some helper functions to do this for you. For those interested, the png images are run-length encoded and saved in a CSV to the specifications required by our competition.\n",
    "\n",
    "It is sufficient to use this helper function. To do so, save your 80 predicted masks into a directory. ONLY the 80 predicted masks should be in this directory. Call the submission_converter function with the first argument as the directory containing your masks, and the second the directory in which you wish to save your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHDVbgu0qW_V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def rle_encoding(x):\n",
    "    '''\n",
    "    *** Credit to https://www.kaggle.com/rakhlin/fast-run-length-encoding-python ***\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev + 1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def submission_converter(mask_directory, path_to_save):\n",
    "    writer = open(os.path.join(path_to_save, \"submission.csv\"), 'w')\n",
    "    writer.write('id,encoding\\n')\n",
    "\n",
    "    files = os.listdir(mask_directory)\n",
    "\n",
    "    for file in files:\n",
    "        name = file[:-4]\n",
    "        mask = cv2.imread(os.path.join(mask_directory, file), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        mask1 = (mask == 1)\n",
    "        mask2 = (mask == 2)\n",
    "        mask3 = (mask == 3)\n",
    "\n",
    "        encoded_mask1 = rle_encoding(mask1)\n",
    "        encoded_mask1 = ' '.join(str(e) for e in encoded_mask1)\n",
    "        encoded_mask2 = rle_encoding(mask2)\n",
    "        encoded_mask2 = ' '.join(str(e) for e in encoded_mask2)\n",
    "        encoded_mask3 = rle_encoding(mask3)\n",
    "        encoded_mask3 = ' '.join(str(e) for e in encoded_mask3)\n",
    "\n",
    "        writer.write(name + '1,' + encoded_mask1 + \"\\n\")\n",
    "        writer.write(name + '2,' + encoded_mask2 + \"\\n\")\n",
    "        writer.write(name + '3,' + encoded_mask3 + \"\\n\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments for Different Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\"\"\"\n",
    "Choose Different Hyperparameters\n",
    "\"\"\"\n",
    "# loss_name = 'CrossEntropy'\n",
    "loss_name = 'Tversky'\n",
    "\n",
    "# optimizer_name = 'SGD'\n",
    "optimizer_name = 'Adam'\n",
    "# optimizer_name = 'AdaGrad'\n",
    "\n",
    "activation_name = 'ReLU'\n",
    "# activation_name = 'Tanh'\n",
    "# activation_name = 'LeakyReLU'\n",
    "\n",
    "lr_search_list = [1,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6]\n",
    "batch_search_list = [1,2,4,8,16,32,64]\n",
    "epochs = 25\n",
    "num_workers = 0\n",
    "    \n",
    "# Record the result into a CSV file\n",
    "file_name = activation_name + \"_\" + loss_name + \"_\" + optimizer_name + '.csv'\n",
    "\n",
    "\"\"\"\n",
    "Do Experiments with Different Hyperparameters\n",
    "\"\"\"\n",
    "with open(file_name, 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Learning Rate\", \"Batch Size\",\"Epochs\",\"Loss Function\", \"Optimizer\",\"Activation\",\"Mean Dice\",\"Validation Loss\"])\n",
    "    \n",
    "    for lr in lr_search_list:\n",
    "        print(\"Test for Learning Rate: \", lr)\n",
    "        for batch in batch_search_list:\n",
    "            print(\"Test for Batch Size: \", batch)\n",
    "            \n",
    "            # Initialize the model\n",
    "            model = CNNSEG(act=activation_name)\n",
    "            \n",
    "            # Train the model and get the validation result\n",
    "            meanDice, valLoss = train(\n",
    "                model = model,\n",
    "                num_workers = num_workers, \n",
    "                batch_size = batch,\n",
    "                epochs = epochs,\n",
    "                learning_rate = lr, \n",
    "                optimizer_name = optimizer_name,\n",
    "                loss_name = loss_name\n",
    "            )\n",
    "            \n",
    "            # Record the validation result \n",
    "            writer.writerow([lr, batch, epochs, loss_name, optimizer_name, activation_name, meanDice, valLoss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate the Final Model to Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Set Best Hyperparameters\n",
    "loss_name = 'Tversky'\n",
    "optimizer_name = 'Adam'\n",
    "activation_name = 'ReLU'\n",
    "learning_rate = 0.0001\n",
    "batch_size = 1\n",
    "epochs = 25\n",
    "num_workers = 0\n",
    "model = CNNSEG(act=activation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Train the model\n",
    "model_para_path = train(\n",
    "    model = model, \n",
    "    num_workers = num_workers, \n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    learning_rate = learning_rate, \n",
    "    optimizer_name = optimizer_name, \n",
    "    loss_name= loss_name, \n",
    "    target=0.85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Visualise prediction in Validation Set\n",
    "model_params_path = \"net_params.pth\"\n",
    "model.load_state_dict(torch.load(model_params_path))\n",
    "evaluate(model, get_loss_func(loss_name), imshow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Implement on Test Set\n",
    "folder = test(model)\n",
    "\n",
    "# Generate CSV file\n",
    "submission_converter(folder, './')\n",
    "print(\"Generate CSV file successfully\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
